# SEOHEE
# 2026-02-11 ver. (refac: keep same features)

import streamlit as st
import pandas as pd
import numpy as np
import importlib
from datetime import datetime, timedelta
import plotly.express as px  # pie/barë§Œ ì‚¬ìš©
import plotly.graph_objects as go  # âœ… ìƒë‹¨ì— ìˆì–´ë„ ë˜ê³ , ë°‘ì— ë¸”ë¡ ë‚´ë¶€ go importë„ ìœ ì§€í•  ê²ƒ(ìš”ì²­)

import modules.ui_common as ui
importlib.reload(ui)

from google.oauth2.service_account import Credentials
import gspread


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CONFIG
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CFG = {
    "TZ": "Asia/Seoul",
    "CACHE_TTL": 3600,
    "DEFAULT_LOOKBACK_DAYS": 14,
    "HEADER_UPDATE_AM": 850,
    "HEADER_UPDATE_PM": 1535,
    "CSS_BLOCK_CONTAINER": """
        <style>
            .block-container {
                max-width: 100% !important;
                padding-top: 0rem;
                padding-bottom: 8rem;
                padding-left: 5rem;
                padding-right: 4.5rem;
            }
        </style>
    """,
    "CSS_TABS": """
        <style>
            [role="tablist"] [role="tab"] { margin-right: 1rem; }
        </style>
    """,
}

AW_COLS  = {
            "awareness_type",
            "awareness_type_a",
            "awareness_type_b"
            }
CAT_COLS = [
            "shrm_type",
            "shrm_region",
            "shrm_branch",
            "demo_gender",
            "demo_age",
            "awareness_type",
            "purchase_purpose",
            "visit_type",
            ]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DATE NORMALIZATION (ë‹¨ì¼ ê¸°ì¤€)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _norm_dt(s: pd.Series | pd.Index | pd.DatetimeIndex) -> pd.Series:
    """
    ë‚ ì§œ/ì‹œê°„ì´ ì„ì—¬ ë“¤ì–´ì™€ë„ ë¬´ì¡°ê±´ 'ë‚ ì§œ(00:00:00)'ë¡œ í†µì¼.
    ìŠ¤íƒ/ë¼ì¸/í”¼ë²— ë“± ëª¨ë“  ì¶•ì˜ ê¸°ì¤€ì„ ë‹¨ í•˜ë‚˜ë¡œ ìœ ì§€.
    """
    x = pd.to_datetime(s, errors="coerce")
    return x.dt.normalize()


def _add_period_day(df1: pd.DataFrame, date_col: str) -> pd.DataFrame:
    """
    ui.add_period_columnsë¥¼ ì“°ë˜,
    _period_dtê°€ í•­ìƒ normalize(00:00:00) ë˜ë„ë¡ ê°•ì œ.
    """
    out = ui.add_period_columns(df1, date_col, "ì¼ë³„")
    if "_period_dt" in out.columns:
        out["_period_dt"] = _norm_dt(out["_period_dt"])
    return out


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# HELPER
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _clean_cat(s: pd.Series) -> pd.Series:
    # âœ… "nan" ë¬¸ìì—´/ê³µë°±/None/NA ëª¨ë‘ "ê¸°íƒ€"ë¡œ í†µì¼ (ê¸°ì¡´ ë™ì‘ ìœ ì§€ + ì¼€ì´ìŠ¤ í™•ì¥)
    ss = s.astype("string")
    ss = ss.str.strip()
    ss = ss.fillna("")
    ss = ss.replace(["nan", "NaN", "None", "<NA>"], "")
    ss = ss.replace("", "ê¸°íƒ€")
    return ss


def _order_with_etc_last(keys: list, sums: dict | None = None) -> list:
    sums = sums or {}
    ks = [str(k) for k in keys if str(k) != "nan" and str(k) != ""]
    etc = [k for k in ks if k == "ê¸°íƒ€"]
    others = [k for k in ks if k != "ê¸°íƒ€"]
    others = sorted(others, key=lambda k: float(sums.get(k, 0.0)), reverse=True)
    return others + etc


def _get_px_sequence() -> list[str]:
    # âœ… "ë§‰ëŒ€ê°€ ì“°ëŠ” ê¸°ë³¸ íŒ”ë ˆíŠ¸"ë¥¼ ê·¸ëŒ€ë¡œ ì“´ë‹¤ (í™˜ê²½ ê¸°ë³¸ê°’ ë³µì œ)
    # seq = px.defaults.color_discrete_sequence
    seq = px.colors.qualitative.Set1
    if not isinstance(seq, (list, tuple)) or len(seq) == 0:
        seq = px.colors.qualitative.Plotly
    return list(seq)


def _make_color_map(order: list[str], seq: list[str]) -> dict[str, str]:
    if not order:
        return {}
    pal = (list(seq) * ((len(order) // len(seq)) + 1))[: len(order)]
    return dict(zip(order, pal))


def _agg_dim_for_order(d: pd.DataFrame, dim: str) -> pd.DataFrame:
    if dim not in d.columns:
        return pd.DataFrame(columns=[dim, "value"])

    key = _clean_cat(d[dim]).astype(str)

    if (dim in AW_COLS) and ("weight" in d.columns):
        out = (
            d.assign(_k=key)
            .groupby("_k", dropna=False)["weight"]
            .sum()
            .reset_index()
            .rename(columns={"_k": dim, "weight": "value"})
        )
    else:
        out = (
            d.assign(_k=key)
            .groupby("_k", dropna=False)
            .size()
            .reset_index(name="value")
            .rename(columns={"_k": dim})
        )

    out["value"] = pd.to_numeric(out["value"], errors="coerce").fillna(0)
    out[dim] = _clean_cat(out[dim]).astype(str)

    # cleanìœ¼ë¡œ ë¼ë²¨ í•©ì³ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ ì¬ì§‘ê³„
    out = out.groupby(dim, dropna=False, as_index=False)["value"].sum()
    out = out.sort_values("value", ascending=False).reset_index(drop=True)
    return out


def _parse_shrm_text(df1: pd.DataFrame) -> pd.DataFrame:
    if "shrm_name" in df1.columns:
        ss = (
            df1["shrm_name"]
            .astype("string")
            .fillna("")
            .astype(str)
            .str.strip()
        )

        parts = ss.str.split("_", n=2, expand=True)

        df1["shrm_type"] = parts[0].fillna("").str.strip().replace("", "ê¸°íƒ€")
        df1["shrm_branch"] = parts[1].fillna("").str.strip().replace("", "ê¸°íƒ€")
        df1["shrm_region"] = parts[2].fillna("").str.strip().replace("", "ê¸°íƒ€")

    else:
        df1["shrm_type"] = "ê¸°íƒ€"
        df1["shrm_branch"] = "ê¸°íƒ€"
        df1["shrm_region"] = "ê¸°íƒ€"

    return df1


def render_shrm_tabs(
    df: pd.DataFrame,
    df_aw: pd.DataFrame,
    title: str,
    conf: dict,
    key_tag: str = "tab",
    agg_mode: str = "auto",        # "auto" | "size" | "sum"
    agg_value_col: str | None = None,  # ex) "cnt"  (sumì¼ ë•Œë§Œ ì˜ë¯¸)
):
    pie_dim = conf["pie"]
    x = conf["stack_x"]
    c = conf["stack_color"]

    if df is None or df.empty:
        st.warning("ì„ íƒëœ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    use_aw = (pie_dim in AW_COLS) or (c in AW_COLS)
    src = df_aw if (use_aw and df_aw is not None and not df_aw.empty) else df

    # agg_mode
    mode = (agg_mode or "auto").lower().strip()
    if mode not in ("auto", "size", "sum"):
        mode = "auto"

    if mode == "auto":
        if agg_value_col and (agg_value_col in src.columns):
            mode2 = "sum"
        else:
            mode2 = "size"
    else:
        mode2 = mode

    # sumì„ ê°•ì œí–ˆëŠ”ë° ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ë§Œë“¤ì–´ì„œ ë™ì‘ë§Œ ìœ ì§€ (êµ³ì´)
    if mode2 == "sum":
        if (not agg_value_col) or (agg_value_col not in src.columns):
            src[agg_value_col or "_cnt"] = 0
            agg_value_col = agg_value_col or "_cnt"
        src[agg_value_col] = pd.to_numeric(src[agg_value_col], errors="coerce").fillna(0)

    # íŒ”ë ˆíŠ¸/ë§µ ë¡œì§ ë‹¨ì¼í™”: ì „ì—­ í•¨ìˆ˜ë§Œ ì‚¬ìš©
    seq = _get_px_sequence()

    # 1) order/cmap ê¸°ì¤€: stack_color(c) ê¸°ì¤€ í•©ê³„ í° ìˆœ + ê¸°íƒ€ ë§¨ë’¤
    bar_order = None
    bar_cmap = None
    if c in src.columns:
        if mode2 == "sum":
            d_ord = (
                src.assign(_k=_clean_cat(src[c]).astype(str))
                .groupby("_k", dropna=False)[agg_value_col]
                .sum()
                .reset_index()
                .rename(columns={"_k": c, agg_value_col: "value"})
            )
            d_ord["value"] = pd.to_numeric(d_ord["value"], errors="coerce").fillna(0)
            d_ord[c] = _clean_cat(d_ord[c]).astype(str)
            d_ord = d_ord.groupby(c, dropna=False, as_index=False)["value"].sum()
            d_ord = d_ord.sort_values("value", ascending=False).reset_index(drop=True)
        else:
            d_ord = _agg_dim_for_order(src, c)

        if not d_ord.empty:
            sums = d_ord.set_index(c)["value"].to_dict()
            bar_order = _order_with_etc_last(list(sums.keys()), sums)
            bar_cmap = _make_color_map(bar_order, seq)

    pv = None
    c1, c2 = st.columns([3, 7], vertical_alignment="top")

    # 2) PIE
    with c1:
        if pie_dim not in src.columns:
            st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            if mode2 == "sum":
                d_pie = (
                    src.assign(_k=_clean_cat(src[pie_dim]).astype(str))
                    .groupby("_k", dropna=False)[agg_value_col]
                    .sum()
                    .reset_index()
                    .rename(columns={"_k": pie_dim, agg_value_col: "value"})
                )
                d_pie["value"] = pd.to_numeric(d_pie["value"], errors="coerce").fillna(0)
                d_pie[pie_dim] = _clean_cat(d_pie[pie_dim]).astype(str)
                d_pie = d_pie.groupby(pie_dim, dropna=False, as_index=False)["value"].sum()
                d_pie = d_pie.sort_values("value", ascending=False).reset_index(drop=True)
            else:
                d_pie = _agg_dim_for_order(src, pie_dim)

            if d_pie.empty:
                st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                sums_p = d_pie.set_index(pie_dim)["value"].to_dict()
                pie_order = _order_with_etc_last(list(sums_p.keys()), sums_p)

                if (pie_dim == c) and (bar_order is not None) and (bar_cmap is not None):
                    pie_order = [k for k in bar_order if k in pie_order] + [
                        k for k in pie_order if k not in bar_order
                    ]
                    pie_cmap = {k: bar_cmap[k] for k in pie_order if k in bar_cmap}
                    missing = [k for k in pie_order if k not in pie_cmap]
                    if missing:
                        pie_cmap.update(_make_color_map(missing, seq))
                else:
                    pie_cmap = _make_color_map(pie_order, seq)

                d_pie[pie_dim] = pd.Categorical(
                    d_pie[pie_dim].astype(str), categories=pie_order, ordered=True
                )
                d_pie = d_pie.sort_values(pie_dim).reset_index(drop=True)

                fig1 = px.pie(
                    d_pie,
                    names=pie_dim,
                    values="value",
                    color=pie_dim,
                    color_discrete_map=pie_cmap,
                    category_orders={pie_dim: pie_order},
                    title=None,
                )
                fig1.update_traces(opacity=0.6)
                fig1.update_layout(
                    height=360,
                    margin=dict(l=0, r=0, t=30, b=30),
                    showlegend=False,
                )
                st.plotly_chart(
                    fig1,
                    use_container_width=True,
                    key=f"pie::{key_tag}::{title}::{pie_dim}",
                )

    # 3) STACK
    with c2:
        if x in src.columns and c in src.columns:
            if x == "event_date":
                base = _add_period_day(src, "event_date")
                base = base.assign(**{c: _clean_cat(base[c]).astype(str)})
                
                # ì£¼ë³„/ì¼ë³„ ìë™ íŒë‹¨
                is_week = False
                if "_period" in base.columns:
                    is_week = base["_period"].astype(str).str.contains("~").any()

                x_col = "_period" if is_week else "_period_dt"
                sort_col = "_period_dt"

                if mode2 == "sum":
                    agg = (
                        base.groupby([x_col, "_period", c], dropna=False)[agg_value_col]
                        .sum()
                        .reset_index(name="value")
                        .sort_values(sort_col)
                        .reset_index(drop=True)
                    )
                else:
                    if (c in AW_COLS) and ("weight" in base.columns):
                        agg = (
                            base.groupby([x_col, "_period", c], dropna=False)["weight"]
                            .sum()
                            .reset_index(name="value")
                            .sort_values(sort_col)
                            .reset_index(drop=True)
                        )
                    else:
                        agg = (
                            base.groupby([x_col, "_period", c], dropna=False)
                            .size()
                            .reset_index(name="value")
                            .sort_values(sort_col)
                            .reset_index(drop=True)
                        )

                agg["value"] = pd.to_numeric(agg["value"], errors="coerce").fillna(0)

                if bar_order is not None:
                    agg[c] = pd.Categorical(agg[c].astype(str), categories=bar_order, ordered=True)
                    agg = agg.sort_values([sort_col, c]).reset_index(drop=True)

                ui.render_stack_graph(
                    agg,
                    x=x_col,
                    y="value",
                    color=c,
                    height=360,
                    opacity=0.6,
                    show_value_in_hover=True,
                    key=f"stack::{key_tag}::{title}::{c}",
                    color_discrete_map=(bar_cmap or None),
                    category_orders={c: (bar_order or None)},
                )

                pv = ui.build_pivot_table(agg, index_col=c, col_col=x_col, val_col="value")

            else:
                tmp = src.assign(**{c: _clean_cat(src[c]).astype(str)})

                if mode2 == "sum":
                    agg = (
                        tmp.groupby([x, c], dropna=False)[agg_value_col]
                        .sum()
                        .reset_index(name="value")
                    )
                else:
                    if (c in AW_COLS) and ("weight" in tmp.columns):
                        agg = (
                            tmp.groupby([x, c], dropna=False)["weight"]
                            .sum()
                            .reset_index(name="value")
                        )
                    else:
                        agg = (
                            tmp.groupby([x, c], dropna=False)
                            .size()
                            .reset_index(name="value")
                        )

                agg["value"] = pd.to_numeric(agg["value"], errors="coerce").fillna(0)
                agg[x] = agg[x].astype(str)
                agg[c] = _clean_cat(agg[c]).astype(str)

                if bar_order is not None:
                    agg[c] = pd.Categorical(agg[c].astype(str), categories=bar_order, ordered=True)
                    agg = agg.sort_values([x, c]).reset_index(drop=True)

                ui.render_stack_graph(
                    agg,
                    x=x,
                    y="value",
                    color=c,
                    height=360,
                    opacity=0.6,
                    show_value_in_hover=True,
                    key=f"stack::{key_tag}::{title}::{x}::{c}",
                    color_discrete_map=(bar_cmap or None),
                    category_orders={c: (bar_order or None)},
                )

                pv = ui.build_pivot_table(agg, index_col=c, col_col=x, val_col="value")
        else:
            st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    if pv is not None:
        st.dataframe(pv, use_container_width=True, hide_index=True, row_height=30)
    else:
        st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# INSIGHT (CROSS)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def write_mutable_insight(
    agg: pd.DataFrame,
    row_col: str,
    col_col: str,
    row_label: str,
    col_label: str,
    row_order: list[str],
    col_order: list[str],
    min_row_total: int = 5,
    strong_pct: float = 50.0,
    gap_pct: float = 20.0,
    topk: int = 3,
):
    if agg is None or agg.empty:
        return ["ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."]

    d = agg[[row_col, col_col, "value"]].copy()
    d[row_col] = d[row_col].astype(str)
    d[col_col] = d[col_col].astype(str)
    d["value"] = pd.to_numeric(d["value"], errors="coerce").fillna(0)

    col_sum = d.groupby(col_col, dropna=False)["value"].sum().sort_values(ascending=False)
    if col_sum.empty:
        return ["ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."]

    total = float(col_sum.sum()) if float(col_sum.sum()) != 0 else 1.0
    top_cols = [c for c in col_order if c in col_sum.index][:topk] or col_sum.index.astype(str).tolist()[:topk]

    lines = []
    lines.append(
        f"ì „ì²´ì ìœ¼ë¡œ **{col_label}**ì—ì„œëŠ” "
        + ", ".join([f"**{c}**({col_sum[c]/total*100:.0f}%)" for c in top_cols])
        + " ìˆœìœ¼ë¡œ ë§ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤."
    )

    row_tot = d.groupby(row_col, dropna=False)["value"].sum()
    d["_row_sum"] = d.groupby(row_col, dropna=False)["value"].transform("sum").replace(0, np.nan)
    d["pct_row"] = (d["value"] / d["_row_sum"] * 100).fillna(0)
    d = d.drop(columns=["_row_sum"])

    for r in row_order:
        if r not in row_tot.index:
            continue
        if float(row_tot[r]) < float(min_row_total):
            continue

        rr = d[d[row_col] == r].sort_values("pct_row", ascending=False)
        if rr.empty:
            continue

        c1 = rr.iloc[0][col_col]
        v1 = float(rr.iloc[0]["pct_row"])
        v2 = float(rr.iloc[1]["pct_row"]) if len(rr) > 1 else 0.0

        if (v1 >= strong_pct) or ((v1 - v2) >= gap_pct):
            lines.append(f"- **{r}**ì—ì„œëŠ” **{c1}**ì´(ê°€) {v1:.0f}%ë¡œ ê°€ì¥ ë§ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")

    top1 = str(col_sum.index[0])
    top1_pct = float(col_sum.iloc[0] / total * 100)
    if top1_pct >= 40:
        lines.append(f"- ì „ì²´ì ìœ¼ë¡œ **{top1}** ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ({top1_pct:.0f}%)")

    return lines


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# main
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # A) Layout / CSS
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown(CFG["CSS_BLOCK_CONTAINER"], unsafe_allow_html=True)
    st.markdown(CFG["CSS_TABS"], unsafe_allow_html=True)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # B) Sidebar (ê¸°ê°„)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.sidebar.header("Filter")
    today = datetime.now().date()
    default_end = today - timedelta(days=1)
    default_start = today - timedelta(days=CFG["DEFAULT_LOOKBACK_DAYS"])

    start_date, end_date = st.sidebar.date_input(
        "ê¸°ê°„ ì„ íƒ",
        value=[default_start, default_end],
        max_value=default_end,
    )
    cs = start_date.strftime("%Y%m%d")
    ce = (end_date + timedelta(days=1)).strftime("%Y%m%d")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # C) Data Load
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    @st.cache_data(ttl=CFG["CACHE_TTL"])
    def load_data(cs: str, ce: str):
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive",]
        try:
            creds = Credentials.from_service_account_file("C:/_code/auth/sleeper-461005-c74c5cd91818.json", scopes=scope,)
        except:
            sa_info = st.secrets["sleeper-462701-admin"]
            if isinstance(sa_info, str):
                import json
                sa_info = json.loads(sa_info)
            creds = Credentials.from_service_account_info(sa_info, scopes=scope)

        gc = gspread.authorize(creds)
        sh = gc.open_by_url("https://docs.google.com/spreadsheets/d/1g2HWpm3Le3t3P3Hb9nm2owoiaxywaXv--L0SHEDx3rQ/edit")
        
        df1 = pd.DataFrame(sh.worksheet("shrm_data").get_all_records())
        df2 = pd.DataFrame(sh.worksheet("shrm_nplace").get_all_records())
        
        # ì‡¼ë£¸ ì •ë³´ê°€ ì—†ìœ¼ë©´ ë¼ì¸ ì‚­ì œ
        for d in [df1, df2]:
            d["shrm_name"] = (
                d["shrm_name"]
                .astype("string")
                .str.strip()
                .replace(["", "nan", "NaN", "None", "none", "null", "<NA>"], pd.NA)
            )

            d.dropna(subset=["shrm_name"], inplace=True)
            d.drop(d[d["shrm_name"].str.len() < 2].index, inplace=True)

        # (ì •ê·œí™”) GSìš© ë‚ ì§œ ê¹¨ì§ ë°©ì§€
        df1["event_date"] = df1["event_date"].astype("string").str.strip()
        df1["event_date"] = pd.to_datetime(df1["event_date"], format="%Y. %m. %d", errors="coerce")
        df1["event_date"] = _norm_dt(df1["event_date"])
        df2["event_date"] = df2["event_date"].astype("string").str.strip()
        df2["event_date"] = pd.to_datetime(df2["event_date"], format="%Y. %m. %d", errors="coerce")
        df2["event_date"] = _norm_dt(df2["event_date"])

        # (íŒŒìƒì»¬ëŸ¼) {ì‡¼ë£¸ ìœ í˜•}_{ì‡¼ë£¸ ì§€ì }_{ì‡¼ë£¸ ê¶Œì—­}

        df1 = _parse_shrm_text(df1)
        df2 = _parse_shrm_text(df2)

        # (ë²”ì£¼í™”) ì¹´í…Œê³ ë¦¬ì»¬ ë³€í™˜
        for d in [df1, df2]:
            for c in CAT_COLS:
                if c in d.columns:
                    d[c] = d[c].astype("category")

        # ê¸°ê°„ í•„í„°
        cs_dt = pd.to_datetime(cs, format="%Y%m%d", errors="coerce")
        ce_dt = pd.to_datetime(ce, format="%Y%m%d", errors="coerce")

        for d in [df1, df2]:
            if "event_date" in d.columns:
                d["event_date"] = pd.to_datetime(d["event_date"], errors="coerce")
                d.drop(
                    d[(d["event_date"] < cs_dt) | (d["event_date"] >= ce_dt)].index,
                    inplace=True
                )

        return df1, df2

    with st.spinner("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”."):
        df1, df2 = load_data(cs, ce)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # D) Header
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.subheader("ì‡¼ë£¸ ëŒ€ì‹œë³´ë“œ (ì œì‘ì¤‘)")

    if "refresh" in st.query_params:
        st.cache_data.clear()
        st.query_params.clear()
        st.rerun()

    col1, col2 = st.columns([0.65, 0.35], vertical_alignment="center")
    with col1:
        st.markdown(
            """
            <div style="font-size:14px; line-height:1.5;">
            ëŒ€ì‹œë³´ë“œ ì„¤ëª…  
            </div>
            <div style="color:#6c757d; font-size:14px; line-height:2.0;">
            â€» ì„¤ëª…  
            </div>
            """,
            unsafe_allow_html=True,
        )

    with col2:
        st.markdown(
            """
            <div style="display:flex;justify-content:flex-end;align-items:center;gap:8px;">
            <a href="?refresh=1" title="ìºì‹œ ì´ˆê¸°í™”" style="text-decoration:none;vertical-align:middle;">
                <span style="
                display:inline-flex;align-items:center;justify-content:center;
                height:26px;padding:0 8px;font-size:13px;line-height:1;
                color:#475569;background:#f8fafc;border:1px solid #e2e8f0;
                border-radius:10px;white-space:nowrap;">
                ğŸ—‘ï¸ ìºì‹œ ì´ˆê¸°í™”
                </span>
            </a>
            </div>
            """,
            unsafe_allow_html=True,
        )

    st.divider()


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1) ì¡°íšŒÂ·ì˜ˆì•½Â·ë°©ë¬¸ ì¶”ì´
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown(" ")
    st.markdown("<h5 style='margin:0'>ì‡¼ë£¸ í˜„í™©</h5>", unsafe_allow_html=True)
    st.markdown(":gray-badge[:material/Info: Info]ã…¤ì„¤ëª…", unsafe_allow_html=True)

    # ë°©ë¬¸(df1) + ì¡°íšŒ/ì˜ˆì•½(df2) --> long í†µí•©
    base_cols = [c for c in ["event_date", "shrm_name", "shrm_type", "shrm_region", "shrm_branch"] if c in df1.columns]
    v = df1.loc[:, base_cols].assign(event_type="ë°©ë¬¸", cnt=1)

    m_cols = [c for c in ["look_cnt", "bookConfirmed_cnt"] if c in df2.columns]
    if not m_cols:
        df2["look_cnt"] = 0
        df2["bookConfirmed_cnt"] = 0
        m_cols = ["look_cnt", "bookConfirmed_cnt"]

    m_base_cols = [c for c in ["event_date", "shrm_name", "shrm_type", "shrm_region", "shrm_branch"] if c in df2.columns]
    m = df2.loc[:, m_base_cols + m_cols]
    m[m_cols] = m[m_cols].apply(pd.to_numeric, errors="coerce").fillna(0)

    m = m.melt(
        id_vars=m_base_cols,
        value_vars=m_cols,
        var_name="event_type",
        value_name="cnt",
    )
    m["event_type"] = m["event_type"].replace({"look_cnt": "ì¡°íšŒ", "bookConfirmed_cnt": "ì˜ˆì•½"})
    m["cnt"] = pd.to_numeric(m["cnt"], errors="coerce").fillna(0)

    df_evt = pd.concat([v, m], ignore_index=True)
    df_evt["event_date"] = pd.to_datetime(df_evt["event_date"], errors="coerce").dt.normalize()
    df_evt["event_type"] = df_evt["event_type"].astype(str).str.strip().replace("", "ê¸°íƒ€")
    df_evt["cnt"] = pd.to_numeric(df_evt["cnt"], errors="coerce").fillna(0)

    # âœ… ê³µí†µ í•„í„°
    with st.expander("Filter", expanded=True):
        c1, c2, c3, c4 = st.columns(4)

        def _opts(col, all_label="ì „ì²´"):
            s = df_evt[col].astype("string").fillna("").str.strip().replace("", "ê¸°íƒ€") if col in df_evt.columns else pd.Series([], dtype="string")
            o = sorted(s.dropna().unique().astype(str).tolist())
            return ([all_label] + o) if all_label else o

        evt_opts = _opts("event_type", all_label=None)
        
        # evt_idx = evt_opts.index("ë°©ë¬¸") if "ë°©ë¬¸" in evt_opts else 0
        # with c1: sel_evt    = st.radio("ì´ë²¤íŠ¸", options=evt_opts, index=evt_idx, horizontal=True, key="df_evt_filter__evt")
        
        with c1:
            evt_opts_raw = _opts("event_type", all_label=None)
            _ord = [k for k in ["ì¡°íšŒ","ì˜ˆì•½","ë°©ë¬¸"] if k in evt_opts_raw]
            sel_evt = st.radio("ì´ë²¤íŠ¸", options=_ord, index=_ord.index("ë°©ë¬¸") if "ë°©ë¬¸" in _ord else 0, horizontal=True, key="df_evt_filter__evt")
        with c2: sel_type   = st.selectbox("ì‡¼ë£¸í˜•íƒœ",  _opts("shrm_type"),   0, key="df_evt_filter__type")
        with c3: sel_region = st.selectbox("ì‡¼ë£¸ê¶Œì—­",  _opts("shrm_region"), 0, key="df_evt_filter__region")
        with c4: sel_branch = st.selectbox("ì‡¼ë£¸ì§€ì ",  _opts("shrm_branch"), 0, key="df_evt_filter__branch")

        df_evt_f = df_evt[df_evt["event_type"] == sel_evt]
        for col, val in [("shrm_type", sel_type), ("shrm_region", sel_region), ("shrm_branch", sel_branch)]:
            if val != "ì „ì²´" and col in df_evt_f.columns:
                df_evt_f = df_evt_f[df_evt_f[col].astype(str) == str(val)]


    DIM_MAP = {
        "ì‡¼ë£¸í˜•íƒœ": {
            "pie": "shrm_type",
            "stack_x": "event_date",
            "stack_color": "shrm_type",
            "raw_cols": ["event_date", "shrm_type"],
        },
        "ì‡¼ë£¸ê¶Œì—­": {
            "pie": "shrm_region",
            "stack_x": "event_date",
            "stack_color": "shrm_region",
            "raw_cols": ["event_date", "shrm_region"],
        },
        "ì‡¼ë£¸ì§€ì ": {
            "pie": "shrm_branch",
            "stack_x": "event_date",
            "stack_color": "shrm_branch",
            "raw_cols": ["event_date", "shrm_branch"],
        },
    }

    tabs = st.tabs(list(DIM_MAP.keys()))
    for tab, name in zip(tabs, DIM_MAP.keys()):
        with tab:
            render_shrm_tabs(
                df=df_evt_f,               # í•„í„° ì ìš©
                df_aw=None,
                title=name,
                conf=DIM_MAP[name],
                key_tag="status",          
                agg_mode="sum",            # cnt í•©ê³„
                agg_value_col="cnt",
            )


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 2) Tabs
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.header(" ")
    st.markdown("<h5 style='margin:0'>ë°©ë¬¸ í˜„í™© </h5>", unsafe_allow_html=True)
    st.markdown(":gray-badge[:material/Info: Info]ã…¤ì„¤ëª…")

    # âœ… ê³µí†µ í•„í„°
    with st.expander("Filter", expanded=True):
        f1, f2, f3 = st.columns(3)

        def _opts2(d: pd.DataFrame, col: str, all_label: str = "ì „ì²´"):
            if d is None or d.empty or col not in d.columns:
                return [all_label]
            s = d[col].astype("string").fillna("").str.strip().replace("", "ê¸°íƒ€")
            o = sorted(s.dropna().unique().astype(str).tolist())
            return [all_label] + o

        with f1:
            sel_type2 = st.selectbox("ì‡¼ë£¸í˜•íƒœ", _opts2(df1, "shrm_type"), 0, key="visit_filter__type")
        with f2:
            sel_region2 = st.selectbox("ì‡¼ë£¸ê¶Œì—­", _opts2(df1, "shrm_region"), 0, key="visit_filter__region")
        with f3:
            sel_branch2 = st.selectbox("ì‡¼ë£¸ì§€ì ", _opts2(df1, "shrm_branch"), 0, key="visit_filter__branch")

    # awareness_type: ì½¤ë§ˆ ë©€í‹°ê°’ ë¶„í•´ + weight + (ê´„í˜¸)/(ê´„í˜¸ì œì™¸) ë¶„ë¦¬
    df_aw = None
    if df1 is not None and not df1.empty and "awareness_type" in df1.columns:
        _rid = np.arange(len(df1))
        s = df1["awareness_type"].astype("string").fillna("").astype(str)

        lst = s.apply(lambda x: [t.strip() for t in str(x).split(",") if t.strip()] or ["ê¸°íƒ€"])
        n = lst.apply(len).astype(float).replace(0, 1.0)

        df_aw = df1.assign(_rid=_rid, awareness_type_list=lst, _n=n)
        df_aw = df_aw.explode("awareness_type_list", ignore_index=True)

        df_aw["awareness_type"] = df_aw["awareness_type_list"].astype(str).str.strip()
        df_aw["weight"] = (1.0 / df_aw["_n"]).astype(float)

        df_aw["awareness_type_a"] = (
            df_aw["awareness_type"]
            .astype(str)
            .str.extract(r"\((.*?)\)", expand=False)
            .fillna("ê¸°íƒ€")
            .replace("", "ê¸°íƒ€")
        )
        df_aw["awareness_type_b"] = (
            df_aw["awareness_type"]
            .astype(str)
            .str.replace(r"\(.*?\)", "", regex=True)
            .str.strip()
            .replace("", "ê¸°íƒ€")
        )

        df_aw = df_aw.drop(columns=["awareness_type_list", "_n"])

    # âœ… í•„í„° ì ìš©
    df1_f = df1
    if df1_f is not None and not df1_f.empty:
        for col, val in [("shrm_type", sel_type2), ("shrm_region", sel_region2), ("shrm_branch", sel_branch2)]:
            if val != "ì „ì²´" and col in df1_f.columns:
                df1_f = df1_f[df1_f[col].astype(str) == str(val)]

    df_aw_f = df_aw
    if df_aw_f is not None and not df_aw_f.empty:
        for col, val in [("shrm_type", sel_type2), ("shrm_region", sel_region2), ("shrm_branch", sel_branch2)]:
            if val != "ì „ì²´" and col in df_aw_f.columns:
                df_aw_f = df_aw_f[df_aw_f[col].astype(str) == str(val)]

    DIM_MAP = {
        "ë°©ë¬¸ìœ í˜•": {
            "pie": "visit_type",
            "stack_x": "event_date",
            "stack_color": "visit_type",
            "raw_cols": ["event_date", "visit_type"],
        },
        "ë°ëª¨ê·¸ë˜í”½": {
            "pie": "demo_gender",
            "stack_x": "demo_age",
            "stack_color": "demo_gender",
            "raw_cols": ["event_date", "demo_gender", "demo_age"],
        },
        "ì¸ì§€ë‹¨ê³„": {
            "pie": "awareness_type_a",
            "stack_x": "event_date",
            "stack_color": "awareness_type_a",
            "raw_cols": ["event_date", "awareness_type_a"],
        },
        "ì¸ì§€ì±„ë„": {
            "pie": "awareness_type_b",
            "stack_x": "event_date",
            "stack_color": "awareness_type_b",
            "raw_cols": ["event_date", "awareness_type_b"],
        },
        "êµ¬ë§¤ëª©ì ": {
            "pie": "purchase_purpose",
            "stack_x": "event_date",
            "stack_color": "purchase_purpose",
            "raw_cols": ["event_date", "purchase_purpose"],
        },
    }

    tabs = st.tabs(list(DIM_MAP.keys()))
    for tab, name in zip(tabs, DIM_MAP.keys()):
        with tab:
            render_shrm_tabs(
                df=df1_f,          # âœ… í•„í„° ì ìš©
                df_aw=df_aw_f,      # âœ… í•„í„° ì ìš©
                title=name,
                conf=DIM_MAP[name],
                key_tag="detail",
                agg_mode="size",
                agg_value_col=None,
            )


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 3) CROSS INSIGHT
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.header(" ")
    st.markdown("<h5 style='margin:0'>CROSS INSIGHT </h5>", unsafe_allow_html=True)
    st.markdown(":gray-badge[:material/Info: Info]ã…¤ì„¤ëª… ")

    DIM_OPTS = {
        "ì‡¼ë£¸í˜•íƒœ": "shrm_type",
        "ì‡¼ë£¸ê¶Œì—­": "shrm_region",
        "ì‡¼ë£¸ì§€ì ": "shrm_branch",
        "ë°©ë¬¸ìœ í˜•": "visit_type",
        "ì„±ë³„"   : "demo_gender",
        "ì—°ë ¹ëŒ€" : "demo_age",
        "ì¸ì§€ë‹¨ê³„": "awareness_type_a",
        "ì¸ì§€ì±„ë„": "awareness_type_b",
        "êµ¬ë§¤ëª©ì ": "purchase_purpose",
    }

    with st.expander("Filter", expanded=True):
        cc1, cc2 = st.columns(2)
        with cc1:
            row_label = st.selectbox(
                "ë¶„ì„ ê¸°ì¤€ (*ì„ íƒí•œ í•­ëª©ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë‚˜ëˆ•ë‹ˆë‹¤.)",
                options=list(DIM_OPTS.keys()),
                index=5,
                key="cross_row",
            )
        with cc2:
            col_label = st.selectbox(
                "êµ¬ì„± ê¸°ì¤€ (*ì„ íƒí•œ í•­ëª©ì˜ êµ¬ì„± ë¹„ì¤‘ì„ í‘œì‹œí•©ë‹ˆë‹¤.)",
                options=[k for k in DIM_OPTS.keys() if k != row_label],
                index=7,
                key="cross_col",
            )

    row_col = DIM_OPTS[row_label]
    col_col = DIM_OPTS[col_label]

    has_row = (row_col in df1.columns) or (df_aw is not None and row_col in df_aw.columns)
    has_col = (col_col in df1.columns) or (df_aw is not None and col_col in df_aw.columns)

    if not (has_row and has_col):
        st.warning("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        use_aw = (row_col in AW_COLS) or (col_col in AW_COLS)

        if use_aw:
            if df_aw is None or df_aw.empty:
                st.warning("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                agg = None
            else:
                agg = (
                    df_aw.groupby([row_col, col_col], dropna=False)["weight"]
                    .sum()
                    .reset_index(name="value")
                )
        else:
            agg = df1.groupby([row_col, col_col], dropna=False).size().reset_index(name="value")

        if agg is None or agg.empty:
            st.warning("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            agg[row_col] = _clean_cat(agg[row_col])
            agg[col_col] = _clean_cat(agg[col_col])
            agg["value"] = pd.to_numeric(agg["value"], errors="coerce").fillna(0)

            # âœ… clean í›„ ë¼ë²¨ í•©ì³ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ í‚¤ ê¸°ì¤€ ì¬ì§‘ê³„(ì¤‘ë³µ ì œê±°)
            agg = agg.groupby([row_col, col_col], dropna=False, as_index=False)["value"].sum()

            row_sum = agg.groupby(row_col, dropna=False)["value"].sum().sort_values(ascending=False)
            base_order = row_sum.index.astype(str).tolist()
            etc_in = [k for k in ["ê¸°íƒ€"] if k in base_order]

            if row_col == "demo_age":
                age_order = ["20ëŒ€", "30ëŒ€", "40ëŒ€", "50ëŒ€", "60ëŒ€ ì´ìƒ"]
                row_order = (
                    [x for x in age_order if x in base_order]
                    + [x for x in base_order if (x not in age_order) and (x not in etc_in)]
                    + etc_in
                )
            else:
                row_order = [x for x in base_order if x not in etc_in] + etc_in

            col_sum = agg.groupby(col_col, dropna=False)["value"].sum().sort_values(ascending=False)
            col_order = col_sum.index.astype(str).tolist()
            etc_in_col = [k for k in ["ê¸°íƒ€"] if k in col_order]
            col_order = [x for x in col_order if x not in etc_in_col] + etc_in_col

            agg["_row_sum"] = agg.groupby(row_col, dropna=False)["value"].transform("sum").replace(0, np.nan)
            agg["pct_row"] = (agg["value"] / agg["_row_sum"] * 100).fillna(0)
            agg = agg.drop(columns=["_row_sum"])

            pv_cnt = ui.build_pivot_table(agg, index_col=row_col, col_col=col_col, val_col="value")
            pv_pct = ui.build_pivot_table(agg, index_col=row_col, col_col=col_col, val_col="pct_row")

            pv_cnt = pv_cnt.set_index(row_col).reindex(row_order).reset_index()
            pv_pct = pv_pct.set_index(row_col).reindex(row_order).reset_index()

            cnt_cols = [c for c in pv_cnt.columns if c != row_col]
            cnt_cols = [c for c in col_order if c in cnt_cols]
            pv_cnt = pv_cnt[[row_col] + cnt_cols]

            pct_cols = [c for c in pv_pct.columns if c != row_col]
            pct_cols = [c for c in col_order if c in pct_cols]
            pv_pct = pv_pct[[row_col] + pct_cols]

            
            
            # â”€â”€ ëˆ„ì  ê°€ë¡œë§‰ëŒ€(í–‰=100%)
            import plotly.graph_objects as go  # âœ… ìš”ì²­ëŒ€ë¡œ ì—¬ê¸° ë¸”ë¡ì˜ go importëŠ” ìœ ì§€

            bar = agg[[row_col, col_col, "pct_row"]].copy()
            bar = bar.rename(columns={"pct_row": "pct"})
            bar["pct"] = pd.to_numeric(bar["pct"], errors="coerce").fillna(0)

            fig = go.Figure()

            # âœ… ë²”ë¡€/ê·¸ë˜í”„ ìˆœì„œ ì •í•©: stackì—ì„œ ë³´ì´ëŠ” ì²´ê° ìˆœì„œì— ë§ì¶”ë ¤ë©´ ì—­ìˆœìœ¼ë¡œ ê·¸ë¦¬ê¸°
            # - ë²”ë¡€ëŠ” trace ì¶”ê°€ ìˆœì„œ
            # - stackì—ì„œ ë³´ì´ëŠ” ë¸”ë¡ ìˆœì„œ(ìœ„/ì•„ë˜)ëŠ” ì²´ê°ìƒ ë°˜ëŒ€ë¡œ ëŠê»´ì§ˆ ìˆ˜ ìˆì–´ ì—­ìˆœì´ ë§ëŠ” ê²½ìš°ê°€ ë§ìŒ
            col_order_draw = list(col_order)[::-1]

            for cc in col_order_draw:
                s = (
                    bar[bar[col_col].astype(str) == str(cc)]
                    .groupby(row_col, dropna=False)["pct"]
                    .sum()
                    .reindex(row_order)
                    .fillna(0)
                )

                fig.add_bar(
                    y=row_order,
                    x=s.values,
                    name=str(cc),
                    orientation="h",
                    text=(s.round(0).astype(int).astype(str) + "%").values,
                    textposition="inside",
                    hovertemplate="%{y}<br>%{fullData.name}: %{x:.1f}%<extra></extra>",
                    opacity=0.7,  # opacity
                )

            fig.update_layout(
                barmode="stack",
                height=150 + (len(row_order) * 30),
                margin=dict(l=10, r=10, t=70, b=20),
                xaxis_title=None,
                yaxis_title=None,
                legend=dict(
                    orientation="h",
                    yanchor="bottom",
                    y=1.15,
                    xanchor="right",
                    x=1,
                    title_text="",
                    traceorder="normal",  # âœ… trace ì¶”ê°€ ìˆœì„œ ê·¸ëŒ€ë¡œ
                ),
            )

            fig.update_xaxes(range=[0, 100], ticksuffix="%")
            fig.update_yaxes(categoryorder="array", categoryarray=row_order, autorange="reversed")

            st.plotly_chart(fig, use_container_width=True, key="cross_stack_100")


            pv_show = pv_cnt.copy()
            for cc in [c for c in pv_show.columns if c != row_col]:
                if cc in pv_pct.columns:
                    pv_show[cc] = (
                        pv_cnt[cc].fillna(0).astype(int).astype(str)
                        + " ("
                        + pv_pct[cc].fillna(0).round(0).astype(int).astype(str)
                        + "%)"
                    )

            st.dataframe(pv_show, use_container_width=True, hide_index=True, row_height=30)

            # insight_lines = write_mutable_insight(
            #     agg=agg,
            #     row_col=row_col,
            #     col_col=col_col,
            #     row_label=row_label,
            #     col_label=col_label,
            #     row_order=row_order,
            #     col_order=col_order,
            # )
            # st.write("ì‹œë²”ê¸°ëŠ¥ì…ë‹ˆë‹¤..")
            # st.success("\n".join(insight_lines), icon="âœ…")


if __name__ == "__main__":
    main()
