# SEOHEE
# 2026-02-10 ver.

import streamlit as st
import pandas as pd
import numpy as np
import importlib
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo

import modules.bigquery
importlib.reload(modules.bigquery)
from modules.bigquery import BigQuery

import sys
import modules.style
importlib.reload(sys.modules["modules.style"])
from modules.style import style_format, style_cmap

from google.oauth2.service_account import Credentials
import gspread


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CONFIG
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CFG = {
    # ê¸°ë³¸
    "TZ": "Asia/Seoul",
    "CACHE_TTL": 3600,
    "DEFAULT_LOOKBACK_DAYS": 14,
    "HEADER_UPDATE_AM": 850,
    "HEADER_UPDATE_PM": 1535,

    "TOPK_OPTS": [5, 10, 15, 20],

    "CSS_BLOCK_CONTAINER": """
        <style>
            .block-container {
                max-width: 100% !important;
                padding-top: 1rem;
                padding-bottom: 8rem;
                padding-left: 5rem;
                padding-right: 4rem;
            }
        </style>
    """,
    "CSS_TABS": """
        <style>
            [role="tablist"] [role="tab"] { margin-right: 1rem; }
        </style>
    """,
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CONSTANTS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
HEADER_MAP = {
    "event_date": "ë‚ ì§œ",
    "media_name": "ë§¤ì²´",
    "utm_source": "ì†ŒìŠ¤",
    "utm_medium": "ë¯¸ë””ì—„",
    "brand_type": "ë¸Œëœë“œ",
    "funnel_type": "í¼ë„",
    "product_type": "í’ˆëª©",
    "campaign_name": "ìº í˜ì¸",
    "adgroup_name": "ê´‘ê³ ê·¸ë£¹",
    "ad_name": "ê´‘ê³ ì†Œì¬",
    "keyword_name": "í‚¤ì›Œë“œ",
    "utm_content": "ì»¨í…ì¸ ",
    "utm_term": "ê²€ìƒ‰ì–´",
}

AGG_MAP = dict(
    cost_sum=("cost", "sum"),
    cost_gross_sum=("cost_gross", "sum"),
    impressions_sum=("impressions", "sum"),
    clicks_sum=("clicks", "sum"),
    view_item_sum=("view_item", "sum"),
    product_page_scroll_50_sum=("product_page_scroll_50", "sum"),
    product_option_price_sum=("product_option_price", "sum"),
    find_nearby_showroom_sum=("find_nearby_showroom", "sum"),
    showroom_10s_sum=("showroom_10s", "sum"),
    add_to_cart_sum=("add_to_cart", "sum"),
    showroom_leads_sum=("showroom_leads", "sum"),
    purchase_sum=("purchase", "sum"),
    session_count=("session_start", "sum"),
    engagement_time_msec_sum=("engagement_time_msec_sum", "sum"),
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# main
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # A) Layout / CSS
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown(CFG["CSS_BLOCK_CONTAINER"], unsafe_allow_html=True)
    st.markdown(CFG["CSS_TABS"], unsafe_allow_html=True)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # B) Sidebar (ê¸°ê°„/ë¹„êµê¸°ê°„)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ê¸°ê°„
    st.sidebar.header("Filter")
    today = datetime.now().date()
    default_end = today - timedelta(days=1)
    default_start = today - timedelta(days=CFG["DEFAULT_LOOKBACK_DAYS"])

    start_date, end_date = st.sidebar.date_input(
        "ê¸°ê°„ ì„ íƒ",
        value=[default_start, default_end],
        max_value=default_end,
    )
    cs = start_date.strftime("%Y%m%d")
    ce = end_date.strftime("%Y%m%d")
    
    # ë¹„êµê¸°ê°„
    use_compare = st.sidebar.checkbox("ë¹„êµê¸°ê°„ ì‚¬ìš©")
    period_len = (end_date - start_date).days + 1
    default_comp_e = start_date - timedelta(days=1)
    default_comp_s = default_comp_e - timedelta(days=period_len - 1)

    if use_compare:
        comp_start, comp_end = st.sidebar.date_input(
            "ë¹„êµ ê¸°ê°„ ì„ íƒ",
            value=[default_comp_s, default_comp_e],
            max_value=default_comp_e,
        )

    show_totals = st.sidebar.checkbox("ê¸°ê°„ë³„ í•©ê³„ ë³´ê¸°")

    # ê¸°ê°„ ë¼ë²¨ (í‘œê¸°í˜•ì‹)
    start_date_str = start_date.strftime("%m/%d")
    end_date_str = end_date.strftime("%m/%d")
    default_comp_s_str = default_comp_s.strftime("%m/%d")
    default_comp_e_str = default_comp_e.strftime("%m/%d")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # C) Data Load
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    @st.cache_data(ttl=CFG["CACHE_TTL"])
    def load_data(cs: str, ce: str):
        # 1) tb_media
        bq = BigQuery(projectCode="sleeper", custom_startDate=cs, custom_endDate=ce)
        df_bq = bq.get_data("tb_media")
        df_bq["event_date"] = pd.to_datetime(df_bq["event_date"], format="%Y%m%d", errors="coerce")

        parts = df_bq["campaign_name"].astype(str).str.split("_", n=5, expand=True)
        df_bq["campaign_name_short"] = df_bq["campaign_name"]
        mask = parts[5].notna()
        df_bq.loc[mask, "campaign_name_short"] = (
            parts.loc[mask, :4].apply(lambda r: "_".join(r.dropna().astype(str)), axis=1)
        )

        # 2) Google Sheet
        # secretsê°€ dict/string ì–´ë–¤ í˜•íƒœë“  ì²˜ë¦¬(ì› ì½”ë“œ ë™ì‘ ìœ ì§€)
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive",] 
        try:
            creds = Credentials.from_service_account_file("C:/_code/auth/sleeper-461005-c74c5cd91818.json", scopes=scope)
        except:
            sa_info = st.secrets["sleeper-462701-admin"] 
            if isinstance(sa_info, str):
                import json
                sa_info = json.loads(sa_info)
            creds = Credentials.from_service_account_info(sa_info, scopes=scope)

        gc = gspread.authorize(creds)
        sh = gc.open_by_url("https://docs.google.com/spreadsheets/d/11ov-_o6Lv5HcuZo1QxrKOZnLtnxEKTiV78OFBZzVmWA/edit")
        df_sheet = pd.DataFrame(sh.worksheet("parse").get_all_records())

        # 3) merge
        merged = df_bq.merge(df_sheet, how="left", on="campaign_name_short")

        # [ í•˜ë“œì½”ë”© ì „ì²˜ë¦¬ ] cost_gross(v2) 
        merged["cost_gross"] = np.where(
            merged["event_date"] < pd.to_datetime("2025-11-06"),
            np.where(
                merged["media_name"].isin(["GOOGLE", "META"]),
                merged["cost"] * 1.1 / 0.98,
                merged["cost"],
            ),
            np.where(
                merged["media_name"].isin(["GOOGLE", "META"]),
                merged["cost"] * 1.1 / 0.955,
                merged["cost"],
            ),
        )

        # [ í•˜ë“œì½”ë”© ì „ì²˜ë¦¬ ] handle NSA - ê¸°ì¡´ ë¡œì§ ìœ ì§€
        cond = (
            (merged["media_name"] == "NSA")
            & merged["utm_source"].isna()
            & merged["utm_medium"].isna()
            & merged["media_name_type"].isin(["RSA_AD", "TEXT_45"])
        )
        merged.loc[cond, ["utm_source", "utm_medium"]] = ["naver", "search-nonmatch"]

        # âš ï¸ ì› ì½”ë“œì™€ ë™ì¼: merged.event_dateëŠ” ë¬¸ìì—´ í‘œê¸°ë¡œ ë³€í™˜
        merged["event_date"] = merged["event_date"].dt.strftime("%Y-%m-%d")

        return merged

    with st.spinner("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”."):
        if use_compare:
            cs_cmp = comp_start.strftime("%Y%m%d")
            df_merged = load_data(cs_cmp, ce)

            # ë¹„êµ/ì„ íƒ ë¶„ë¦¬ìš© event_dateë¥¼ datetimeìœ¼ë¡œ ë³µì›(ì› ì½”ë“œ ìœ ì§€)
            df_merged["event_date"] = pd.to_datetime(df_merged["event_date"], errors="coerce")

            df_primary = df_merged[
                (df_merged["event_date"] >= pd.to_datetime(start_date))
                & (df_merged["event_date"] <= pd.to_datetime(end_date))
            ]
            df_compare = df_merged[
                (df_merged["event_date"] >= pd.to_datetime(comp_start))
                & (df_merged["event_date"] <= pd.to_datetime(comp_end))
            ]

            df_filtered = df_primary
            df_filtered_cmp = df_compare
        else:
            df_merged = load_data(cs, ce)
            df_merged["event_date"] = pd.to_datetime(df_merged["event_date"], errors="coerce")
            df_filtered = df_merged
            df_filtered_cmp = None

        # apply_filter_pairì—ì„œ ì˜µì…˜ì€ í•­ìƒ "ì„ íƒê¸°ê°„ ê¸°ì¤€"ì„ ì“°ë¯€ë¡œ ì›ë³¸ ìœ ì§€
        df_primary = df_filtered


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Helpers (ì´ íŒŒì¼ ë‚´ë¶€ì—ì„œë§Œ)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def pivot_perf(df_in: pd.DataFrame, keys: list[str]) -> pd.DataFrame:
        return df_in.groupby(keys, as_index=False).agg(**AGG_MAP)

    def render_decor_perf(df: pd.DataFrame, pivot_cols: list[str]) -> pd.DataFrame:
        df2 = df

        # ìë£Œí˜• ì›Œì‹± 1
        if "event_date" in df2.columns:
            df2 = df2.assign(event_date=pd.to_datetime(df2["event_date"], errors="coerce").dt.strftime("%Y-%m-%d"))

        # íŒŒìƒ ì§€í‘œ ìƒì„±(ì› ë¡œì§ ìœ ì§€)
        df2 = df2.assign(
            CPC=((df2["cost_gross_sum"] / df2["clicks_sum"]).replace([np.inf, -np.inf], 0).fillna(0).round(0)),
            CTR=((df2["clicks_sum"] / df2["impressions_sum"] * 100).replace([np.inf, -np.inf], 0).fillna(0).round(2)),
            session_count_CPA=(df2["cost_gross_sum"] / df2["session_count"]).replace([np.inf, -np.inf], 0).fillna(0).round(0),

            view_item_CPA=(df2["cost_gross_sum"] / df2["view_item_sum"]).replace([np.inf, -np.inf], 0).fillna(0).round(2),
            product_page_scroll_50_CPA=(df2["cost_gross_sum"] / df2["product_page_scroll_50_sum"]).replace([np.inf, -np.inf], 0).fillna(0).round(2),
            product_option_price_CPA=(df2["cost_gross_sum"] / df2["product_option_price_sum"]).replace([np.inf, -np.inf], 0).fillna(0).round(2),
            find_nearby_showroom_CPA=(df2["cost_gross_sum"] / df2["find_nearby_showroom_sum"]).replace([np.inf, -np.inf], 0).fillna(0).round(2),
            showroom_10s_CPA=(df2["cost_gross_sum"] / df2["showroom_10s_sum"]).replace([np.inf, -np.inf], 0).fillna(0).round(2),
            showroom_leads_CPA=(df2["cost_gross_sum"] / df2["showroom_leads_sum"]).replace([np.inf, -np.inf], 0).fillna(0).round(2),
            add_to_cart_CPA=(df2["cost_gross_sum"] / df2["add_to_cart_sum"]).replace([np.inf, -np.inf], 0).fillna(0).round(2),
            purchase_CPA=(df2["cost_gross_sum"] / df2["purchase_sum"]).replace([np.inf, -np.inf], 0).fillna(0).round(2),
        )

        # ìë£Œí˜• ì›Œì‹± 2
        num_cols = df2.select_dtypes(include=["number"]).columns
        if len(num_cols) > 0:
            df2[num_cols] = df2[num_cols].replace([np.inf, -np.inf], np.nan).fillna(0)

        # ì»¬ëŸ¼ ìˆœì„œ
        base_info = ["period", "event_date"]
        pivot_extra = [c for c in pivot_cols if c not in base_info and c in df2.columns]

        metric_cols = [
            "cost_sum", "cost_gross_sum", "impressions_sum", "clicks_sum", "CPC", "CTR",
            "session_count", "session_count_CPA",
            "view_item_sum", "view_item_CPA",
            "product_page_scroll_50_sum", "product_page_scroll_50_CPA",
            "product_option_price_sum", "product_option_price_CPA",
            "find_nearby_showroom_sum", "find_nearby_showroom_CPA",
            "add_to_cart_sum", "add_to_cart_CPA",
            "showroom_10s_sum", "showroom_10s_CPA",
            "showroom_leads_sum", "showroom_leads_CPA",
            "purchase_sum", "purchase_CPA",
        ]

        ordered_cols = [c for c in (base_info + pivot_extra + metric_cols) if c in df2.columns]
        df2 = df2[ordered_cols]

        # ë©€í‹°ì¸ë±ìŠ¤ ì»¬ëŸ¼ ë§µ
        metrics_map_dict = {
            "cost_sum": ("MEDIA", "ê´‘ê³ ë¹„"),
            "cost_gross_sum": ("MEDIA", "ê´‘ê³ ë¹„(G)"),
            "impressions_sum": ("MEDIA", "ë…¸ì¶œìˆ˜"),
            "clicks_sum": ("MEDIA", "í´ë¦­ìˆ˜"),
            "CPC": ("MEDIA", "CPC"),
            "CTR": ("MEDIA", "CTR"),
            "session_count": ("ì „ì²´ ì„¸ì…˜ìˆ˜", "Actual"),
            "session_count_CPA": ("ì „ì²´ ì„¸ì…˜ìˆ˜", "CPA"),
            "view_item_sum": ("PDPì¡°íšŒ", "Actual"),
            "view_item_CPA": ("PDPì¡°íšŒ", "CPA"),
            "product_page_scroll_50_sum": ("PDPscr50", "Actual"),
            "product_page_scroll_50_CPA": ("PDPscr50", "CPA"),
            "product_option_price_sum": ("ê°€ê²©í‘œì‹œ", "Actual"),
            "product_option_price_CPA": ("ê°€ê²©í‘œì‹œ", "CPA"),
            "find_nearby_showroom_sum": ("ì‡¼ë£¸ì°¾ê¸°", "Actual"),
            "find_nearby_showroom_CPA": ("ì‡¼ë£¸ì°¾ê¸°", "CPA"),
            "add_to_cart_sum": ("ì¥ë°”êµ¬ë‹ˆ", "Actual"),
            "add_to_cart_CPA": ("ì¥ë°”êµ¬ë‹ˆ", "CPA"),
            "showroom_10s_sum": ("ì‡¼ë£¸10ì´ˆ", "Actual"),
            "showroom_10s_CPA": ("ì‡¼ë£¸10ì´ˆ", "CPA"),
            "showroom_leads_sum": ("ì‡¼ë£¸ì˜ˆì•½", "Actual"),
            "showroom_leads_CPA": ("ì‡¼ë£¸ì˜ˆì•½", "CPA"),
            "purchase_sum": ("êµ¬ë§¤ì™„ë£Œ", "Actual"),
            "purchase_CPA": ("êµ¬ë§¤ì™„ë£Œ", "CPA"),
        }

        multi_labels: list[tuple[str, str]] = []
        for c in ordered_cols:
            if c == "period":
                multi_labels.append(("ê¸°ë³¸ì •ë³´", "ê¸°ê°„"))
            elif c == "event_date":
                multi_labels.append(("ê¸°ë³¸ì •ë³´", "ë‚ ì§œ"))
            elif c in pivot_extra:
                multi_labels.append(("ê¸°ë³¸ì •ë³´", c))
            else:
                multi_labels.append(metrics_map_dict.get(c, ("ê¸°ë³¸ì •ë³´", c)))

        df2.columns = pd.MultiIndex.from_tuples(multi_labels, names=["ê·¸ë£¹", "ì§€í‘œ"])
        return df2

    def render_style_perf(target_df: pd.DataFrame, pivot_cols: list[str]) -> None:
        styled = style_format(
            render_decor_perf(target_df, pivot_cols),
            decimals_map={
                ("MEDIA", "ê´‘ê³ ë¹„"): 0,
                ("MEDIA", "ê´‘ê³ ë¹„(G)"): 0,
                ("MEDIA", "ë…¸ì¶œìˆ˜"): 0,
                ("MEDIA", "í´ë¦­ìˆ˜"): 0,
                ("MEDIA", "CPC"): 0,
                ("MEDIA", "CTR"): 2,
                ("ì „ì²´ ì„¸ì…˜ìˆ˜", "Actual"): 0,
                ("ì „ì²´ ì„¸ì…˜ìˆ˜", "CPA"): 0,
                ("PDPì¡°íšŒ", "Actual"): 0,
                ("PDPì¡°íšŒ", "CPA"): 0,
                ("PDPscr50", "Actual"): 0,
                ("PDPscr50", "CPA"): 0,
                ("ê°€ê²©í‘œì‹œ", "Actual"): 0,
                ("ê°€ê²©í‘œì‹œ", "CPA"): 0,
                ("ì‡¼ë£¸ì°¾ê¸°", "Actual"): 0,
                ("ì‡¼ë£¸ì°¾ê¸°", "CPA"): 0,
                ("ì¥ë°”êµ¬ë‹ˆ", "Actual"): 0,
                ("ì¥ë°”êµ¬ë‹ˆ", "CPA"): 0,
                ("ì‡¼ë£¸10ì´ˆ", "Actual"): 0,
                ("ì‡¼ë£¸10ì´ˆ", "CPA"): 0,
                ("ì‡¼ë£¸ì˜ˆì•½", "Actual"): 0,
                ("ì‡¼ë£¸ì˜ˆì•½", "CPA"): 0,
                ("êµ¬ë§¤ì™„ë£Œ", "Actual"): 0,
                ("êµ¬ë§¤ì™„ë£Œ", "CPA"): 0,
            },
            suffix_map={
                ("MEDIA", "CTR"): " %",
            },
        )

        styled2 = style_cmap(
            styled,
            gradient_rules=[
                {"col": ("MEDIA", "ë…¸ì¶œìˆ˜"), "cmap": "Blues", "low": 0.0, "high": 0.3},
                {"col": ("MEDIA", "í´ë¦­ìˆ˜"), "cmap": "PuBu", "low": 0.0, "high": 0.3},

                {"col": ("ì „ì²´ ì„¸ì…˜ìˆ˜", "CPA"), "cmap": "OrRd_r", "low": 0.4, "high": -0.3},
                {"col": ("PDPì¡°íšŒ", "CPA"), "cmap": "OrRd_r", "low": 0.4, "high": -0.4},
                {"col": ("PDPscr50", "CPA"), "cmap": "OrRd_r", "low": 0.4, "high": -0.4},
                {"col": ("ê°€ê²©í‘œì‹œ", "CPA"), "cmap": "OrRd_r", "low": 0.3, "high": -0.5},
                {"col": ("ì‡¼ë£¸ì°¾ê¸°", "CPA"), "cmap": "OrRd_r", "low": 0.3, "high": -0.5},
                {"col": ("ì¥ë°”êµ¬ë‹ˆ", "CPA"), "cmap": "OrRd_r", "low": 0.3, "high": -0.6},
                {"col": ("ì‡¼ë£¸10ì´ˆ", "CPA"), "cmap": "OrRd_r", "low": 0.3, "high": -0.6},
                {"col": ("ì‡¼ë£¸ì˜ˆì•½", "CPA"), "cmap": "OrRd_r", "low": 0.3, "high": -0.7},
                {"col": ("êµ¬ë§¤ì™„ë£Œ", "CPA"), "cmap": "OrRd_r", "low": 0.3, "high": -0.7},
            ],
        )
        st.dataframe(styled2, use_container_width=True, height=500, row_height=30, hide_index=True)

    # (26.02.10) í¬í•¨ í•„í„°ì—ì„œ ì •ê·œí‘œí˜„ì‹ í•„í„°ë¡œ ë³€ê²½ 
    def apply_regex_filter(
        df: pd.DataFrame,
        df_cmp: pd.DataFrame | None,
        column: str,
        text_filter: bool = False,
    ) -> tuple[pd.DataFrame, pd.DataFrame | None]:
        key = f"{column}_{'text' if text_filter else 'multi'}"

        # â”€â”€ 1) ì •ê·œì‹(í…ìŠ¤íŠ¸) í•„í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if text_filter:
            expr = st.text_input(
                f"{HEADER_MAP.get(column, column)} ì •ê·œì‹ ê²€ìƒ‰",
                key=key
            )

            if expr:
                s = df[column].astype(str)

                if "&" in expr:
                    terms = [t.strip() for t in expr.split("&") if t.strip()]
                    mask = pd.Series(True, index=df.index)
                    for t in terms:
                        if t.startswith("!"):
                            mask &= ~s.str.contains(t[1:], regex=True, na=False)
                        else:
                            mask &= s.str.contains(t, regex=True, na=False)

                elif "|" in expr:
                    terms = [t.strip() for t in expr.split("|") if t.strip()]
                    mask = pd.Series(False, index=df.index)
                    for t in terms:
                        if t.startswith("!"):
                            mask |= ~s.str.contains(t[1:], regex=True, na=False)
                        else:
                            mask |= s.str.contains(t, regex=True, na=False)

                else:
                    if expr.startswith("!"):
                        mask = ~s.str.contains(expr[1:], regex=True, na=False)
                    else:
                        mask = s.str.contains(expr, regex=True, na=False)

                df = df[mask]

                if df_cmp is not None:
                    s_cmp = df_cmp[column].astype(str)

                    # dfì—ì„œ ë§Œë“  maskë¥¼ ë¹„êµê¸°ê°„ì—ë„ "ë™ì¼ ì¡°ê±´"ìœ¼ë¡œ ì ìš©
                    if "&" in expr:
                        terms = [t.strip() for t in expr.split("&") if t.strip()]
                        mask_cmp = pd.Series(True, index=df_cmp.index)
                        for t in terms:
                            if t.startswith("!"):
                                mask_cmp &= ~s_cmp.str.contains(t[1:], regex=True, na=False)
                            else:
                                mask_cmp &= s_cmp.str.contains(t, regex=True, na=False)

                    elif "|" in expr:
                        terms = [t.strip() for t in expr.split("|") if t.strip()]
                        mask_cmp = pd.Series(False, index=df_cmp.index)
                        for t in terms:
                            if t.startswith("!"):
                                mask_cmp |= ~s_cmp.str.contains(t[1:], regex=True, na=False)
                            else:
                                mask_cmp |= s_cmp.str.contains(t, regex=True, na=False)

                    else:
                        if expr.startswith("!"):
                            mask_cmp = ~s_cmp.str.contains(expr[1:], regex=True, na=False)
                        else:
                            mask_cmp = s_cmp.str.contains(expr, regex=True, na=False)

                    df_cmp = df_cmp[mask_cmp]

            return df, df_cmp

        # â”€â”€ 2) ë©€í‹°ì…€ë ‰íŠ¸ í•„í„°(ê¸°ì¡´ apply_filter_pair ê·¸ëŒ€ë¡œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€
        opts = sorted(df_primary[column].dropna().unique())
        sel = st.multiselect(f"{HEADER_MAP.get(column, column)} í•„í„°", opts, key=key)
        if sel:
            df = df[df[column].isin(sel)]
            if df_cmp is not None:
                df_cmp = df_cmp[df_cmp[column].isin(sel)]
        return df, df_cmp


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # D) Header
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.subheader("í¼í¬ë¨¼ìŠ¤ ëŒ€ì‹œë³´ë“œ")

    if "refresh" in st.query_params:
        st.cache_data.clear()
        st.query_params.clear()
        st.rerun()

    col1, col2 = st.columns([0.65, 0.35], vertical_alignment="center")
    with col1:
        st.markdown(
            """
            <div style="font-size:14px;line-height:1.5;">
            ê´‘ê³  ë§¤ì²´ ë°ì´í„°ì™€ GA í–‰ë™ ë°ì´í„°ë¥¼ ë§¤ì¹­í•˜ì—¬, <b>ìº í˜ì¸Â·ë¸Œëœë“œÂ·í’ˆëª© ë“±</b>ì˜ ê¸°ì¤€ìœ¼ë¡œ
            <b>í¼í¬ë¨¼ìŠ¤ ë§ˆì¼€íŒ… ì„±ê³¼</b>ë¥¼ í†µí•© ë¶„ì„í•  ìˆ˜ ìˆëŠ” ëŒ€ì‹œë³´ë“œì…ë‹ˆë‹¤.<br>
            </div>
            <div style="color:#6c757d;font-size:14px;line-height:2.0;">
            â€» ë§¤ì²´-GA í†µí•© D-1 ë°ì´í„°ëŠ” ë§¤ì¼ 15ì‹œ ~ 16ì‹œ ì‚¬ì´ì— ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.
            </div>
            """,
            unsafe_allow_html=True,
        )

    with col2:
        st.markdown(
            f"""
            <div style="display:flex;justify-content:flex-end;align-items:center;gap:8px;">
            <a href="?refresh=1" title="ìºì‹œ ì´ˆê¸°í™”" style="text-decoration:none;vertical-align:middle;">
                <span style="
                display:inline-flex;align-items:center;justify-content:center;
                height:26px;padding:0 8px;
                font-size:13px;line-height:1;
                color:#475569;background:#f8fafc;border:1px solid #e2e8f0;
                border-radius:10px;white-space:nowrap;">
                ğŸ—‘ï¸ ìºì‹œ ì´ˆê¸°í™”
                </span>
            </a>
            </div>
            """,
            unsafe_allow_html=True,
        )

    st.divider()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1) ì»¤ìŠ¤í…€ ë¦¬í¬íŠ¸
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown(" ")
    st.markdown("<h5 style='margin:0'>ë§¤ì²´-GA í†µí•© ë¦¬í¬íŠ¸</h5>", unsafe_allow_html=True)
    st.markdown(
        ":gray-badge[:material/Info: Info]ã…¤**í–‰ í•„ë“œ**ëŠ” ë°ì´í„°ë¥¼ ì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ êµ¬ë¶„í•´ ë³¼ì§€ ì •í•˜ëŠ” ê¸°ëŠ¥ì´ë©°, **í•„í„°**ë¡œ ì›í•˜ëŠ” ì¡°ê±´ë§Œ ì„ íƒí•´ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",    
        unsafe_allow_html=True,
    )
        
    with st.popover("ğŸ¤” ê³ ê¸‰í•„í„° ì •ê·œì‹ ì‚¬ìš© ë°©ë²•"):
        st.markdown("""
    - **ë‹¨ì¼ ì…ë ¥**  
    ì…ë ¥í•œ ë‹¨ì–´/íŒ¨í„´ì„ **í¬í•¨**í•˜ëŠ” ê°’ì„ ì°¾ìŠµë‹ˆë‹¤.  
    ì˜ˆ) `ìŠ¬ë¦½í¼` : ìŠ¬ë¦½í¼ ìº í˜ì¸ë§Œ ì¡°íšŒ  
    ì˜ˆ) `low` : low í¼ë„ ìº í˜ì¸ë§Œ ì¡°íšŒ  

    - **OR (`|`)**  
    ì—¬ëŸ¬ íŒ¨í„´ ì¤‘ **í•˜ë‚˜ë¼ë„ í¬í•¨**í•˜ë©´ ë§¤ì¹­ë©ë‹ˆë‹¤.  
    ì˜ˆ) `ìŠ¤í…Œì´ë¸”|ì‹œê·¸ë‹ˆì²˜` : ìŠ¤í…Œì´ë¸” ë˜ëŠ” ì‹œê·¸ë‹ˆì²˜ í¬í•¨

    - **AND (`&`)**  
    ì…ë ¥í•œ **ëª¨ë“  íŒ¨í„´ì´ í¬í•¨**ë˜ì–´ì•¼ ë§¤ì¹­ë©ë‹ˆë‹¤.  
    ì˜ˆ) `low&ì‹œê·¸ë‹ˆì²˜` : lowë„ ìˆê³  ì‹œê·¸ë‹ˆì²˜ë„ ìˆëŠ” ê°’

    - **ì œì™¸ (`!`)**  
    `!íŒ¨í„´`ì€ í•´ë‹¹ íŒ¨í„´ì„ **ì œì™¸**í•©ë‹ˆë‹¤.  
    ì˜ˆ) `!ëˆ„ì–´` : ëˆ„ì–´ í¬í•¨ëœ ê°’ ì œì™¸  
    ì˜ˆ) `ìŠ¬ë¦½í¼&!í”„ë¡œëª¨ì…˜` : ìŠ¬ë¦½í¼ ì¤‘ í”„ë¡œëª¨ì…˜ ì œì™¸  

    - ì—¬ëŸ¬ ê¸°í˜¸ë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ê±°ë‚˜, ê¸°ë³¸ ì •ê·œí‘œí˜„ì‹ ë¬¸ë²•ë„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.  
    ì˜ˆ) `^BSA` : BSAë¡œ ì‹œì‘   
    ì˜ˆ) `MO$` : MOë¡œ ë  
    ì˜ˆ) `ìŠ¬ë¦½í¼&(í—ˆì‰¬|ì‹œê·¸)` : ìŠ¬ë¦½í¼ í—ˆì‰¬ ë˜ëŠ” ìŠ¬ë¦½í¼ ì‹œê·¸ë‹ˆì²˜  
    ì˜ˆ) `ëˆ„ì–´&low&!ë§¤íŠ¸ë¦¬ìŠ¤` : ëˆ„ì–´ low ì¤‘ ë§¤íŠ¸ë¦¬ìŠ¤ë§Œ ì œì™¸  
    """)


    st.markdown(" ")

    pivot_cols = st.multiselect(
        "í–‰ í•„ë“œ ì„ íƒ",
        options=list(HEADER_MAP.keys()),
        default=["event_date"],
        format_func=lambda x: HEADER_MAP.get(x, x),
    )

    # ê¸°ê°„ë³„ í•©ê³„ ë³´ê¸° ëª¨ë“œë¼ë©´ event_date ëŠ” ë¬´ì‹œ
    if show_totals and "event_date" in pivot_cols:
        pivot_cols.remove("event_date")
        st.caption("ê¸°ê°„ë³„ í•©ê³„ ë³´ê¸° ì„ íƒì‹œ, ë‚ ì§œëŠ” ìë™ìœ¼ë¡œ ì œì™¸ë©ë‹ˆë‹¤.")

    # í•„í„°
    with st.expander("ê¸°ë³¸ í•„í„°", expanded=False):
        ft1, ft2, ft3, ft4, ft5, ft6 = st.columns(6)
        with ft1:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "media_name", text_filter=False)
        with ft2:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "utm_source", text_filter=False)
        with ft3:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "utm_medium", text_filter=False)
        with ft4:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "brand_type", text_filter=False)
        with ft5:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "funnel_type", text_filter=False)
        with ft6:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "product_type", text_filter=False)

    with st.expander("ê³ ê¸‰ í•„í„°", expanded=False):
        ft7, ft8, ft9, ft10 = st.columns([2, 1, 2, 1])
        with ft7:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "campaign_name", text_filter=False)
        with ft8:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "campaign_name", text_filter=True)
        with ft9:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "adgroup_name", text_filter=False)
        with ft10:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "adgroup_name", text_filter=True)

        ft11, ft12, ft13, ft14 = st.columns([2, 1, 2, 1])
        with ft11:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "ad_name", text_filter=False)
        with ft12:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "ad_name", text_filter=True)
        with ft13:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "keyword_name", text_filter=False)
        with ft14:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "keyword_name", text_filter=True)

        ft15, ft16, ft17, ft18 = st.columns([2, 1, 2, 1])
        with ft15:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "utm_content", text_filter=False)
        with ft16:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "utm_content", text_filter=True)
        with ft17:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "utm_term", text_filter=False)
        with ft18:
            df_filtered, df_filtered_cmp = apply_regex_filter(df_filtered, df_filtered_cmp, "utm_term", text_filter=True)


    # ------------------------------
    # í‘œ (pivot)
    # ------------------------------
    if pivot_cols or show_totals:
        if show_totals:
            df_sel = df_filtered.assign(period=f"{start_date_str} ~ {end_date_str}")

            if use_compare:
                df_cmp = df_filtered_cmp.assign(period=f"{default_comp_s_str} ~ {default_comp_e_str}")
                df_combined = pd.concat([df_sel, df_cmp], ignore_index=True)
            else:
                df_combined = df_sel

            group_keys = ["period"] + pivot_cols
            df_pivot = pivot_perf(df_combined, group_keys)
            render_style_perf(df_pivot, group_keys)


        else:
            df_sel = pivot_perf(df_filtered, pivot_cols).assign(period=f"{start_date_str} ~ {end_date_str}")

            if use_compare:
                df_cmp = pivot_perf(df_filtered_cmp, pivot_cols).assign(period=f"{default_comp_s_str} ~ {default_comp_e_str}")
                df_pivot = pd.concat([df_sel, df_cmp], ignore_index=True)
            else:
                df_pivot = df_sel

            render_style_perf(df_pivot, ["period"] + pivot_cols)


    else:
        st.warning("í”¼ë²—í•  í–‰ í•„ë“œë¥¼ í•˜ë‚˜ ì´ìƒ ì„ íƒí•´ ì£¼ì„¸ìš”.")



if __name__ == "__main__":
    main()
