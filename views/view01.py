# ì„œí¬_ìµœì‹ ìˆ˜ì •ì¼_25-08-19

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import importlib
from datetime import datetime, timedelta
import modules.bigquery
importlib.reload(modules.bigquery)
from modules.bigquery import BigQuery
from st_aggrid import AgGrid, GridOptionsBuilder
from st_aggrid.shared import JsCode
import io
from google.oauth2.service_account import Credentials
import gspread
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import math

import sys
import modules.style
importlib.reload(sys.modules['modules.style'])
from modules.style import style_format, style_cmap
from pandas.tseries.offsets import MonthEnd


def main():
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ìŠ¤íŠ¸ë¦¼ë¦¿ í˜ì´ì§€ ì„¤ì •
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    st.markdown(
        """
        <style>
            /* ì „ì²´ ì»¨í…Œì´ë„ˆì˜ íŒ¨ë”© ì¡°ì • */
            .block-container {
                max-width: 100% !important;
                padding-top: 4rem;   /* ìœ„ìª½ ì—¬ë°± */
                padding-bottom: 8rem;
                padding-left: 5rem; 
                padding-right: 4rem; 
            }
        </style>
        """,
        unsafe_allow_html=True
    )    

    st.subheader('ë§¤ì¶œ ì¢…í•© ëŒ€ì‹œë³´ë“œ')
    st.markdown(
        """
        <div style="
            color:#6c757d;        /* ê¸€ì ìƒ‰ (íšŒìƒ‰í†¤) */
            font-size:14px;       /* ê¸€ì í¬ê¸° */
            line-height:1.5;      /* ì¤„ê°„ê²© */
        ">
        ì´ ëŒ€ì‹œë³´ë“œëŠ” <b>ë§¤ì¶œ Â· ë§¤ì²´ Â· ìœ ì…</b> ë°ì´í„°ë¥¼ ì¼ìë³„ë¡œ í•œëˆˆì— ë³´ì—¬ì£¼ëŠ” 
        <b>ê°€ì¥ ê°œê´„ì ì¸ ëŒ€ì‹œë³´ë“œ</b>ì…ë‹ˆë‹¤.<br>
        ì—¬ê¸°ì„œëŠ” <b>"ì–¼ë§ˆ ë²Œì—ˆê³ , ì–¼ë§ˆ ì¼ê³ , ì–¼ë§ˆ ìœ ì…ëê³ "</b>ë¥¼ 
        íš¨ìœ¨ ì§€í‘œì™€ í•¨ê»˜ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        </div>
        """,
        unsafe_allow_html=True
    )
    st.divider()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì‚¬ì´ë“œë°” í•„í„° ì„¤ì •
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.sidebar.header("Filter")
    
    today = datetime.now().date()
    default_end = today - timedelta(days=1)
    default_start = today - timedelta(days=7)
    start_date, end_date = st.sidebar.date_input(
        "ê¸°ê°„ ì„ íƒ",
        value=[default_start, default_end],
        max_value=default_end
    )
    cs = start_date.strftime("%Y%m%d")
    ce = end_date.strftime("%Y%m%d")

    @st.cache_data(ttl=3600)
    def load_data(cs: str, ce: str) -> pd.DataFrame:
        
        # 1) tb_media
        bq = BigQuery(projectCode="sleeper", custom_startDate=cs, custom_endDate=ce)
        df_bq = bq.get_data("tb_media")
        df_bq["event_date"] = pd.to_datetime(df_bq["event_date"], format="%Y%m%d")
        parts = df_bq['campaign_name'].str.split('_', n=5, expand=True)
        df_bq['campaign_name_short'] = df_bq['campaign_name']
        mask = parts[5].notna()
        df_bq.loc[mask, 'campaign_name_short'] = (
            parts.loc[mask, :4].apply(lambda r: '_'.join(r.dropna().astype(str)), axis=1)
        )
        # 2) Google Sheet
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        
        try: 
            creds = Credentials.from_service_account_file("C:/_code/auth/sleeper-461005-c74c5cd91818.json", scopes=scope)
        except: # ë°°í¬ìš© (secrets.toml)
            sa_info = st.secrets["sleeper-462701-admin"]
            if isinstance(sa_info, str):  # í˜¹ì‹œ ë¬¸ìì—´(JSON)ë¡œ ì €ì¥í–ˆì„ ê²½ìš°
                sa_info = json.loads(sa_info)
            creds = Credentials.from_service_account_info(sa_info, scopes=scope)
            
        gc = gspread.authorize(creds)
        sh = gc.open_by_url('https://docs.google.com/spreadsheets/d/11ov-_o6Lv5HcuZo1QxrKOZnLtnxEKTiV78OFBZzVmWA/edit')
        df_sheet = pd.DataFrame(sh.worksheet('parse').get_all_records())
        
        # merge (1+2)
        merged = df_bq.merge(df_sheet, how='left', on='campaign_name_short')
        # cost_gross
        merged['cost_gross'] = np.where(
            merged['media_name'].isin(['GOOGLE','META']), merged['cost']*1.1/0.98, merged['cost']
        )
        # handle NSA
        cond = (
            (merged['media_name']=='NSA') & merged['utm_source'].isna() &
            merged['utm_medium'].isna() & merged['media_name_type'].isin(['RSA_AD','TEXT_45'])
        )
        merged.loc[cond, ['utm_source','utm_medium']] = ['naver','search-nonmatch']
        
        # 3) tb_sleeper_psi
        df_psi = bq.get_data("tb_sleeper_psi")
        df_psi["event_date"] = pd.to_datetime(df_psi["event_date"], format="%Y%m%d")
        df_psi = (df_psi
                .assign(event_date=pd.to_datetime(df_psi["event_date"], format="%Y%m%d"))
                .groupby("event_date", as_index=False)
                .agg(session_count=("pseudo_session_id", "nunique")))

        return merged, df_psi

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.toast("GA D-1 ë°ì´í„°ëŠ” ì˜¤ì „ì— ì˜ˆë¹„ ì²˜ë¦¬ë˜ê³ , **15ì‹œ ì´í›„ì— ìµœì¢… ì—…ë°ì´íŠ¸** ë©ë‹ˆë‹¤.", icon="ğŸ””")

    with st.spinner("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”."):
        df_merged, df_psi = load_data(cs, ce)
    

    # ê³µí†µí•©ìˆ˜ (1) ì¼ìë³„ ê´‘ê³ ë¹„, ì„¸ì…˜ìˆ˜ (íŒŒìƒë³€ìˆ˜ëŠ” í•´ë‹¹ í•¨ìˆ˜ê°€ ê³„ì‚°í•˜ì§€ ì•ŠìŒ -> ë‚˜ì¤‘ì— ê³„ì‚°í•¨)
    def pivot_cstSes(
        df: pd.DataFrame,
        brand_type: str | None = None,
        product_type: str | None = None
        ) -> pd.DataFrame:
        """
        1) í•¨ìˆ˜ ì‘ì„±
        :  pivot_cstSes(df, brand_type="ìŠ¬ë¦½í¼", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
        2) ê²°ê³¼ ì»¬ëŸ¼
        :  ['event_date', 'session_count', 'cost_gross_sum']
        """
        df_f = df.copy()

        if brand_type:
            df_f = df_f[df_f['brand_type'].astype(str).str.contains(brand_type, regex=True, na=False)]
        if product_type:
            df_f = df_f[df_f['product_type'].astype(str).str.contains(product_type, regex=True, na=False)]

        df_f['event_date'] = pd.to_datetime(df_f['event_date'], errors='coerce')
        df_f['event_date'] = df_f['event_date'].dt.strftime('%Y-%m-%d')

        pivot = (
            df_f
            .groupby('event_date', as_index=False) # ë°˜ë“œì‹œ Falseë¡œ ìœ ì§€ (ê·¸ë˜ì•¼ ì»¬ëŸ¼ì— ì‚´ì•„ìˆìŒ)
            .agg(
                session_count=('pseudo_session_id', 'sum'),
                cost_gross_sum=('cost_gross', 'sum')
            )
            .reset_index(drop=True)
        )
        return pivot


    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    
    try: 
        creds = Credentials.from_service_account_file("C:/_code/auth/sleeper-461005-c74c5cd91818.json", scopes=scope)
    except: # ë°°í¬ìš© (secrets.toml)
        sa_info = st.secrets["sleeper-462701-admin"]
        if isinstance(sa_info, str):  # í˜¹ì‹œ ë¬¸ìì—´(JSON)ë¡œ ì €ì¥í–ˆì„ ê²½ìš°
            sa_info = json.loads(sa_info)
        creds = Credentials.from_service_account_info(sa_info, scopes=scope)

    
    gc = gspread.authorize(creds)
    sh = gc.open_by_url('https://docs.google.com/spreadsheets/d/1chXeCek1UZPyCr18zLe7lV-8tmv6YPWK6cEqAJcDPqs/edit')
    df_order = pd.DataFrame(sh.worksheet('ì˜¨ì˜¤í”„ë¼ì¸_ì¢…í•©').get_all_records())
    df_order = df_order.rename(columns={"íŒë§¤ìˆ˜ëŸ‰": "ì£¼ë¬¸ìˆ˜"})  # ì»¬ëŸ¼ ì´ë¦„ ì¹˜í™˜
    def convert_dot_date(x):
        try:
            # 1. ë¬¸ìì—´ë¡œ ë³€í™˜ + ê³µë°± ì œê±°
            s = str(x).replace(" ", "")
            # 2. ë§ˆì¹¨í‘œ ê¸°ì¤€ split
            parts = s.split(".")
            if len(parts) == 3:
                y = parts[0]
                m = parts[1].zfill(2)
                d = parts[2].zfill(2)
                return pd.to_datetime(f"{y}-{m}-{d}", format="%Y-%m-%d", errors="coerce")
            return pd.NaT
        except:
            return pd.NaT
    df_order["ì£¼ë¬¸ì¼"] = pd.to_datetime(df_order["ì£¼ë¬¸ì¼"].apply(convert_dot_date), format="%Y-%m-%d", errors="coerce")
    df_order["ì‹¤ê²°ì œê¸ˆì•¡"] = pd.to_numeric(df_order["ì‹¤ê²°ì œê¸ˆì•¡"], errors='coerce')
    df_order["ì£¼ë¬¸ìˆ˜"] = pd.to_numeric(df_order["ì£¼ë¬¸ìˆ˜"], errors='coerce')
    df_order = df_order.dropna(subset=["ì£¼ë¬¸ì¼"])


    # ê³µí†µí•©ìˆ˜ (2) ì¼ìë³„ ë§¤ì¶œ, ì£¼ë¬¸ìˆ˜ (íŒŒìƒë³€ìˆ˜ëŠ” í•´ë‹¹ í•¨ìˆ˜ê°€ ê³„ì‚°í•˜ì§€ ì•ŠìŒ)
    def pivot_ord(
        df: pd.DataFrame,
        brand_type: str | None = None,
        product_type: str | None = None
        ) -> pd.DataFrame:
        """
        1) í•¨ìˆ˜ ì‘ì„±
        :  pivot_ord(df, brand_type="ìŠ¬ë¦½í¼", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
        2) ê²°ê³¼ ì»¬ëŸ¼
        :  ['ì£¼ë¬¸ì¼', 'ord_amount_sum', 'ord_count_sum']
        
        """
        df_f = df.copy()

        if brand_type:
            df_f = df_f[df_f['ë¸Œëœë“œ'].astype(str).str.contains(brand_type, regex=True, na=False)]
        if product_type:
            df_f = df_f[df_f['ì¹´í…Œê³ ë¦¬'].astype(str).str.contains(product_type, regex=True, na=False)]
            
        df_f['ì£¼ë¬¸ì¼'] = pd.to_datetime(df_f['ì£¼ë¬¸ì¼'], errors='coerce')
        df_f['ì£¼ë¬¸ì¼'] = df_f['ì£¼ë¬¸ì¼'].dt.strftime('%Y-%m-%d')

        pivot = (
            df_f
            .groupby('ì£¼ë¬¸ì¼', as_index=False) # ë°˜ë“œì‹œ Falseë¡œ ìœ ì§€ (ê·¸ë˜ì•¼ ì»¬ëŸ¼ì— ì‚´ì•„ìˆìŒ)
            .agg(
                ord_amount_sum=('ì‹¤ê²°ì œê¸ˆì•¡', 'sum'),
                ord_count_sum=('ì£¼ë¬¸ìˆ˜', 'sum')
            )
            .reset_index(drop=True)
        )
        return pivot

    def summary_row(df):
        sum_row = df.iloc[:, 1:].sum(numeric_only=True)
        avg_row = df.iloc[:, 1:].mean(numeric_only=True)

        # í•©ê³„/í‰ê·  í–‰ DataFrame
        summary = pd.DataFrame([
            ["í•©ê³„"] + sum_row.astype(int).tolist(),
            ["í‰ê· "] + avg_row.round(1).tolist()
        ], columns=df.columns)
        
        return summary



    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë°ì´í„°í”„ë ˆì„ ìƒì„± (JOINì¸ ê²½ìš°ëŠ” ê³ ì˜ë¡œ "ì£¼ë¬¸ì¼" ì»¬ëŸ¼ ë–¨êµ´ ëª©ì )
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1-1) ìŠ¬ë¦½í¼
    _sctSes_slp      = pivot_cstSes(df_merged, brand_type="ìŠ¬ë¦½í¼")
    _ord_slp         = pivot_ord(df_order,     brand_type="ìŠ¬ë¦½í¼")
    df_slp           = _sctSes_slp.join(_ord_slp.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')
    
    # 1-2) ìŠ¬ë¦½í¼ & ë§¤íŠ¸ë¦¬ìŠ¤
    _sctSes_slp_mat  = pivot_cstSes(df_merged, brand_type="ìŠ¬ë¦½í¼", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
    _ord_slp_mat     = pivot_ord(df_order,     brand_type="ìŠ¬ë¦½í¼", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
    df_slp_mat       = _sctSes_slp_mat.join(_ord_slp_mat.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')
    
    # 1-3) ìŠ¬ë¦½í¼ & í”„ë ˆì„
    _sctSes_slp_frm  = pivot_cstSes(df_merged, brand_type="ìŠ¬ë¦½í¼", product_type="í”„ë ˆì„")
    _ord_slp_frm     = pivot_ord(df_order,     brand_type="ìŠ¬ë¦½í¼", product_type="í”„ë ˆì„")
    df_slp_frm       = _sctSes_slp_frm.join(_ord_slp_frm.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')
    
    # 2-1) ëˆ„ì–´ 
    _sctSes_nor      = pivot_cstSes(df_merged, brand_type="ëˆ„ì–´")
    _ord_nor         = pivot_ord(df_order,     brand_type="ëˆ„ì–´")
    df_nor           = _sctSes_nor.join(_ord_nor.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')
    
    # 2-2) ëˆ„ì–´ & ë§¤íŠ¸ë¦¬ìŠ¤
    _sctSes_nor_mat  = pivot_cstSes(df_merged, brand_type="ëˆ„ì–´", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
    _ord_nor_mat     = pivot_ord(df_order,     brand_type="ëˆ„ì–´", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
    df_nor_mat       = _sctSes_nor_mat.join(_ord_nor_mat.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')
    
    # 2-3) ëˆ„ì–´ & í”„ë ˆì„
    _sctSes_nor_frm  = pivot_cstSes(df_merged, brand_type="ëˆ„ì–´", product_type="í”„ë ˆì„")
    _ord_nor_frm     = pivot_ord(df_order,     brand_type="ëˆ„ì–´", product_type="í”„ë ˆì„")
    df_nor_frm       = _sctSes_nor_frm.join(_ord_nor_frm.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')
    
    # 3) í†µí•© ë°ì´í„° (3ë²ˆ ì´ì§€ë§Œ, ìœ„ì¹˜ìƒ ìµœìƒìœ„ì— ìœ„ì¹˜í•¨ ì£¼ì˜)
    _df_total_psi    = df_psi  # ì´ë¯¸ ë‚ ì§œë³„ë¡œ ì„¸ì…˜ìˆ˜ê°€ í”¼ë²—ë˜ì–´ ìˆëŠ” ë°ì´í„°í”„ë ˆì„
    _df_total_cost   = df_merged.groupby('event_date', as_index=False).agg(cost_gross_sum=('cost_gross','sum')).sort_values('event_date')  # df_mergedì—ì„œ cost_grossë§Œ ê°€ì ¸ì˜´
    _df_total_order  = df_order.groupby('ì£¼ë¬¸ì¼', as_index=False).agg(ord_amount_sum=('ì‹¤ê²°ì œê¸ˆì•¡','sum'), ord_count_sum  =('ì£¼ë¬¸ìˆ˜', 'sum')).sort_values('ì£¼ë¬¸ì¼')
    _df_total_order  = _df_total_order.rename(columns={'ì£¼ë¬¸ì¼':'event_date'}) # ì£¼ë¬¸ì¼ -> event_date
    df_total = (_df_total_psi
                .merge(_df_total_cost,  on='event_date', how='left')
                .merge(_df_total_order, on='event_date', how='left')
                )

    
    # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ì´ ë™ì¼í•œ íŒŒìƒ ì§€í‘œë¥¼ ê°€ì§
    def decorate_df(df: pd.DataFrame) -> pd.DataFrame:
        # í‚¤ì—ëŸ¬ ë°©ì§€
        required = ["event_date", "ord_amount_sum", "ord_count_sum", "cost_gross_sum", "session_count"]
        for c in required:
            if c not in df.columns:
                df[c] = 0  
        num_cols = ["ord_amount_sum", "ord_count_sum", "cost_gross_sum", "session_count"]
        df[num_cols] = df[num_cols].apply(pd.to_numeric, errors="coerce").fillna(0)
            
        # íŒŒìƒì§€í‘œ ìƒì„±
        df['CVR']    =  (df['ord_count_sum']  / df['session_count']  * 100).round(2)
        df['AOV']    =  (df['ord_amount_sum'] / df['ord_count_sum']  ).round(0)
        df['ROAS']   =  (df['ord_amount_sum'] / df['cost_gross_sum'] * 100).round(2)
        
        # ì»¬ëŸ¼ ìˆœì„œ ì§€ì •
        df = df[['event_date','ord_amount_sum','ord_count_sum','AOV','cost_gross_sum','ROAS','session_count','CVR']]
        
        # ìë£Œí˜• ì›Œì‹±
        df['event_date'] = pd.to_datetime(df['event_date'], errors='coerce').dt.strftime('%Y-%m-%d')
        num_cols = df.select_dtypes(include=['number']).columns
        df[num_cols] = (df[num_cols].replace([np.inf, -np.inf], np.nan).fillna(0))        

        # ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½ - ë‹¨ì¼ ì¸ë±ìŠ¤
        # rename_map = {
        #     "event_date":       "ë‚ ì§œ",
        #     "ord_amount_sum":   "ë§¤ì¶œ",
        #     "ord_count_sum":    "ì£¼ë¬¸ìˆ˜",
        #     "AOV":              "AOV(í‰ê· ì£¼ë¬¸ê¸ˆì•¡)",
        #     "cost_gross_sum":   "ê´‘ê³ ë¹„",
        #     "ROAS":             "ROAS(ê´‘ê³ ìˆ˜ìµë¥ )",
        #     "session_count":    "ì„¸ì…˜ìˆ˜",
        #     "CVR":              "CVR(ì „í™˜ìœ¨)",
        # }
        # apply_map = {k: v for k, v in rename_map.items() if k in df.columns}
        # df = df.rename(columns=apply_map)
        
        # í•©ê³„ & í‰ê·  í–‰ ì¶”ê°€
        sum_row = df[num_cols].sum().to_frame().T
        sum_row['event_date'] = "í•©ê³„"
        mean_row = df[num_cols].mean().to_frame().T
        mean_row['event_date'] = "í‰ê· "
        df = pd.concat([df, sum_row, mean_row], ignore_index=True)

        # ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½ - ë©€í‹° ì¸ë±ìŠ¤
        df.columns = pd.MultiIndex.from_tuples([
            ("ê¸°ë³¸ì •ë³´",      "ë‚ ì§œ"),              # event_date
            ("COST",        "ë§¤ì¶œ"),               # ord_amount_sum
            ("COST",        "ì£¼ë¬¸ìˆ˜"),             # ord_count_sum
            ("COST",        "AOV"),    # AOV
            ("MEDIA", "ê´‘ê³ ë¹„"),              # cost_gross_sum
            ("MEDIA", "ROAS"),     # ROAS
            ("GA",          "ì„¸ì…˜ìˆ˜"),              # session_count
            ("GA",          "CVR"),          # CVR
        ], names=["ê·¸ë£¹","ì§€í‘œ"])  # ìƒë‹¨ ë ˆë²¨ ì´ë¦„(ì˜µì…˜)        
        
        return df

    def render_style(target_df):
        styled = style_format(
            decorate_df(target_df),
            decimals_map={
                ("COST",        "ë§¤ì¶œ"): 0,
                ("COST",        "ì£¼ë¬¸ìˆ˜"): 0,
                ("COST",        "AOV"): 0,
                ("MEDIA", "ê´‘ê³ ë¹„"): 0,
                ("MEDIA", "ROAS"): 1,
                ("GA",          "ì„¸ì…˜ìˆ˜"): 0,
                ("GA",          "CVR"): 1,
            },
            suffix_map={
                ("MEDIA", "ROAS"): " %",
                ("GA",          "CVR"): " %",
        }
        )
        styled2 = style_cmap(
            styled,
            gradient_rules=[
                {"col": ("COST",   "ë§¤ì¶œ"), "cmap":"Greens", "low":0.0, "high":0.3},
                {"col": ("MEDIA", "ê´‘ê³ ë¹„"), "cmap":"Blues", "low":0.0, "high":0.3},
                {"col": ("GA",          "ì„¸ì…˜ìˆ˜"), "cmap":"OrRd",  "low":0.0, "high":0.3},

            ],
        )
        st.dataframe(styled2, use_container_width=True, hide_index=True, row_height=30)


# height=410, 
        
    # def render_aggrid(
    #     df: pd.DataFrame,
    #     height: int = 323,
    #     use_parent: bool = True
    #     ) -> None:
    #     """
    #     use_parent: False / True
    #     """
    #     df2 = df.copy()
    #     df2.fillna(0, inplace=True)     # ê°’ì´ ì—†ëŠ” ê²½ìš° ì¼ë‹¨ 0ìœ¼ë¡œ ì¹˜í™˜
        
    #     # ì „ì²˜ë¦¬ ì˜ì—­ (íŒŒìƒì§€í‘œ ìƒì„±, ì»¬ëŸ¼ìˆœì„œ ì§€ì •)
    #     df2['CVR']  = (df2['ord_count_sum']  / df2['session_count']  * 100).round(2)
    #     df2['AOV']  = (df2['ord_amount_sum'] / df2['ord_count_sum']  ).round(0)
    #     df2['ROAS'] = (df2['ord_amount_sum'] / df2['cost_gross_sum'] * 100).round(2)
    #     df2 = df2[['event_date','ord_amount_sum','ord_count_sum','AOV','cost_gross_sum','ROAS','session_count','CVR']]
        
    #     # (í•„ìˆ˜í•¨ìˆ˜) make_num_child
    #     def make_num_child(header, field, fmt_digits=0, suffix=''):
    #         return {
    #             "headerName": header, "field": field,
    #             "type": ["numericColumn","customNumericFormat"],
    #             "valueFormatter": JsCode(
    #                 f"function(params){{"
    #                 f"  return params.value!=null?"
    #                 f"params.value.toLocaleString(undefined,{{minimumFractionDigits:{fmt_digits},maximumFractionDigits:{fmt_digits}}})+'{suffix}':'';"
    #                 f"}}"
    #             ),
    #             "cellStyle": JsCode("params=>({textAlign:'right'})")
    #         }

    #     # (í•„ìˆ˜í•¨ìˆ˜) add_summary - deprecated !!
    #     # def add_summary(grid_options: dict, df: pd.DataFrame, agg_map: dict[str, str]): #'sum'|'avg'|'mid'
    #     #     summary: dict[str, float] = {}
    #     #     for col, op in agg_map.items():
    #     #         if op == 'sum':
    #     #             summary[col] = int(df[col].sum())
    #     #         elif op == 'avg':
    #     #             summary[col] = float(df[col].mean())
    #     #         elif op == 'mid':
    #     #             summary[col] = float(df[col].median())
    #     #         else:
    #     #             summary[col] = "-"  # ì—ëŸ¬ ë°œìƒì‹œ, "-"ë¡œ í‘œê¸°í•˜ê³  raise error í•˜ì§€ ì•ŠìŒ
                    
    #     #     grid_options['pinnedBottomRowData'] = [summary]
    #     #     return grid_options

    #     # (í•„ìˆ˜í•¨ìˆ˜) add_summary
    #     def add_summary(grid_options: dict, df: pd.DataFrame, agg_map: dict[str, str]):
    #         summary: dict[str, float | str] = {}
    #         for col, op in agg_map.items():
    #             val = None
    #             try:
    #                 if op == 'sum':
    #                     val = df[col].sum()
    #                 elif op == 'avg':
    #                     val = df[col].mean()
    #                 elif op == 'mid':
    #                     val = df[col].median()
    #             except:
    #                 val = None

    #             # NaN / Inf / numpy íƒ€ì… â†’ None or native íƒ€ì…ìœ¼ë¡œ ì²˜ë¦¬
    #             if val is None or isinstance(val, float) and (math.isnan(val) or math.isinf(val)):
    #                 summary[col] = None
    #             else:
    #                 # numpy íƒ€ì… ì œê±°
    #                 if isinstance(val, (np.integer, np.int64, np.int32)):
    #                     summary[col] = int(val)
    #                 elif isinstance(val, (np.floating, np.float64, np.float32)):
    #                     summary[col] = float(round(val, 2))
    #                 else:
    #                     summary[col] = val

    #         grid_options['pinnedBottomRowData'] = [summary]
    #         return grid_options

    #     # date_col
    #     date_col = {
    #         "headerName": "ë‚ ì§œ",
    #         "field": "event_date",
    #         "pinned": "left",
    #         "width": 100,
    #         "cellStyle": JsCode("params=>({textAlign:'left'})"),
    #         "sort": "desc"
    #     }

    #     # (use_parent) flat_cols
    #     flat_cols = [
    #         date_col,
    #         make_num_child("ë§¤ì¶œ",   "ord_amount_sum"),
    #         make_num_child("ì£¼ë¬¸ìˆ˜", "ord_count_sum"),
    #         make_num_child("AOV(í‰ê· ì£¼ë¬¸ê¸ˆì•¡)",    "AOV"),
    #         make_num_child("ê´‘ê³ ë¹„", "cost_gross_sum"),
    #         make_num_child("ROAS(ê´‘ê³ ìˆ˜ìµë¥ )",   "ROAS", fmt_digits=2, suffix='%'),
    #         make_num_child("ì„¸ì…˜ìˆ˜", "session_count"),
    #         make_num_child("CVR(ì „í™˜ìœ¨)",    "CVR", fmt_digits=2, suffix='%'),
    #     ]

    #     # (use_parent) grouped_cols
    #     grouped_cols = [
    #         date_col,
    #         {
    #             "headerName": "COST",
    #             "children": [
    #                 make_num_child("ë§¤ì¶œ",   "ord_amount_sum"),
    #                 make_num_child("ì£¼ë¬¸ìˆ˜", "ord_count_sum"),
    #                 make_num_child("AOV(í‰ê· ì£¼ë¬¸ê¸ˆì•¡)",    "AOV"),
    #             ]
    #         },
    #         {
    #             "headerName": "PERP",
    #             "children": [
    #                 make_num_child("ê´‘ê³ ë¹„", "cost_gross_sum"),
    #                 make_num_child("ROAS(ê´‘ê³ ìˆ˜ìµë¥ )",   "ROAS", fmt_digits=2, suffix='%'),
    #             ]
    #         },
    #         {
    #             "headerName": "GA",
    #             "children": [
    #                 make_num_child("ì„¸ì…˜ìˆ˜", "session_count"),
    #                 make_num_child("CVR(ì „í™˜ìœ¨)",    "CVR", fmt_digits=2, suffix='%'),
    #             ]
    #         },
    #     ]

    #     # (use_parent)
    #     column_defs = grouped_cols if use_parent else flat_cols
        
    #     # grid_options & ë Œë”ë§
    #     grid_options = {
    #         "columnDefs": column_defs,
    #         "defaultColDef": {"sortable": True, "filter": True, "resizable": True},
    #         "headerHeight": 30,
    #         "groupHeaderHeight": 30,
    #     }

    #     # (add_summary) grid_options & ë Œë”ë§ -> í•©ê³„ í–‰ ì¶”ê°€í•˜ì—¬ ì¬ë Œë”ë§
    #     grid_options = add_summary(
    #         grid_options,
    #         df2,
    #         {
    #             'ord_amount_sum': 'sum',
    #             'ord_count_sum' : 'sum',
    #             'AOV'           : 'avg',
    #             'cost_gross_sum': 'sum',
    #             'ROAS'          : 'avg',
    #             'session_count' : 'sum',
    #             'CVR'           : 'avg',
    #         }
    #     )

    #     AgGrid(
    #         df2,
    #         gridOptions=grid_options,
    #         height=height,
    #         fit_columns_on_grid_load=False,  # Trueë©´ ì „ì²´ë„“ì´ì—ì„œ ê· ë“±ë¶„ë°° 
    #         theme="streamlit-dark" if st.get_option("theme.base") == "dark" else "streamlit",
    #         allow_unsafe_jscode=True
    #     )


    # íƒ­ ê°„ê²© CSS
    st.markdown("""
        <style>
          [role="tablist"] [role="tab"] { margin-right: 1rem; }
        </style>
    """, unsafe_allow_html=True)


    # # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # # ì‹œê°í™” (ë¡¤ë°±ìš© - ê¸°ê°„ì¡°ì • ì´ì „)
    # # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # st.markdown("<h5 style='margin:0'>ì œëª©</h5>", unsafe_allow_html=True)  
    # st.markdown(":gray-badge[:material/Info: Info]ã…¤ì„¤ëª… ", unsafe_allow_html=True)
    

    # with st.expander("ì¶”ì´ì„  ì„¤ëª…", expanded=False):
    #     st.markdown("""
    # - **MA (ì´ë™í‰ê· )** : **ê¸°ë³¸ ìŠ¤ë¬´ë”©**, ìµœê·¼ Sì¼ í‰ê· ìœ¼ë¡œ ìš”ë™ì„ ëˆŒëŸ¬ í° íë¦„ë§Œ ë³´ì´ê²Œ í•©ë‹ˆë‹¤.
    # - **EWMA (ì§€ìˆ˜ê°€ì¤‘)** : **ê°€ì¤‘ ìŠ¤ë¬´ë”©**, ìµœê·¼ ê°’ì— ë” í° ê°€ì¤‘ì¹˜ë¥¼ ì£¼ì–´ ë³€í™”ì— ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•©ë‹ˆë‹¤.
    # - **STL Trend** : ê³„ì ˆì„±(ì£¼ê¸°) ì„±ë¶„ì„ ì œê±°í•˜ê³  **ìˆœìˆ˜ ì¶”ì„¸(ë°©í–¥)**ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
    # - **Seasonally Adjusted** : ì› ë°ì´í„°ì—ì„œ ê³„ì ˆì„±(ì£¼ê¸°) ì„±ë¶„ì„ ëº€ ì‹¤ì œê°’ìœ¼ë¡œ, ì´ë²¤íŠ¸ë‚˜ í”„ë¡œëª¨ì…˜ì˜ **ìˆœìˆ˜ ë³€í™”ëŸ‰(í¬ê¸°)**ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
    # """)


    # options = {"ì „ì²´ í†µí•©": df_total, "ìŠ¬ë¦½í¼ í†µí•©": df_slp, "ëˆ„ì–´ í†µí•©": df_nor}

    # # ì»¨íŠ¸ë¡¤ íŒ¨ë„ ê°€ë¡œ ë°°ì¹˜
    # c1, c2, c3, c4 = st.columns([ 3, 3, 3, 3])

    # # 1. ë°ì´í„° ì„ íƒ
    # with c1:
    #     ds_name = st.selectbox("ë°ì´í„° ì„ íƒ", list(options.keys()), index=0)
    # df = options[ds_name].copy()

    # # ë‚ ì§œ ì •ê·œí™”
    # DATE_CANDS = ['ë‚ ì§œ','date','event_date']
    # date_col = next((c for c in DATE_CANDS if c in df.columns), None)
    # if date_col is None:
    #     st.error("ë‚ ì§œ ì»¬ëŸ¼(ì˜ˆ: 'ë‚ ì§œ')ì´ í•„ìš”í•©ë‹ˆë‹¤."); st.stop()
    # df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
    # df = df.dropna(subset=[date_col]).sort_values(date_col)

    # # 2. ì§€í‘œ ì„ íƒ
    # label_map = {
    #     'ord_amount_sum': 'ë§¤ì¶œ',
    #     'cost_gross_sum': 'ê´‘ê³ ë¹„',
    #     'session_count' : 'ì„¸ì…˜ìˆ˜',
    #     'ord_count_sum' : 'ì£¼ë¬¸ìˆ˜',
    # }
    # metric_options = [k for k in ['ord_amount_sum','cost_gross_sum','session_count','ord_count_sum'] if k in df.columns]
    # with c2:
    #     metric = st.selectbox("ì§€í‘œ ì„ íƒ", metric_options, index=0, format_func=lambda k: label_map.get(k, k))

    # # 3. ì¶”ì´ì„  ì„ íƒ
    # overlay_options = ["MA (ì´ë™í‰ê· )", "EWMA (ì§€ìˆ˜ê°€ì¤‘)", "STL Trend", "Seasonally Adjusted"]
    # with c3:
    #     overlay = st.selectbox("ì¶”ì´ì„  ì„ íƒ", overlay_options, index=0)

    # # 4. ì£¼ê¸° ì„ íƒ
    # with c4:
    #     period = st.radio(
    #         "ì£¼ê¸°(S) ì„ íƒ", [14, 7], horizontal=True,
    #         help="ì´ ê°’ì€ ì´ë™í‰ê· /ì§€ìˆ˜ê°€ì¤‘(EWMA)ì˜ í‰í™œê³¼ ì„¸ë¡œì„  ê°„ê²© ë° ë³¼ë¦°ì € ë°´ë“œ ì°½ì— ì‚¬ìš©ë©ë‹ˆë‹¤."
    #     )


    # # 1) ì‹œê³„ì—´ ì¤€ë¹„ (ì „ì²´ êµ¬ê°„)
    # s = df.set_index(date_col)[metric].asfreq('D').fillna(0)

    # # 2) ë³´ì¡° ì‹œë¦¬ì¦ˆ ê³„ì‚° (í•„ìš”í•  ë•Œë§Œ)
    # win = period
    # y_ma = s.rolling(win, min_periods=1).mean() if overlay == "MA (ì´ë™í‰ê· )" else None

    # y_trend = y_seas = y_sa = None
    # if overlay in ("STL Trend", "Seasonally Adjusted"):
    #     try:
    #         from statsmodels.tsa.seasonal import STL
    #         stl = STL(s, period=period, robust=True).fit()
    #         y_trend, y_seas = stl.trend, stl.seasonal
    #     except Exception:
    #         key = np.arange(len(s)) % period
    #         y_seas  = s.groupby(key).transform('mean')
    #         y_trend = (s - y_seas).rolling(period, min_periods=1, center=True).mean()
    #     y_sa = (s - y_seas) if y_seas is not None else None

    # y_ewma = s.ewm(halflife=period, adjust=False, min_periods=1).mean() if overlay == "EWMA (ì§€ìˆ˜ê°€ì¤‘)" else None

    # # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # # 3) ê·¸ë˜í”„: RAW(ì¢Œ) + ì„ íƒ ì˜¤ë²„ë ˆì´(ìš°) + ì£¼ê¸° ì„¸ë¡œì„  + Bollinger Bands(í•­ìƒ)
    # # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # fig = make_subplots(specs=[[{"secondary_y": True}]])

    # # RAW â†’ ì¢Œì¸¡ ì¶•
    # fig.add_trace(
    #     go.Scatter(x=s.index, y=s, name="RAW", mode="lines+markers", line=dict(color="#666"), opacity=0.45),
    #     secondary_y=False
    # )

    # # Bollinger Bands (ì¢Œì¸¡ ì¶•, í•­ìƒ í‘œì‹œ) â€” ì°½=S, k=2
    # k = 2.0
    # ma_bb = s.rolling(period, min_periods=period).mean()
    # sd_bb = s.rolling(period, min_periods=period).std(ddof=0)
    # bb_upper = ma_bb + k * sd_bb
    # bb_lower = ma_bb - k * sd_bb

    # # ìƒë‹¨ ë°´ë“œ
    # fig.add_trace(
    #     go.Scatter(
    #         x=bb_upper.index, y=bb_upper, name="BB Upper",
    #         mode="lines", line=dict(width=1, color="#FFB6C1")
    #     ),
    #     secondary_y=False
    # )
    # # í•˜ë‹¨ ë°´ë“œ + ìŒì˜
    # fig.add_trace(
    #     go.Scatter(
    #         x=bb_lower.index, y=bb_lower, name="BB Lower",
    #         mode="lines", line=dict(width=1, color="#ADD8E6"),
    #         fill="tonexty", fillcolor="rgba(128,128,128,0.12)"
    #     ),
    #     secondary_y=False
    # )

    # # ì˜¤ë²„ë ˆì´ â†’ ìš°ì¸¡ ì¶• (ëª¨ë‘ #FF4B4B)
    # overlay_series = None
    # if overlay == "MA (ì´ë™í‰ê· )" and y_ma is not None:
    #     overlay_series = y_ma
    #     fig.add_trace(
    #         go.Scatter(x=y_ma.index, y=y_ma, name=f"MA{win}",
    #                 mode="lines",
    #                 line=dict(color="#FF4B4B")),
    #         secondary_y=True
    #     )
    # elif overlay == "STL Trend" and y_trend is not None:
    #     overlay_series = y_trend
    #     fig.add_trace(
    #         go.Scatter(x=y_trend.index, y=y_trend, name="STL Trend",
    #                 mode="lines", line=dict(color="#FF4B4B")),
    #         secondary_y=True
    #     )
    # elif overlay == "Seasonally Adjusted" and y_sa is not None:
    #     overlay_series = y_sa
    #     fig.add_trace(
    #         go.Scatter(x=y_sa.index, y=y_sa, name="Seasonally Adjusted",
    #                 mode="lines", line=dict(color="#FF4B4B")),
    #         secondary_y=True
    #     )
    # elif overlay == "EWMA (ì§€ìˆ˜ê°€ì¤‘)" and y_ewma is not None:
    #     overlay_series = y_ewma
    #     fig.add_trace(
    #         go.Scatter(x=y_ewma.index, y=y_ewma, name=f"EWMA(h={period})",
    #                 mode="lines", line=dict(color="#FF4B4B")),
    #         secondary_y=True
    #     )

    # # â”€â”€ ì¢Œ/ìš° ì¶• ë²”ìœ„ ë™ê¸°í™” (Â±5% íŒ¨ë”©) â€” BBê¹Œì§€ í¬í•¨
    # left_candidates = [s.dropna()]
    # if bb_upper is not None: left_candidates.append(bb_upper.dropna())
    # if bb_lower is not None: left_candidates.append(bb_lower.dropna())
    # left_all = pd.concat(left_candidates, axis=0) if left_candidates else s.dropna()
    # right = overlay_series.dropna() if overlay_series is not None else None

    # if len(left_all) and (right is not None) and len(right):
    #     ymin = float(np.nanmin([left_all.min(), right.min()]))
    #     ymax = float(np.nanmax([left_all.max(), right.max()]))
    #     if not np.isfinite(ymin) or not np.isfinite(ymax):
    #         ymin, ymax = 0.0, 1.0
    #     if ymax <= ymin:
    #         pad = max(1.0, abs(ymax) * 0.05)
    #         ymin, ymax = ymin - pad, ymax + pad
    #     else:
    #         pad = (ymax - ymin) * 0.05
    #         ymin, ymax = ymin - pad, ymax + pad
    #     fig.update_yaxes(range=[ymin, ymax], secondary_y=False)
    #     fig.update_yaxes(range=[ymin, ymax], secondary_y=True)
    #     fig.update_yaxes(tickformat="~s", secondary_y=False)
    #     fig.update_yaxes(tickformat="~s", secondary_y=True)

    # # ì£¼ê¸°ë³„ ì„¸ë¡œì„ : 7â†’ì¼ìš”ì¼ ê¸°ì¤€ ë§¤ 7ì¼, 14â†’ë§¤ 14ì¼
    # start_ts = pd.to_datetime(s.index.min()).normalize()
    # end_ts   = pd.to_datetime(s.index.max()).normalize()
    # offset_days = (6 - start_ts.weekday()) % 7   # 0=ì›” ... 6=ì¼ â†’ ì²« ì¼ìš”ì¼
    # first_sunday = start_ts + pd.Timedelta(days=offset_days)
    # step = 7 if period == 7 else 14
    # t = first_sunday
    # while t <= end_ts:
    #     fig.add_vline(x=t, line_dash="dash", line_width=1, opacity=0.6, line_color="#8c8c8c")
    #     t += pd.Timedelta(days=step)

    # # ì¶• ë¼ë²¨: ì¢Œ=RAW(+BB), ìš°=ì˜¤ë²„ë ˆì´
    # fig.update_yaxes(title_text=f"{label_map.get(metric, metric)} Â· RAW / BB", secondary_y=False)
    # overlay_title = {
    #     "MA (ì´ë™í‰ê· )": f"{label_map.get(metric, metric)} Â· MA{win}",
    #     "STL Trend": "STL Trend",
    #     "Seasonally Adjusted": "Seasonally Adjusted",
    #     "EWMA (ì§€ìˆ˜ê°€ì¤‘)": f"EWMA (halflife={period})"
    # }[overlay]
    # fig.update_yaxes(title_text=overlay_title, secondary_y=True)

    # fig.update_layout(
    #     margin=dict(l=10, r=10, t=30, b=10),
    #     # legend=dict(orientation="h", yanchor="bottom", y=1.02, x=0)
    #     legend=dict(orientation="h", y=1.03, x=1, xanchor="right", yanchor="bottom", title=None),

    # )

    # st.plotly_chart(fig, use_container_width=True)




    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì‹œê°í™” (ì‹ ê·œ - ê¸°ê°„ ì¡°ì • ê°œë³„~)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("<h5 style='margin:0'>ì œëª©</h5>", unsafe_allow_html=True)  
    st.markdown(":gray-badge[:material/Info: Info]ã…¤ì„¤ëª… ", unsafe_allow_html=True)

    with st.expander("ì¶”ì´ì„  ì„¤ëª…", expanded=False):
        st.markdown("""
    - **MA (ì´ë™í‰ê· )** : ê¸°ë³¸ ìŠ¤ë¬´ë”©, ìµœê·¼ Sì¼ í‰ê· ìœ¼ë¡œ ìš”ë™ì„ ëˆŒëŸ¬ í° íë¦„ë§Œ ë³´ì´ê²Œ í•©ë‹ˆë‹¤.
    - **EWMA (ì§€ìˆ˜ê°€ì¤‘)** : ê°€ì¤‘ ìŠ¤ë¬´ë”©, ìµœê·¼ ê°’ì— ë” í° ê°€ì¤‘ì¹˜ë¥¼ ì£¼ì–´ ë³€í™”ì— ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•©ë‹ˆë‹¤.
    - **STL (Seasonal-Trend decomposition using LOESS, Only Trend)** : ì£¼ê¸°ì„±(Seasonal)ì„ ì œê±°í•˜ê³ , ìˆœìˆ˜ ì¶”ì„¸(Trend)ë§Œ ë³´ì—¬ì¤ë‹ˆë‹¤.
    - **SA (Seasonally Adjusted, Only Trend & Remainder)** : ì£¼ê¸°ì„±(Seasonal)ë§Œ ì œê±°í•˜ê³ , ì´ë²¤íŠ¸ë‚˜ í”„ë¡œëª¨ì…˜ì˜ ìˆœìˆ˜ ë³€í™”ëŸ‰ ì¶”ì„¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
    """)

    #  ë‚ ì§œ ë¡œë“œ
    _today = pd.Timestamp.today().normalize()
    _chart_end = (_today - pd.Timedelta(days=1)).date()  # D-1

    cs_chart = "20250701"
    ce_chart = pd.Timestamp(_chart_end).strftime("%Y%m%d")

    # ì´í›„ ë¡œì§ ë™ì¼
    df_merged_chart, df_psi_chart = load_data(cs_chart, ce_chart)

    # ê¸°ì¡´ load_data(cs, ce)ë¥¼ ì¬ì‚¬ìš©í•˜ì—¬ ì°¨íŠ¸ ì „ìš© ë°ì´í„° í™•ë³´
    df_merged_chart, df_psi_chart = load_data(cs_chart, ce_chart)

    # â”€â”€ 1) ë¸Œëœë“œë³„ ì¼ì í”¼ë²—(ì°¨íŠ¸ìš©) â€“ ë³´ê³ ì„œ ìª½ê³¼ ë™ì¼í•œ ë¡œì§ ê°„ì†Œ ë³µì œ
    def _pivot_cstSes(df, brand_type=None, product_type=None):
        df_f = df.copy()
        if brand_type:
            df_f = df_f[df_f['brand_type'].astype(str).str.contains(brand_type, regex=True, na=False)]
        if product_type:
            df_f = df_f[df_f['product_type'].astype(str).str.contains(product_type, regex=True, na=False)]
        df_f['event_date'] = pd.to_datetime(df_f['event_date'], errors='coerce').dt.strftime('%Y-%m-%d')
        return (df_f.groupby('event_date', as_index=False)
                    .agg(session_count=('pseudo_session_id','sum'),
                        cost_gross_sum=('cost_gross','sum'))
                    .reset_index(drop=True))

    def _pivot_ord(df, brand_type=None, product_type=None):
        df_f = df.copy()
        if brand_type:
            df_f = df_f[df_f['ë¸Œëœë“œ'].astype(str).str.contains(brand_type, regex=True, na=False)]
        if product_type:
            df_f = df_f[df_f['ì¹´í…Œê³ ë¦¬'].astype(str).str.contains(product_type, regex=True, na=False)]
        df_f['ì£¼ë¬¸ì¼'] = pd.to_datetime(df_f['ì£¼ë¬¸ì¼'], errors='coerce').dt.strftime('%Y-%m-%d')
        return (df_f.groupby('ì£¼ë¬¸ì¼', as_index=False)
                    .agg(ord_amount_sum=('ì‹¤ê²°ì œê¸ˆì•¡','sum'),
                        ord_count_sum=('ì£¼ë¬¸ìˆ˜','sum'))
                    .reset_index(drop=True))

    # ì°¨íŠ¸ìš© ë°ì´í„°í”„ë ˆì„ êµ¬ì„± (í†µí•©/ìŠ¬ë¦½í¼/ëˆ„ì–´)
    _df_total_cost = (df_merged_chart.groupby('event_date', as_index=False)
                    .agg(cost_gross_sum=('cost_gross','sum'))
                    .sort_values('event_date'))
    _df_total_order = (df_order.groupby('ì£¼ë¬¸ì¼', as_index=False)
                    .agg(ord_amount_sum=('ì‹¤ê²°ì œê¸ˆì•¡','sum'), ord_count_sum=('ì£¼ë¬¸ìˆ˜','sum'))
                    .sort_values('ì£¼ë¬¸ì¼')
                    .rename(columns={'ì£¼ë¬¸ì¼':'event_date'}))
    df_total_chart = (df_psi_chart
                    .merge(_df_total_cost,  on='event_date', how='left')
                    .merge(_df_total_order, on='event_date', how='left'))

    _s_slp  = _pivot_cstSes(df_merged_chart, brand_type="ìŠ¬ë¦½í¼")
    _o_slp  = _pivot_ord(df_order,          brand_type="ìŠ¬ë¦½í¼")
    df_slp_chart = _s_slp.join(_o_slp.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')

    _s_nor  = _pivot_cstSes(df_merged_chart, brand_type="ëˆ„ì–´")
    _o_nor  = _pivot_ord(df_order,          brand_type="ëˆ„ì–´")
    df_nor_chart = _s_nor.join(_o_nor.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')

    # â”€â”€ 2) ì»¨íŠ¸ë¡¤ (ì´ ì˜ì—­ë§Œ ë…ë¦½ í‚¤ ì‚¬ìš©)
    options = {"ì „ì²´ í†µí•©": df_total_chart, "ìŠ¬ë¦½í¼ í†µí•©": df_slp_chart, "ëˆ„ì–´ í†µí•©": df_nor_chart}
    c1, c2, c3, _p, c4 = st.columns([3,3,3,0.5,3])

    with c1:
        ds_name = st.selectbox("ë°ì´í„° ì„ íƒ", list(options.keys()), index=0, key="ts_ds")
    df_ts = options[ds_name].copy()

    # ë‚ ì§œ ì •ê·œí™”
    DATE_CANDS = ['ë‚ ì§œ','date','event_date']
    date_col = next((c for c in DATE_CANDS if c in df_ts.columns), None)
    if date_col is None:
        st.error("ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ì–´ ì‹œê³„ì—´ì„ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); st.stop()
    df_ts[date_col] = pd.to_datetime(df_ts[date_col], errors='coerce')
    df_ts = df_ts.dropna(subset=[date_col]).sort_values(date_col)

    label_map = {
        'ord_amount_sum': 'ë§¤ì¶œ',
        'cost_gross_sum': 'ê´‘ê³ ë¹„',
        'session_count' : 'ì„¸ì…˜ìˆ˜',
        'ord_count_sum' : 'ì£¼ë¬¸ìˆ˜',
    }
    metric_options = [k for k in ['ord_amount_sum','cost_gross_sum','session_count','ord_count_sum'] if k in df_ts.columns]
    with c2:
        metric = st.selectbox("ì§€í‘œ ì„ íƒ", metric_options, index=0, key="ts_metric",
                            format_func=lambda k: label_map.get(k, k))
    overlay_options = ["MA (ì´ë™í‰ê· )", "EWMA (ì§€ìˆ˜ê°€ì¤‘)", "STL Trend", "Seasonally Adjusted"]
    with c3:
        overlay = st.selectbox("ì¶”ì´ì„  ì„ íƒ", overlay_options, index=0, key="ts_overlay")
    with _p:
        pass
    with c4:
        period = st.radio("ì£¼ê¸°(S) ì„ íƒ", [14, 7], horizontal=True, index=0, key="ts_period",
                        help="ë””í´íŠ¸ê°’ì¸ 14ì¼ì„ ê¶Œì¥í•©ë‹ˆë‹¤. ì´ ê°’ì€ ì´ë™í‰ê· /ì§€ìˆ˜ê°€ì¤‘ì˜ í‰í™œ, ì„¸ë¡œì„  ê°„ê²©, ë³¼ë¦°ì € ë°´ë“œ ìˆ˜ì‹ì— ì‚¬ìš©ë©ë‹ˆë‹¤.")

    # â”€â”€ 3) ì›” ë‹¨ìœ„ ì„ íƒ ìŠ¬ë¼ì´ë” (ì´ ì˜ì—­ë§Œ ë…ë¦½) â€” ê¸°ë³¸: ìµœì‹  2ê°œì›”
    date_min = pd.to_datetime(df_ts[date_col].min()).normalize()
    date_max = pd.to_datetime(df_ts[date_col].max()).normalize()
    if pd.isna(date_min) or pd.isna(date_max):
        st.warning("ìœ íš¨í•œ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); st.stop()

    start_period = date_min.to_period("M")
    end_period   = date_max.to_period("M")
    month_options = [p.to_timestamp() for p in pd.period_range(start=start_period, end=end_period, freq="M")]

    # ì˜µì…˜ì´ 0/1ê°œì¼ ë•Œ ë°©ì–´ (RangeError ì˜ˆë°©)
    if len(month_options) == 0:
        st.warning("í‘œì‹œí•  ì›” ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."); st.stop()
    elif len(month_options) == 1:
        start_sel = end_sel = month_options[0]
        st.select_slider("ê¸°ê°„(ì›”)", options=month_options, value=start_sel,
                        format_func=lambda x: x.strftime("%Y-%m"), key="ts_period_single")
    else:
        # ê¸°ë³¸ê°’: ë§ˆì§€ë§‰ ë‘ ë‹¬
        default_start, default_end = (month_options[-2], month_options[-1])
        start_sel, end_sel = st.select_slider(
            "ê¸°ê°„(ì›”)", options=month_options, value=(default_start, default_end),
            format_func=lambda x: x.strftime("%Y-%m"), key="ts_period_range"
        )
        if start_sel > end_sel:
            start_sel, end_sel = end_sel, start_sel

    period_start, period_end = start_sel, end_sel + MonthEnd(0)
    dfp = df_ts[(df_ts[date_col] >= period_start) & (df_ts[date_col] <= period_end)].copy()

    # â”€â”€ 4) ì‹œê³„ì—´ ê³„ì‚° ë° ê·¸ë¦¬ê¸° 
    s = dfp.set_index(date_col)[metric].asfreq('D').fillna(0)
    if s.empty or s.dropna().shape[0] < 2:
        st.warning("ì„ íƒí•œ ê¸°ê°„ì— í‘œì‹œí•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ê¸°ê°„ì„ ë„“í˜€ì£¼ì„¸ìš”.")
    else:
        win = period
        y_ma = s.rolling(win, min_periods=1).mean() if overlay == "MA (ì´ë™í‰ê· )" else None

        y_trend = y_seas = y_sa = None
        if overlay in ("STL Trend", "Seasonally Adjusted"):
            try:
                from statsmodels.tsa.seasonal import STL
                stl_period = max(2, min(int(period), max(2, len(s)//2)))
                stl = STL(s, period=stl_period, robust=True).fit()
                y_trend, y_seas = stl.trend, stl.seasonal
            except Exception:
                key = np.arange(len(s)) % period
                y_seas  = s.groupby(key).transform('mean')
                y_trend = (s - y_seas).rolling(period, min_periods=1, center=True).mean()
            y_sa = (s - y_seas) if y_seas is not None else None

        y_ewma = s.ewm(halflife=period, adjust=False, min_periods=1).mean() if overlay == "EWMA (ì§€ìˆ˜ê°€ì¤‘)" else None

        fig = make_subplots(specs=[[{"secondary_y": True}]])
        fig.add_trace(
            go.Scatter(x=s.index, y=s, name="RAW", mode="lines+markers", line=dict(color="#666"), opacity=0.45),
            secondary_y=False
        )

        # Bollinger Bands (ì§§ì€ êµ¬ê°„ ë°©ì–´)
        k = 2.0
        minp = int(min(period, max(2, len(s))))
        ma_bb = s.rolling(period, min_periods=minp).mean()
        sd_bb = s.rolling(period, min_periods=minp).std(ddof=0)
        bb_upper = ma_bb + k * sd_bb
        bb_lower = ma_bb - k * sd_bb

        fig.add_trace(go.Scatter(x=bb_upper.index, y=bb_upper, name="BB Upper", mode="lines", line=dict(width=1, color="#FFB6C1")), secondary_y=False)
        fig.add_trace(go.Scatter(x=bb_lower.index, y=bb_lower, name="BB Lower", mode="lines", line=dict(width=1, color="#ADD8E6"),
                                fill="tonexty", fillcolor="rgba(128,128,128,0.12)"), secondary_y=False)

        overlay_series = None
        if overlay == "MA (ì´ë™í‰ê· )" and y_ma is not None:
            overlay_series = y_ma
            fig.add_trace(go.Scatter(x=y_ma.index, y=y_ma, name=f"MA{win}", mode="lines", line=dict(color="#FF4B4B")), secondary_y=True)
        elif overlay == "STL Trend" and y_trend is not None:
            overlay_series = y_trend
            fig.add_trace(go.Scatter(x=y_trend.index, y=y_trend, name="STL Trend", mode="lines", line=dict(color="#FF4B4B")), secondary_y=True)
        elif overlay == "Seasonally Adjusted" and y_sa is not None:
            overlay_series = y_sa
            fig.add_trace(go.Scatter(x=y_sa.index, y=y_sa, name="Seasonally Adjusted", mode="lines", line=dict(color="#FF4B4B")), secondary_y=True)
        elif overlay == "EWMA (ì§€ìˆ˜ê°€ì¤‘)" and y_ewma is not None:
            overlay_series = y_ewma
            fig.add_trace(go.Scatter(x=y_ewma.index, y=y_ewma, name=f"EWMA(h={period})", mode="lines", line=dict(color="#FF4B4B")), secondary_y=True)

        # left_candidates = [s.dropna()]
        # if (bb_upper is not None) and (not bb_upper.dropna().empty): left_candidates.append(bb_upper.dropna())
        # if (bb_lower is not None) and (not bb_lower.dropna().empty): left_candidates.append(bb_lower.dropna())
        # left_all = pd.concat(left_candidates) if left_candidates else s.dropna()
        # right = overlay_series.dropna() if (overlay_series is not None) else None

        # if (not left_all.empty) and (right is not None) and (not right.empty):
        #     ymin = float(np.nanmin([left_all.min(), right.min()]))
        #     ymax = float(np.nanmax([left_all.max(), right.max()]))
        #     if (not np.isfinite(ymin)) or (not np.isfinite(ymax)) or (ymax <= ymin):
        #         pad = 1.0
        #         ymin = (ymin if np.isfinite(ymin) else 0.0) - pad
        #         ymax = (ymax if np.isfinite(ymax) else 0.0) + pad
        #     else:
        #         pad = (ymax - ymin) * 0.05
        #         ymin, ymax = ymin - pad, ymax + pad
        #     fig.update_yaxes(range=[ymin, ymax], secondary_y=False)
        #     fig.update_yaxes(range=[ymin, ymax], secondary_y=True)
        #     fig.update_yaxes(tickformat="~s", secondary_y=False)
        #     fig.update_yaxes(tickformat="~s", secondary_y=True)
        
        # â”€â”€ ì¢Œ/ìš° ì¶• ë²”ìœ„ ì„¤ì • (STL/SAëŠ” ìš°ì¸¡ ë…ë¦½ ìŠ¤ì¼€ì¼)
        left_candidates = [s.dropna()]
        if (bb_upper is not None) and (not bb_upper.dropna().empty):
            left_candidates.append(bb_upper.dropna())
        if (bb_lower is not None) and (not bb_lower.dropna().empty):
            left_candidates.append(bb_lower.dropna())
        left_all = pd.concat(left_candidates) if left_candidates else s.dropna()
        right = overlay_series.dropna() if (overlay_series is not None) else None

        def _minmax_with_pad(series_min, series_max, pad_ratio=0.05, fallback_pad=1.0):
            # ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ None ë°˜í™˜ (ìë™ ìŠ¤ì¼€ì¼)
            if (series_min is None) or (series_max is None):
                return None
            if (not np.isfinite(series_min)) or (not np.isfinite(series_max)):
                return None
            if series_max <= series_min:
                pad = fallback_pad
                return (series_min - pad, series_max + pad)
            pad = (series_max - series_min) * pad_ratio
            return (series_min - pad, series_max + pad)

        # 1) ì¢Œì¸¡ ì¶•: RAW(+BB) ê¸°ì¤€ ë²”ìœ„ ì„¤ì •
        if not left_all.empty:
            lmin = float(left_all.min())
            lmax = float(left_all.max())
            lrange = _minmax_with_pad(lmin, lmax)
            if lrange is not None:
                fig.update_yaxes(range=list(lrange), secondary_y=False)
        fig.update_yaxes(tickformat="~s", secondary_y=False)

        # 2) ìš°ì¸¡ ì¶•: ì˜¤ë²„ë ˆì´ë³„ ì²˜ë¦¬
        if (right is not None) and (not right.empty):
            rmin = float(right.min())
            rmax = float(right.max())

            # STL / Seasonally Adjusted â†’ ìš°ì¸¡ ë…ë¦½ ìŠ¤ì¼€ì¼
            if overlay in ("STL Trend", "Seasonally Adjusted"):
                rrange = _minmax_with_pad(rmin, rmax)
                if rrange is not None:
                    fig.update_yaxes(range=list(rrange), secondary_y=True)
            else:
                # ê·¸ ì™¸(MA/EWMA)ëŠ” ì¢Œì¸¡ê³¼ ë™ì¼ ë²”ìœ„(ë™ê¸°í™”)
                if not left_all.empty:
                    if lrange is not None:
                        fig.update_yaxes(range=list(lrange), secondary_y=True)

        fig.update_yaxes(tickformat="~s", secondary_y=True)


        # ì£¼ê¸°ë³„ ì„¸ë¡œì„ 
        start_ts = pd.to_datetime(s.index.min()).normalize()
        end_ts   = pd.to_datetime(s.index.max()).normalize()
        offset_days = (6 - start_ts.weekday()) % 7   # 0=ì›” ... 6=ì¼ â†’ ì²« ì¼ìš”ì¼
        first_sunday = start_ts + pd.Timedelta(days=offset_days)
        step = 7 if period == 7 else 14
        t = first_sunday
        while t <= end_ts:
            fig.add_vline(x=t, line_dash="dash", line_width=1, opacity=0.6, line_color="#8c8c8c")
            t += pd.Timedelta(days=step)

        fig.update_yaxes(title_text=f"{label_map.get(metric, metric)} Â· RAW / BB", secondary_y=False)
        overlay_title = {
            "MA (ì´ë™í‰ê· )": f"{label_map.get(metric, metric)} Â· MA{win}",
            "STL Trend": "STL Trend",
            "Seasonally Adjusted": "Seasonally Adjusted",
            "EWMA (ì§€ìˆ˜ê°€ì¤‘)": f"EWMA (halflife={period})"
        }[overlay]
        fig.update_yaxes(title_text=overlay_title, secondary_y=True)
        fig.update_yaxes(showgrid=False, zeroline=False)
        fig.update_layout(
            margin=dict(l=10, r=10, t=30, b=10),
            legend=dict(orientation="h", y=1.03, x=1, xanchor="right", yanchor="bottom", title=None),
        )
        st.plotly_chart(fig, use_container_width=True)







    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # í†µí•© ë§¤ì¶œ ë¦¬í¬íŠ¸ 
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.header(" ") # ê³µë°±ìš©
    st.markdown("<h5 style='margin:0'>í†µí•© ë§¤ì¶œ ë¦¬í¬íŠ¸</h5>", unsafe_allow_html=True)  
    st.markdown(":gray-badge[:material/Info: Info]ã…¤ì¼ìë³„ **í†µí•©** ë°ì´í„°ì™€ íš¨ìœ¨ ì¶”ì´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ", unsafe_allow_html=True)
    with st.popover("ì§€í‘œ ì„¤ëª…"):
        st.markdown("""
                    - **AOV** (Average Order Value) : **í‰ê· ì£¼ë¬¸ê¸ˆì•¡** (ë§¤ì¶œ Ã· ì£¼ë¬¸ìˆ˜)  
                    - **ROAS** (Return On Ad Spend) : **ê´‘ê³  ìˆ˜ìµë¥ ** (ë§¤ì¶œ Ã· ê´‘ê³ ë¹„ Ã— 100)  
                    - **CVR** (Conversion Rate) : **ì „í™˜ìœ¨** (ì£¼ë¬¸ìˆ˜ Ã· ì„¸ì…˜ìˆ˜ Ã— 100)  
                    """)
    render_style(df_total)


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ìŠ¬ë¦½í¼ ë§¤ì¶œ ë¦¬í¬íŠ¸
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.header(" ") # ê³µë°±ìš©
    st.markdown("<h5 style='margin:0'><span style='color:#FF4B4B;'>ìŠ¬ë¦½í¼</span> ë§¤ì¶œ ë¦¬í¬íŠ¸</h5>", unsafe_allow_html=True)  
    st.markdown(":gray-badge[:material/Info: Info]ã…¤ì¼ìë³„ **í’ˆëª©** ë°ì´í„°ì™€ íš¨ìœ¨ ì¶”ì´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. <span style='color:#8E9097;'>(15ì‹œ ì´í›„ D-1 ë°ì´í„° ì œê³µ)</span> ", unsafe_allow_html=True)
    with st.popover("ì§€í‘œ ì„¤ëª…"):
        st.markdown("""
                    - **AOV** (Average Order Value) : **í‰ê· ì£¼ë¬¸ê¸ˆì•¡** (ë§¤ì¶œ Ã· ì£¼ë¬¸ìˆ˜)  
                    - **ROAS** (Return On Ad Spend) : **ê´‘ê³  ìˆ˜ìµë¥ ** (ë§¤ì¶œ Ã· ê´‘ê³ ë¹„ Ã— 100)  
                    - **CVR** (Conversion Rate) : **ì „í™˜ìœ¨** (ì£¼ë¬¸ìˆ˜ Ã· ì„¸ì…˜ìˆ˜ Ã— 100)  
                    """)

    tabs = st.tabs(["ìŠ¬ë¦½í¼ í†µí•©", "ìŠ¬ë¦½í¼ ë§¤íŠ¸ë¦¬ìŠ¤", "ìŠ¬ë¦½í¼ í”„ë ˆì„"])
    with tabs[0]:
        render_style(df_slp)
    with tabs[1]:
        render_style(df_slp_mat)
    with tabs[2]:
        render_style(df_slp_frm)


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ëˆ„ì–´ ë§¤ì¶œ ë¦¬í¬íŠ¸
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.header(" ") # ê³µë°±ìš©
    st.markdown("<h5 style='margin:0'><span style='color:#FF4B4B;'>ëˆ„ì–´</span> ë§¤ì¶œ ë¦¬í¬íŠ¸</h5>", unsafe_allow_html=True)  
    st.markdown(":gray-badge[:material/Info: Info]ã…¤ì¼ìë³„ **í’ˆëª©** ë°ì´í„°ì™€ íš¨ìœ¨ ì¶”ì´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. <span style='color:#8E9097;'>(15ì‹œ ì´í›„ D-1 ë°ì´í„° ì œê³µ)</span> ", unsafe_allow_html=True)
    with st.popover("ì§€í‘œ ì„¤ëª…"):
        st.markdown("""
                    - **AOV** (Average Order Value) : **í‰ê· ì£¼ë¬¸ê¸ˆì•¡** (ë§¤ì¶œ Ã· ì£¼ë¬¸ìˆ˜)  
                    - **ROAS** (Return On Ad Spend) : **ê´‘ê³  ìˆ˜ìµë¥ ** (ë§¤ì¶œ Ã· ê´‘ê³ ë¹„ Ã— 100)  
                    - **CVR** (Conversion Rate) : **ì „í™˜ìœ¨** (ì£¼ë¬¸ìˆ˜ Ã· ì„¸ì…˜ìˆ˜ Ã— 100)  
                    """)

    tabs = st.tabs(["ëˆ„ì–´ í†µí•©", "ëˆ„ì–´ ë§¤íŠ¸ë¦¬ìŠ¤", "ëˆ„ì–´ í”„ë ˆì„"])
    with tabs[0]:
        render_style(df_nor)
    with tabs[1]:
        render_style(df_nor_mat)
    with tabs[2]:
        render_style(df_nor_frm)


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì‹œê°í™” ì°¨íŠ¸ (ë‚˜ì¤‘ì— ì‹œê°í™” ì˜ì—­ ë”°ë¡œ ì¶”ê°€í•  ê±° ê°™ì•„ì„œ ì£¼ì„ì²˜ë¦¬í•¨ // 08.19)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # st.header(" ")
    # st.markdown("<h5 style='margin:0'>ë¦¬í¬íŠ¸ ì‹œê°í™”</h5>", unsafe_allow_html=True)
    # st.markdown(
    #     ":gray-badge[:material/Info: Info]ã…¤ë¦¬í¬íŠ¸, ì§€í‘œ, ì°¨íŠ¸ ì˜µì…˜ì„ ììœ ë¡­ê²Œ ì„ íƒí•˜ì—¬, ì›í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì‚´í´ë³´ì„¸ìš”.",
    #     unsafe_allow_html=True,
    # )

    # dfs = {
    #     "í†µí•© ë¦¬í¬íŠ¸":    df_total,
    #     "ìŠ¬ë¦½í¼ í†µí•©":    df_slp,
    #     "ìŠ¬ë¦½í¼ ë§¤íŠ¸ë¦¬ìŠ¤": df_slp_mat,
    #     "ìŠ¬ë¦½í¼ í”„ë ˆì„":   df_slp_frm,
    #     "ëˆ„ì–´ í†µí•©":     df_nor,
    #     "ëˆ„ì–´ ë§¤íŠ¸ë¦¬ìŠ¤":  df_nor_mat,
    #     "ëˆ„ì–´ í”„ë ˆì„":    df_nor_frm,
    # }
    
    # metrics = ["ë§¤ì¶œ","ì£¼ë¬¸ìˆ˜","AOV","ê´‘ê³ ë¹„","ROAS","ì„¸ì…˜ìˆ˜","CVR"]
    
    # col_map = {
    #     "ë§¤ì¶œ":   "ord_amount_sum",
    #     "ì£¼ë¬¸ìˆ˜": "ord_count_sum",
    #     "AOV":    "AOV",
    #     "ê´‘ê³ ë¹„": "cost_gross_sum",
    #     "ROAS":   "ROAS",
    #     "ì„¸ì…˜ìˆ˜": "session_count",
    #     "CVR":    "CVR"
    # }

    # default_yaxis = {
    #     "ë§¤ì¶œ": "left",
    #     "ì£¼ë¬¸ìˆ˜": "left",
    #     "AOV": "left",
    #     "ê´‘ê³ ë¹„": "left",
    #     "ROAS": "right",
    #     "ì„¸ì…˜ìˆ˜": "left",
    #     "CVR": "right"
    # }
    # default_chart = {
    #     "ë§¤ì¶œ": "bar",
    #     "ì£¼ë¬¸ìˆ˜": "bar",
    #     "AOV": "line",
    #     "ê´‘ê³ ë¹„": "bar",
    #     "ROAS": "line",
    #     "ì„¸ì…˜ìˆ˜": "bar",
    #     "CVR": "line"
    # }


    # # â”€â”€ 1) ì„ íƒ UI
    # c_report, c_metric = st.columns([3, 7])
    # with c_report:
    #     sel_report = st.selectbox("ë¦¬í¬íŠ¸ ì„ íƒ", list(dfs.keys()), key="select_report")
    # with c_metric:
    #     sel_metrics = st.multiselect("ì§€í‘œ ì„ íƒ", metrics, default=["AOV", "ROAS"], key="select_metrics")

    # # â”€â”€ 2) ì»¬ëŸ¼ë³„ ì˜µì…˜ ì„ íƒ UI (í‘œ í˜•íƒœ)
    # with st.expander("ì§€í‘œë³„ ì˜µì…˜ ì„ íƒ", expanded=False):

    #     metric_settings = {}
    #     for i, metric in enumerate(sel_metrics):
    #         c2, c3 = st.columns([2, 2])
    #         with c2:
    #             yaxis = st.selectbox(
    #                 f"Yì¶• ìœ„ì¹˜: {metric}", ["ì™¼ìª½", "ì˜¤ë¥¸ìª½"],
    #                 key=f"y_axis_{metric}_{i}",
    #                 index=0 if default_yaxis[metric] == "left" else 1
    #             )
    #         with c3:
    #             chart_type = st.selectbox(
    #                 f"ì°¨íŠ¸ ìœ í˜•: {metric}", ["êº¾ì€ì„ ", "ë§‰ëŒ€"],
    #                 key=f"chart_type_{metric}_{i}",
    #                 index=0 if default_chart[metric] == "line" else 1
    #             )
    #         metric_settings[metric] = {
    #             "yaxis": "right" if yaxis == "ì˜¤ë¥¸ìª½" else "left",
    #             "chart": "bar" if chart_type == "ë§‰ëŒ€" else "line"
    #         }

    # # â”€â”€ 3) ì°¨íŠ¸ ë¡œì§
    # if not sel_metrics:
    #     st.warning("í•˜ë‚˜ ì´ìƒì˜ ì§€í‘œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
    # else:
    #     df = dfs[sel_report].sort_values("event_date").copy()
    #     # íŒŒìƒì§€í‘œ ìƒì„± (ìˆ˜ì‹ì´ í•„ìš”í•œ í•­ëª©ë§Œ)
    #     df["AOV"]  = df["ord_amount_sum"] / df["ord_count_sum"]
    #     df["ROAS"] = df["ord_amount_sum"] / df["cost_gross_sum"] * 100
    #     df["CVR"]  = df["ord_count_sum"]  / df["session_count"] * 100

    #     fig = make_subplots(specs=[[{"secondary_y": True}]])

    #     for metric in sel_metrics:
    #         col = col_map[metric]
    #         y_axis = metric_settings[metric]["yaxis"] == "right"
    #         chart_type = metric_settings[metric]["chart"]

    #         if chart_type == "bar":
    #             fig.add_trace(
    #                 go.Bar(
    #                     x=df["event_date"],
    #                     y=df[col],
    #                     name=metric,
    #                     opacity=0.5,
    #                     # width=0.9
    #                 ),
    #                 secondary_y=y_axis
    #             )
    #         else:  # êº¾ì€ì„ 
    #             fig.add_trace(
    #                 go.Scatter(
    #                     x=df["event_date"],
    #                     y=df[col],
    #                     name=metric,
    #                     mode="lines+markers"
    #                 ),
    #                 secondary_y=y_axis
    #             )

    #     left_titles  = [m for m in sel_metrics if metric_settings[m]["yaxis"]=="left"]
    #     right_titles = [m for m in sel_metrics if metric_settings[m]["yaxis"]=="right"]
    #     left_title  = " Â· ".join(left_titles)  if left_titles  else None
    #     right_title = " Â· ".join(right_titles) if right_titles else None

    #     fig.update_layout(
    #         title=f"{sel_report}  -  {' / '.join(sel_metrics)} ì¶”ì´",
    #         xaxis=dict(tickformat="%mì›” %dì¼"),
    #         legend=dict(
    #             orientation="h",
    #             x=1, y=1.1, xanchor="right", yanchor="bottom"
    #         ),
    #         margin=dict(t=80, b=20, l=20, r=20)
    #     )
    #     if left_title:
    #         fig.update_yaxes(title_text=left_title, secondary_y=False)
    #     if right_title:
    #         fig.update_yaxes(title_text=right_title, secondary_y=True)

    #     st.plotly_chart(fig, use_container_width=True)




if __name__ == "__main__":
    main()