# ì„œí¬_ìµœì‹ ìˆ˜ì •ì¼_25-07-24

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import importlib
from datetime import datetime, timedelta
import modules.bigquery
importlib.reload(modules.bigquery)
from modules.bigquery import BigQuery
from st_aggrid import AgGrid, GridOptionsBuilder
from st_aggrid.shared import JsCode
import io
from google.oauth2.service_account import Credentials
import gspread
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import math


def main():
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ìŠ¤íŠ¸ë¦¼ë¦¿ í˜ì´ì§€ ì„¤ì •
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.set_page_config(layout="wide", page_title="SLPR | ë§¤ì¶œ ì¢…í•© ëŒ€ì‹œë³´ë“œ")
    st.markdown(
        """
        <style>
        .reportview-container .main .block-container {
            max-width: 100% !important;
            padding-left: 1rem;
            padding-right: 1rem;
        }
        
        </style>
        """,
        unsafe_allow_html=True,
    )
    st.subheader('ë§¤ì¶œ ì¢…í•© ëŒ€ì‹œë³´ë“œ')
    # st.markdown("ì„¤ëª…")
    st.markdown("""
    ì´ ëŒ€ì‹œë³´ë“œëŠ” **ë§¤ì¶œ Â· ê´‘ê³ ë¹„ Â· ìœ ì…** ë°ì´í„°ë¥¼ ì¼ìë³„ë¡œ í•œëˆˆì— ë³´ì—¬ì£¼ëŠ” **ê°€ì¥ ê°œê´„ì ì¸ ëŒ€ì‹œë³´ë“œ**ì…ë‹ˆë‹¤.  
    ì—¬ê¸°ì„œëŠ” ì¼ì/ë¸Œëœë“œ/í’ˆëª©ë³„ë¡œ â€œ**ì–¼ë§ˆ ë²Œì—ˆê³ , ì–¼ë§ˆ ì¼ê³ , ì–¼ë§ˆ ìœ ì…ëê³ **â€ë¥¼ íš¨ìœ¨ ì§€í‘œ(AOV, ROAS, CVR)ì™€ í•¨ê»˜ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)
    # st.markdown(":primary-badge[:material/Cached: Update]ã…¤ì„¤ëª….")
    st.markdown(
        '<a href="https://www.notion.so/Views-241521e07c7680df86eecf5c5f8da4af#241521e07c76805198d9eaf0c28deadb" target="_blank">'
        'Dashboard Guide</a>',
        unsafe_allow_html=True
    )
    st.divider()


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì‚¬ì´ë“œë°” í•„í„° ì„¤ì •
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.sidebar.header("Filter")
    
    today = datetime.now().date()
    default_end = today - timedelta(days=1)
    default_start = today - timedelta(days=14)
    start_date, end_date = st.sidebar.date_input(
        "ê¸°ê°„ ì„ íƒ",
        value=[default_start, default_end],
        max_value=default_end
    )
    cs = start_date.strftime("%Y%m%d")
    ce = end_date.strftime("%Y%m%d")

    @st.cache_data(ttl=3600)
    def load_data(cs: str, ce: str) -> pd.DataFrame:
        
        # 1) tb_media
        bq = BigQuery(projectCode="sleeper", custom_startDate=cs, custom_endDate=ce)
        df_bq = bq.get_data("tb_media")
        df_bq["event_date"] = pd.to_datetime(df_bq["event_date"], format="%Y%m%d")
        parts = df_bq['campaign_name'].str.split('_', n=5, expand=True)
        df_bq['campaign_name_short'] = df_bq['campaign_name']
        mask = parts[5].notna()
        df_bq.loc[mask, 'campaign_name_short'] = (
            parts.loc[mask, :4].apply(lambda r: '_'.join(r.dropna().astype(str)), axis=1)
        )
        # 2) Google Sheet
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds = Credentials.from_service_account_file("C:/_code/auth/sleeper-461005-c74c5cd91818.json", scopes=scope)
        gc = gspread.authorize(creds)
        sh = gc.open_by_url('https://docs.google.com/spreadsheets/d/11ov-_o6Lv5HcuZo1QxrKOZnLtnxEKTiV78OFBZzVmWA/edit')
        df_sheet = pd.DataFrame(sh.worksheet('parse').get_all_records())
        
        # merge (1+2)
        merged = df_bq.merge(df_sheet, how='left', on='campaign_name_short')
        # cost_gross
        merged['cost_gross'] = np.where(
            merged['media_name'].isin(['GOOGLE','META']), merged['cost']*1.1/0.98, merged['cost']
        )
        # handle NSA
        cond = (
            (merged['media_name']=='NSA') & merged['utm_source'].isna() &
            merged['utm_medium'].isna() & merged['media_name_type'].isin(['RSA_AD','TEXT_45'])
        )
        merged.loc[cond, ['utm_source','utm_medium']] = ['naver','search-nonmatch']
        
        # 3) tb_sleeper_psi
        df_psi = bq.get_data("tb_sleeper_psi")
        df_psi["event_date"] = pd.to_datetime(df_psi["event_date"], format="%Y%m%d")
        df_psi = (df_psi
                .assign(event_date=pd.to_datetime(df_psi["event_date"], format="%Y%m%d"))
                .groupby("event_date", as_index=False)
                .agg(session_count=("pseudo_session_id", "nunique")))

        
        return merged, df_psi

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.toast("GA D-1 ë°ì´í„°ëŠ” ì˜¤ì „ì— ì˜ˆë¹„ ì²˜ë¦¬ë˜ê³ , **15ì‹œ ì´í›„ì— ìµœì¢… ì—…ë°ì´íŠ¸** ë©ë‹ˆë‹¤.", icon="ğŸ””")
    df_merged, df_psi = load_data(cs, ce)

    # ê³µí†µí•©ìˆ˜ (1) ì¼ìë³„ ê´‘ê³ ë¹„, ì„¸ì…˜ìˆ˜ (íŒŒìƒë³€ìˆ˜ëŠ” í•´ë‹¹ í•¨ìˆ˜ê°€ ê³„ì‚°í•˜ì§€ ì•ŠìŒ)
    def pivot_cstSes(
        df: pd.DataFrame,
        brand_type: str | None = None,
        product_type: str | None = None
        ) -> pd.DataFrame:
        """
        1) í•¨ìˆ˜ ì‘ì„±
        :  pivot_cstSes(df, brand_type="ìŠ¬ë¦½í¼", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
        2) ê²°ê³¼ ì»¬ëŸ¼
        :  ['event_date', 'session_count', 'cost_gross_sum']
        """
        df_f = df.copy()

        if brand_type:
            df_f = df_f[df_f['brand_type'].astype(str).str.contains(brand_type, regex=True, na=False)]
        if product_type:
            df_f = df_f[df_f['product_type'].astype(str).str.contains(product_type, regex=True, na=False)]

        df_f['event_date'] = pd.to_datetime(df_f['event_date'], errors='coerce')
        df_f['event_date'] = df_f['event_date'].dt.strftime('%Y-%m-%d')

        pivot = (
            df_f
            .groupby('event_date', as_index=False) # ë°˜ë“œì‹œ Falseë¡œ ìœ ì§€ (ê·¸ë˜ì•¼ ì»¬ëŸ¼ì— ì‚´ì•„ìˆìŒ)
            .agg(
                session_count=('pseudo_session_id', 'sum'),
                cost_gross_sum=('cost_gross', 'sum')
            )
            .reset_index(drop=True)
        )
        return pivot


    # df_order
    
    # dates = pd.date_range("2025-07-01", "2025-07-21")
    # n = 200
    # df_order = pd.DataFrame({
    #     "ì£¼ë¬¸ì¼": np.random.choice(dates, size=n),
    #     "ì‹¤ê²°ì œê¸ˆì•¡": np.random.randint(100_000, 1_000_001, size=n),
    #     "ì¹´í…Œê³ ë¦¬": np.random.choice(["ë§¤íŠ¸ë¦¬ìŠ¤", "í”„ë ˆì„"], size=n),
    #     "ë¸Œëœë“œ": np.random.choice(["ìŠ¬ë¦½í¼", "ëˆ„ì–´"], size=n),
    #     "ì£¼ë¬¸ìˆ˜": np.random.randint(1, 4, size=n)  # 1~3 ëœë¤
    # })
    
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds = Credentials.from_service_account_file("C:/_code/auth/sleeper-461005-c74c5cd91818.json", scopes=scope)
    gc = gspread.authorize(creds)
    sh = gc.open_by_url('https://docs.google.com/spreadsheets/d/1chXeCek1UZPyCr18zLe7lV-8tmv6YPWK6cEqAJcDPqs/edit')
    df_order = pd.DataFrame(sh.worksheet('ì˜¨ì˜¤í”„ë¼ì¸_ì¢…í•©').get_all_records())
    df_order = df_order.rename(columns={"íŒë§¤ìˆ˜ëŸ‰": "ì£¼ë¬¸ìˆ˜"})  # ì»¬ëŸ¼ ì´ë¦„ ì¹˜í™˜
    def convert_dot_date(x):
        try:
            # 1. ë¬¸ìì—´ë¡œ ë³€í™˜ + ê³µë°± ì œê±°
            s = str(x).replace(" ", "")
            # 2. ë§ˆì¹¨í‘œ ê¸°ì¤€ split
            parts = s.split(".")
            if len(parts) == 3:
                y = parts[0]
                m = parts[1].zfill(2)
                d = parts[2].zfill(2)
                return pd.to_datetime(f"{y}-{m}-{d}", format="%Y-%m-%d", errors="coerce")
            return pd.NaT
        except:
            return pd.NaT
    df_order["ì£¼ë¬¸ì¼"] = pd.to_datetime(df_order["ì£¼ë¬¸ì¼"].apply(convert_dot_date), format="%Y-%m-%d", errors="coerce")
    df_order["ì‹¤ê²°ì œê¸ˆì•¡"] = pd.to_numeric(df_order["ì‹¤ê²°ì œê¸ˆì•¡"], errors='coerce')
    df_order["ì£¼ë¬¸ìˆ˜"] = pd.to_numeric(df_order["ì£¼ë¬¸ìˆ˜"], errors='coerce')
    df_order = df_order.dropna(subset=["ì£¼ë¬¸ì¼"])


    # ê³µí†µí•©ìˆ˜ (2) ì¼ìë³„ ë§¤ì¶œ, ì£¼ë¬¸ìˆ˜ (íŒŒìƒë³€ìˆ˜ëŠ” í•´ë‹¹ í•¨ìˆ˜ê°€ ê³„ì‚°í•˜ì§€ ì•ŠìŒ)
    def pivot_ord(
        df: pd.DataFrame,
        brand_type: str | None = None,
        product_type: str | None = None
        ) -> pd.DataFrame:
        """
        1) í•¨ìˆ˜ ì‘ì„±
        :  pivot_ord(df, brand_type="ìŠ¬ë¦½í¼", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
        2) ê²°ê³¼ ì»¬ëŸ¼
        :  ['ì£¼ë¬¸ì¼', 'ord_amount_sum', 'ord_count_sum']
        
        """
        df_f = df.copy()

        if brand_type:
            df_f = df_f[df_f['ë¸Œëœë“œ'].astype(str).str.contains(brand_type, regex=True, na=False)]
        if product_type:
            df_f = df_f[df_f['ì¹´í…Œê³ ë¦¬'].astype(str).str.contains(product_type, regex=True, na=False)]
            
        df_f['ì£¼ë¬¸ì¼'] = pd.to_datetime(df_f['ì£¼ë¬¸ì¼'], errors='coerce')
        df_f['ì£¼ë¬¸ì¼'] = df_f['ì£¼ë¬¸ì¼'].dt.strftime('%Y-%m-%d')

        pivot = (
            df_f
            .groupby('ì£¼ë¬¸ì¼', as_index=False) # ë°˜ë“œì‹œ Falseë¡œ ìœ ì§€ (ê·¸ë˜ì•¼ ì»¬ëŸ¼ì— ì‚´ì•„ìˆìŒ)
            .agg(
                ord_amount_sum=('ì‹¤ê²°ì œê¸ˆì•¡', 'sum'),
                ord_count_sum=('ì£¼ë¬¸ìˆ˜', 'sum')
            )
            .reset_index(drop=True)
        )
        return pivot


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë°ì´í„°í”„ë ˆì„ ìƒì„± (JOINì¸ ê²½ìš°ëŠ” ê³ ì˜ë¡œ "ì£¼ë¬¸ì¼" ì»¬ëŸ¼ ë–¨êµ´ ëª©ì )
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1-1) ìŠ¬ë¦½í¼
    _sctSes_slp      = pivot_cstSes(df_merged, brand_type="ìŠ¬ë¦½í¼")
    _ord_slp         = pivot_ord(df_order,     brand_type="ìŠ¬ë¦½í¼")
    df_slp           = _sctSes_slp.join(_ord_slp.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left') # df_slp = _sctSes_slp.join(_ord_slp, how='left', left_on='event_date', right_on='ì£¼ë¬¸ì¼')
    
    # 1-2) ìŠ¬ë¦½í¼ & ë§¤íŠ¸ë¦¬ìŠ¤
    _sctSes_slp_mat  = pivot_cstSes(df_merged, brand_type="ìŠ¬ë¦½í¼", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
    _ord_slp_mat     = pivot_ord(df_order,     brand_type="ìŠ¬ë¦½í¼", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
    df_slp_mat       = _sctSes_slp_mat.join(_ord_slp_mat.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')
    
    # 1-3) ìŠ¬ë¦½í¼ & í”„ë ˆì„
    _sctSes_slp_frm  = pivot_cstSes(df_merged, brand_type="ìŠ¬ë¦½í¼", product_type="í”„ë ˆì„")
    _ord_slp_frm     = pivot_ord(df_order,     brand_type="ìŠ¬ë¦½í¼", product_type="í”„ë ˆì„")
    df_slp_frm       = _sctSes_slp_frm.join(_ord_slp_frm.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')
    
    # 2-1) ëˆ„ì–´ 
    _sctSes_nor      = pivot_cstSes(df_merged, brand_type="ëˆ„ì–´")
    _ord_nor         = pivot_ord(df_order,     brand_type="ëˆ„ì–´")
    df_nor           = _sctSes_nor.join(_ord_nor.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')
    
    # 2-2) ëˆ„ì–´ & ë§¤íŠ¸ë¦¬ìŠ¤
    _sctSes_nor_mat  = pivot_cstSes(df_merged, brand_type="ëˆ„ì–´", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
    _ord_nor_mat     = pivot_ord(df_order,     brand_type="ëˆ„ì–´", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
    df_nor_mat       = _sctSes_nor_mat.join(_ord_nor_mat.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')
    
    # 2-3) ëˆ„ì–´ & í”„ë ˆì„
    _sctSes_nor_frm  = pivot_cstSes(df_merged, brand_type="ëˆ„ì–´", product_type="í”„ë ˆì„")
    _ord_nor_frm     = pivot_ord(df_order,     brand_type="ëˆ„ì–´", product_type="í”„ë ˆì„")
    df_nor_frm       = _sctSes_nor_frm.join(_ord_nor_frm.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')
    
    # 3) í†µí•© ë°ì´í„° (3ë²ˆ ì´ì§€ë§Œ, ìœ„ì¹˜ìƒ ìµœìƒìœ„ì— ìœ„ì¹˜í•¨ ì£¼ì˜)
    _df_total_psi    = df_psi  # ì´ë¯¸ ë‚ ì§œë³„ë¡œ ì„¸ì…˜ìˆ˜ê°€ í”¼ë²—ë˜ì–´ ìˆëŠ” ë°ì´í„°í”„ë ˆì„
    _df_total_cost   = df_merged.groupby('event_date', as_index=False).agg(cost_gross_sum=('cost_gross','sum')).sort_values('event_date')  # df_mergedì—ì„œ cost_grossë§Œ ê°€ì ¸ì˜´
    _df_total_order  = df_order.groupby('ì£¼ë¬¸ì¼', as_index=False).agg(ord_amount_sum=('ì‹¤ê²°ì œê¸ˆì•¡','sum'), ord_count_sum  =('ì£¼ë¬¸ìˆ˜', 'sum')).sort_values('ì£¼ë¬¸ì¼')
    _df_total_order  = _df_total_order.rename(columns={'ì£¼ë¬¸ì¼':'event_date'}) # ì£¼ë¬¸ì¼ -> event_date
    df_total = (_df_total_psi
                .merge(_df_total_cost,  on='event_date', how='left')
                .merge(_df_total_order, on='event_date', how='left')
                )
    df_total['event_date'] = pd.to_datetime(df_total['event_date'], errors='coerce').dt.strftime('%Y-%m-%d')


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì‹œê°í™”
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ê³µí†µí•¨ìˆ˜ (3) render_aggrid 
    def render_aggrid(
        df: pd.DataFrame,
        height: int = 410,
        use_parent: bool = True
        ) -> None:
        """
        use_parent: False / True
        """
        df2 = df.copy()
        df2.fillna(0, inplace=True)     # ê°’ì´ ì—†ëŠ” ê²½ìš° ì¼ë‹¨ 0ìœ¼ë¡œ ì¹˜í™˜
        
        # ì „ì²˜ë¦¬ ì˜ì—­ (íŒŒìƒì§€í‘œ ìƒì„±, ì»¬ëŸ¼ìˆœì„œ ì§€ì •)
        df2['CVR']  = (df2['ord_count_sum']  / df2['session_count']  * 100).round(2)
        df2['AOV']  = (df2['ord_amount_sum'] / df2['ord_count_sum']  ).round(0)
        df2['ROAS'] = (df2['ord_amount_sum'] / df2['cost_gross_sum'] * 100).round(2)
        df2 = df2[['event_date','ord_amount_sum','ord_count_sum','AOV','cost_gross_sum','ROAS','session_count','CVR']]
        
        # (í•„ìˆ˜í•¨ìˆ˜) make_num_child
        def make_num_child(header, field, fmt_digits=0, suffix=''):
            return {
                "headerName": header, "field": field,
                "type": ["numericColumn","customNumericFormat"],
                "valueFormatter": JsCode(
                    f"function(params){{"
                    f"  return params.value!=null?"
                    f"params.value.toLocaleString(undefined,{{minimumFractionDigits:{fmt_digits},maximumFractionDigits:{fmt_digits}}})+'{suffix}':'';"
                    f"}}"
                ),
                "cellStyle": JsCode("params=>({textAlign:'right'})")
            }

        # (í•„ìˆ˜í•¨ìˆ˜) add_summary - deprecated !!
        # def add_summary(grid_options: dict, df: pd.DataFrame, agg_map: dict[str, str]): #'sum'|'avg'|'mid'
        #     summary: dict[str, float] = {}
        #     for col, op in agg_map.items():
        #         if op == 'sum':
        #             summary[col] = int(df[col].sum())
        #         elif op == 'avg':
        #             summary[col] = float(df[col].mean())
        #         elif op == 'mid':
        #             summary[col] = float(df[col].median())
        #         else:
        #             summary[col] = "-"  # ì—ëŸ¬ ë°œìƒì‹œ, "-"ë¡œ í‘œê¸°í•˜ê³  raise error í•˜ì§€ ì•ŠìŒ
                    
        #     grid_options['pinnedBottomRowData'] = [summary]
        #     return grid_options

        # (í•„ìˆ˜í•¨ìˆ˜) add_summary
        def add_summary(grid_options: dict, df: pd.DataFrame, agg_map: dict[str, str]):
            summary: dict[str, float | str] = {}
            for col, op in agg_map.items():
                val = None
                try:
                    if op == 'sum':
                        val = df[col].sum()
                    elif op == 'avg':
                        val = df[col].mean()
                    elif op == 'mid':
                        val = df[col].median()
                except:
                    val = None

                # NaN / Inf / numpy íƒ€ì… â†’ None or native íƒ€ì…ìœ¼ë¡œ ì²˜ë¦¬
                if val is None or isinstance(val, float) and (math.isnan(val) or math.isinf(val)):
                    summary[col] = None
                else:
                    # numpy íƒ€ì… ì œê±°
                    if isinstance(val, (np.integer, np.int64, np.int32)):
                        summary[col] = int(val)
                    elif isinstance(val, (np.floating, np.float64, np.float32)):
                        summary[col] = float(round(val, 2))
                    else:
                        summary[col] = val

            grid_options['pinnedBottomRowData'] = [summary]
            return grid_options

        # date_col
        date_col = {
            "headerName": "ë‚ ì§œ",
            "field": "event_date",
            "pinned": "left",
            "width": 100,
            "cellStyle": JsCode("params=>({textAlign:'left'})")
        }

        # (use_parent) flat_cols
        flat_cols = [
            date_col,
            make_num_child("ë§¤ì¶œ",   "ord_amount_sum"),
            make_num_child("ì£¼ë¬¸ìˆ˜", "ord_count_sum"),
            make_num_child("AOV",    "AOV"),
            make_num_child("ê´‘ê³ ë¹„", "cost_gross_sum"),
            make_num_child("ROAS",   "ROAS", fmt_digits=2, suffix='%'),
            make_num_child("ì„¸ì…˜ìˆ˜", "session_count"),
            make_num_child("CVR",    "CVR", fmt_digits=2, suffix='%'),
        ]

        # (use_parent) grouped_cols
        grouped_cols = [
            date_col,
            {
                "headerName": "COST",
                "children": [
                    make_num_child("ë§¤ì¶œ",   "ord_amount_sum"),
                    make_num_child("ì£¼ë¬¸ìˆ˜", "ord_count_sum"),
                    make_num_child("AOV",    "AOV"),
                ]
            },
            {
                "headerName": "PERP",
                "children": [
                    make_num_child("ê´‘ê³ ë¹„", "cost_gross_sum"),
                    make_num_child("ROAS",   "ROAS", fmt_digits=2, suffix='%'),
                ]
            },
            {
                "headerName": "GA",
                "children": [
                    make_num_child("ì„¸ì…˜ìˆ˜", "session_count"),
                    make_num_child("CVR",    "CVR", fmt_digits=2, suffix='%'),
                ]
            },
        ]

        # (use_parent)
        column_defs = grouped_cols if use_parent else flat_cols
        
        # grid_options & ë Œë”ë§
        grid_options = {
            "columnDefs": column_defs,
            "defaultColDef": {"sortable": True, "filter": True, "resizable": True},
            "headerHeight": 30,
            "groupHeaderHeight": 30,
        }

        # (add_summary) grid_options & ë Œë”ë§ -> í•©ê³„ í–‰ ì¶”ê°€í•˜ì—¬ ì¬ë Œë”ë§
        grid_options = add_summary(
            grid_options,
            df2,
            {
                'ord_amount_sum': 'sum',
                'ord_count_sum' : 'sum',
                'AOV'           : 'avg',
                'cost_gross_sum': 'sum',
                'ROAS'          : 'avg',
                'session_count' : 'sum',
                'CVR'           : 'avg',
            }
        )

        AgGrid(
            df2,
            gridOptions=grid_options,
            height=height,
            fit_columns_on_grid_load=False,  # Trueë©´ ì „ì²´ë„“ì´ì—ì„œ ê· ë“±ë¶„ë°° 
            theme="streamlit-dark" if st.get_option("theme.base") == "dark" else "streamlit",
            allow_unsafe_jscode=True
        )


    # íƒ­ ê°„ê²© CSS
    st.markdown("""
        <style>
          [role="tablist"] [role="tab"] { margin-right: 1rem; }
        </style>
    """, unsafe_allow_html=True)


    # 1) í†µí•© ì˜ì—­ (íƒ­ X)
    st.markdown("<h5 style='margin:0'><span style='color:#FF4B4B;'>í†µí•©</span> ë§¤ì¶œ ë¦¬í¬íŠ¸</h5>", unsafe_allow_html=True)  
    st.markdown(":gray-badge[:material/Info: Info]ã…¤ì„¤ëª…", unsafe_allow_html=True)

    render_aggrid(df_total)
    
    # 2) ìŠ¬ë¦½í¼ ì˜ì—­ (íƒ­ êµ¬ì„±)
    st.header(" ") # ê³µë°±ìš©
    st.markdown("<h5 style='margin:0'><span style='color:#FF4B4B;'>ìŠ¬ë¦½í¼</span> ë§¤ì¶œ ë¦¬í¬íŠ¸</h5>", unsafe_allow_html=True)  
    st.markdown(":gray-badge[:material/Info: Info]ã…¤ì„¤ëª…", unsafe_allow_html=True)

    tabs = st.tabs(["ìŠ¬ë¦½í¼ í†µí•©", "ìŠ¬ë¦½í¼ ë§¤íŠ¸ë¦¬ìŠ¤", "ìŠ¬ë¦½í¼ í”„ë ˆì„"])
    with tabs[0]:
        render_aggrid(df_slp)
    with tabs[1]:
        render_aggrid(df_slp_mat)
    with tabs[2]:
        render_aggrid(df_slp_frm)

    # 3) ëˆ„ì–´ ì˜ì—­ (íƒ­ êµ¬ì„±)
    st.header(" ") # ê³µë°±ìš©
    st.markdown("<h5 style='margin:0'><span style='color:#FF4B4B;'>ëˆ„ì–´</span> ë§¤ì¶œ ë¦¬í¬íŠ¸</h5>", unsafe_allow_html=True)  
    st.markdown(":gray-badge[:material/Info: Info]ã…¤ì„¤ëª…", unsafe_allow_html=True)

    tabs = st.tabs(["ëˆ„ì–´ í†µí•©", "ëˆ„ì–´ ë§¤íŠ¸ë¦¬ìŠ¤", "ëˆ„ì–´ í”„ë ˆì„"])
    with tabs[0]:
        render_aggrid(df_nor)
    with tabs[1]:
        render_aggrid(df_nor_mat)
    with tabs[2]:
        render_aggrid(df_nor_frm)


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì‹œê°í™” ì°¨íŠ¸
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.header(" ") # ê³µë°±ìš©
    st.markdown("<h5 style='margin:0'>ë¦¬í¬íŠ¸ ì‹œê°í™”</h5>", unsafe_allow_html=True)  
    st.markdown(":gray-badge[:material/Info: Info]ã…¤ì„¤ëª…", unsafe_allow_html=True)
    dfs = {
        "í†µí•© ë¦¬í¬íŠ¸":    df_total,
        "ìŠ¬ë¦½í¼ í†µí•©":    df_slp,
        "ìŠ¬ë¦½í¼ ë§¤íŠ¸ë¦¬ìŠ¤": df_slp_mat,
        "ìŠ¬ë¦½í¼ í”„ë ˆì„":   df_slp_frm,
        "ëˆ„ì–´ í†µí•©":     df_nor,
        "ëˆ„ì–´ ë§¤íŠ¸ë¦¬ìŠ¤":  df_nor_mat,
        "ëˆ„ì–´ í”„ë ˆì„":    df_nor_frm,
    }
    metrics = ["ë§¤ì¶œ","ì£¼ë¬¸ìˆ˜","AOV","ê´‘ê³ ë¹„","ROAS","ì„¸ì…˜ìˆ˜","CVR"]
    col_map = {
        "ë§¤ì¶œ":   "ord_amount_sum",
        "ì£¼ë¬¸ìˆ˜": "ord_count_sum",
        "AOV":    "AOV",
        "ê´‘ê³ ë¹„": "cost_gross_sum",
        "ROAS":   "ROAS",
        "ì„¸ì…˜ìˆ˜": "session_count",
        "CVR":    "CVR"
    }
    left_labels  = {"ë§¤ì¶œ","ì£¼ë¬¸ìˆ˜","AOV","ê´‘ê³ ë¹„","ì„¸ì…˜ìˆ˜"}
    right_labels = {"ROAS","CVR"}

    # 1) ì„ íƒ UI: ì¢Œìš° 3:7
    col1, col2 = st.columns([3, 7])
    with col1:
        df_key = st.selectbox("ë¦¬í¬íŠ¸ ì„ íƒ", list(dfs.keys()))
    with col2:
        sel = st.multiselect("ì»¬ëŸ¼ ì„ íƒ", metrics, default=["AOV", "ROAS"])

    # 2) ì°¨íŠ¸ ë¡œì§
    if not sel:
        st.warning("í•˜ë‚˜ ì´ìƒì˜ ì»¬ëŸ¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        df_sel   = dfs[df_key].sort_values("event_date")
        df_chart = df_sel.assign(
            AOV  = lambda x: x.ord_amount_sum / x.ord_count_sum,
            ROAS = lambda x: x.ord_amount_sum / x.cost_gross_sum * 100,
            CVR  = lambda x: x.ord_count_sum  / x.session_count   * 100,
        )

        fig = make_subplots(specs=[[{"secondary_y": True}]])

        for m in sel:
            col = col_map[m]
            is_right = (m in right_labels)
            fig.add_trace(
                go.Scatter(
                    x=df_chart["event_date"],
                    y=df_chart[col],
                    name=m,
                    mode="lines+markers",
                    line=dict(dash="dash" if is_right else "solid")
                ),
                secondary_y=is_right
            )

        # 3) ë ˆì´ì•„ì›ƒ
        fig.update_layout(
            title=f"{df_key}  -  {' / '.join(sel)} ì¶”ì´",
            # xaxis_title="ë‚ ì§œ",
            xaxis=dict(tickformat="%mì›” %dì¼"),
            legend=dict(
                orientation="h",
                x=1, y=1.1,
                xanchor="right",
                yanchor="bottom"
            ),
            margin=dict(t=100, b=20, l=20, r=20)
        )
        left_title  = "Â·".join([m for m in sel if m in left_labels])
        right_title = "Â·".join([m for m in sel if m in right_labels])
        if left_title:
            fig.update_yaxes(title_text=left_title, secondary_y=False)
        if right_title:
            fig.update_yaxes(title_text=right_title, secondary_y=True)

        st.plotly_chart(fig, use_container_width=True)



if __name__ == "__main__":
    main()