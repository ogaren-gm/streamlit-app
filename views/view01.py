# ì„œí¬_ìµœì‹ ìˆ˜ì •ì¼_25-08-19

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import importlib
from datetime import datetime, timedelta
import modules.bigquery
importlib.reload(modules.bigquery)
from modules.bigquery import BigQuery
from st_aggrid import AgGrid, GridOptionsBuilder
from st_aggrid.shared import JsCode
import io
from google.oauth2.service_account import Credentials
import gspread
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import math

import sys
import modules.style
importlib.reload(sys.modules['modules.style'])
from modules.style import style_format, style_cmap
from pandas.tseries.offsets import MonthEnd
from zoneinfo import ZoneInfo



def main():
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ìŠ¤íŠ¸ë¦¼ë¦¿ í˜ì´ì§€ ì„¤ì •
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    st.markdown(
        """
        <style>
            /* ì „ì²´ ì»¨í…Œì´ë„ˆì˜ íŒ¨ë”© ì¡°ì • */
            .block-container {
                max-width: 100% !important;
                padding-top: 1rem;   /* ìœ„ìª½ ì—¬ë°± */
                padding-bottom: 8rem;
                padding-left: 5rem; 
                padding-right: 4rem; 
            }
        </style>
        """,
        unsafe_allow_html=True
    )    


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì‚¬ì´ë“œë°” í•„í„° ì„¤ì •
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.sidebar.header("Filter")
    
    today = datetime.now().date()
    default_end = today - timedelta(days=1)
    default_start = today - timedelta(days=7)
    start_date, end_date = st.sidebar.date_input(
        "ê¸°ê°„ ì„ íƒ",
        value=[default_start, default_end],
        max_value=default_end
    )
    cs = start_date.strftime("%Y%m%d")
    ce = end_date.strftime("%Y%m%d")

    @st.cache_data(ttl=3600)
    def load_data(cs: str, ce: str) -> pd.DataFrame:
        
        # 1) tb_media
        bq = BigQuery(projectCode="sleeper", custom_startDate=cs, custom_endDate=ce)
        df_bq = bq.get_data("tb_media")        
        df_bq["event_date"] = pd.to_datetime(df_bq["event_date"], format="%Y%m%d")
        parts = df_bq['campaign_name'].str.split('_', n=5, expand=True)
        df_bq['campaign_name_short'] = df_bq['campaign_name']
        mask = parts[5].notna()
        df_bq.loc[mask, 'campaign_name_short'] = (
            parts.loc[mask, :4].apply(lambda r: '_'.join(r.dropna().astype(str)), axis=1)
        )
        # 2) Google Sheet
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        
        try: 
            creds = Credentials.from_service_account_file("C:/_code/auth/sleeper-461005-c74c5cd91818.json", scopes=scope)
        except: # ë°°í¬ìš© (secrets.toml)
            sa_info = st.secrets["sleeper-462701-admin"]
            if isinstance(sa_info, str):  # í˜¹ì‹œ ë¬¸ìì—´(JSON)ë¡œ ì €ì¥í–ˆì„ ê²½ìš°
                sa_info = json.loads(sa_info)
            creds = Credentials.from_service_account_info(sa_info, scopes=scope)
            
        gc = gspread.authorize(creds)
        sh = gc.open_by_url('https://docs.google.com/spreadsheets/d/11ov-_o6Lv5HcuZo1QxrKOZnLtnxEKTiV78OFBZzVmWA/edit')
        df_sheet = pd.DataFrame(sh.worksheet('parse').get_all_records())
        
        # merge (1+2)
        merged = df_bq.merge(df_sheet, how='left', on='campaign_name_short')
        
        # # cost_gross
        # merged['cost_gross'] = np.where(
        #     merged['media_name'].isin(['GOOGLE','META']), merged['cost']*1.1/0.98, merged['cost']
        # )
        
        # cost_gross(v2)
        merged['cost_gross'] = np.where(
            merged['event_date'] < pd.to_datetime("2025-11-06"),
            np.where(
                merged['media_name'].isin(['GOOGLE', 'META']),
                merged['cost'] * 1.1 / 0.98,
                merged['cost']
            ),
            np.where(
                merged['media_name'].isin(['GOOGLE', 'META']),
                merged['cost'] * 1.1 / 0.955,
                merged['cost']
            )
        )
        
        # handle NSA
        cond = (
            (merged['media_name']=='NSA') & merged['utm_source'].isna() &
            merged['utm_medium'].isna() & merged['media_name_type'].isin(['RSA_AD','TEXT_45'])
        )
        merged.loc[cond, ['utm_source','utm_medium']] = ['naver','search-nonmatch']
        
        # 3) tb_sleeper_psi
        df_psi = bq.get_data("tb_sleeper_psi")
        df_psi["event_date"] = pd.to_datetime(df_psi["event_date"], format="%Y%m%d")
        df_psi = (df_psi
                .assign(event_date=pd.to_datetime(df_psi["event_date"], format="%Y%m%d"))
                .groupby("event_date", as_index=False)
                .agg(session_count=("pseudo_session_id", "nunique")))
        
        last_updated_time__media = df_bq["event_date"].max()
        last_updated_time__GA    = df_psi["event_date"].max()


        return merged, df_psi, last_updated_time__media, last_updated_time__GA

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    with st.spinner("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”."):
        df_merged, df_psi, last_updated_time__media, last_updated_time__GA = load_data(cs, ce)
    

    # ê³µí†µí•©ìˆ˜ (1) ì¼ìë³„ ê´‘ê³ ë¹„, ì„¸ì…˜ìˆ˜ (íŒŒìƒë³€ìˆ˜ëŠ” í•´ë‹¹ í•¨ìˆ˜ê°€ ê³„ì‚°í•˜ì§€ ì•ŠìŒ -> ë‚˜ì¤‘ì— ê³„ì‚°í•¨)
    def pivot_cstSes(
        df: pd.DataFrame,
        brand_type: str | None = None,
        product_type: str | None = None
        ) -> pd.DataFrame:
        """
        1) í•¨ìˆ˜ ì‘ì„±
        :  pivot_cstSes(df, brand_type="ìŠ¬ë¦½í¼", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
        2) ê²°ê³¼ ì»¬ëŸ¼
        :  ['event_date', 'session_count', 'cost_gross_sum']
        """
        df_f = df.copy()

        if brand_type:
            df_f = df_f[df_f['brand_type'].astype(str).str.contains(brand_type, regex=True, na=False)]
        if product_type:
            df_f = df_f[df_f['product_type'].astype(str).str.contains(product_type, regex=True, na=False)]

        df_f['event_date'] = pd.to_datetime(df_f['event_date'], errors='coerce')
        df_f['event_date'] = df_f['event_date'].dt.strftime('%Y-%m-%d')

        pivot = (
            df_f
            .groupby('event_date', as_index=False) # ë°˜ë“œì‹œ Falseë¡œ ìœ ì§€ (ê·¸ë˜ì•¼ ì»¬ëŸ¼ì— ì‚´ì•„ìˆìŒ)
            .agg(
                session_count=('pseudo_session_id', 'sum'),
                cost_gross_sum=('cost_gross', 'sum')
            )
            .reset_index(drop=True)
        )
        return pivot


    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    
    try: 
        creds = Credentials.from_service_account_file("C:/_code/auth/sleeper-461005-c74c5cd91818.json", scopes=scope)
    except: # ë°°í¬ìš© (secrets.toml)
        sa_info = st.secrets["sleeper-462701-admin"]
        if isinstance(sa_info, str):  # í˜¹ì‹œ ë¬¸ìì—´(JSON)ë¡œ ì €ì¥í–ˆì„ ê²½ìš°
            sa_info = json.loads(sa_info)
        creds = Credentials.from_service_account_info(sa_info, scopes=scope)

    
    gc = gspread.authorize(creds)
    sh = gc.open_by_url('https://docs.google.com/spreadsheets/d/1chXeCek1UZPyCr18zLe7lV-8tmv6YPWK6cEqAJcDPqs/edit')
    df_order = pd.DataFrame(sh.worksheet('ì˜¨ì˜¤í”„ë¼ì¸_ì¢…í•©').get_all_records())
    df_order = df_order.rename(columns={"íŒë§¤ìˆ˜ëŸ‰": "ì£¼ë¬¸ìˆ˜"})  # ì»¬ëŸ¼ ì´ë¦„ ì¹˜í™˜
    def convert_dot_date(x):
        try:
            # 1. ë¬¸ìì—´ë¡œ ë³€í™˜ + ê³µë°± ì œê±°
            s = str(x).replace(" ", "")
            # 2. ë§ˆì¹¨í‘œ ê¸°ì¤€ split
            parts = s.split(".")
            if len(parts) == 3:
                y = parts[0]
                m = parts[1].zfill(2)
                d = parts[2].zfill(2)
                return pd.to_datetime(f"{y}-{m}-{d}", format="%Y-%m-%d", errors="coerce")
            return pd.NaT
        except:
            return pd.NaT
    df_order["ì£¼ë¬¸ì¼"] = pd.to_datetime(df_order["ì£¼ë¬¸ì¼"].apply(convert_dot_date), format="%Y-%m-%d", errors="coerce")
    df_order["ì‹¤ê²°ì œê¸ˆì•¡"] = pd.to_numeric(df_order["ì‹¤ê²°ì œê¸ˆì•¡"], errors='coerce')
    df_order["ì£¼ë¬¸ìˆ˜"] = pd.to_numeric(df_order["ì£¼ë¬¸ìˆ˜"], errors='coerce')
    df_order = df_order.dropna(subset=["ì£¼ë¬¸ì¼"])


    # ê³µí†µí•©ìˆ˜ (2) ì¼ìë³„ ë§¤ì¶œ, ì£¼ë¬¸ìˆ˜ (íŒŒìƒë³€ìˆ˜ëŠ” í•´ë‹¹ í•¨ìˆ˜ê°€ ê³„ì‚°í•˜ì§€ ì•ŠìŒ)
    def pivot_ord(
        df: pd.DataFrame,
        brand_type: str | None = None,
        product_type: str | None = None
        ) -> pd.DataFrame:
        """
        1) í•¨ìˆ˜ ì‘ì„±
        :  pivot_ord(df, brand_type="ìŠ¬ë¦½í¼", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
        2) ê²°ê³¼ ì»¬ëŸ¼
        :  ['ì£¼ë¬¸ì¼', 'ord_amount_sum', 'ord_count_sum']
        
        """
        df_f = df.copy()

        if brand_type:
            df_f = df_f[df_f['ë¸Œëœë“œ'].astype(str).str.contains(brand_type, regex=True, na=False)]
        if product_type:
            df_f = df_f[df_f['ì¹´í…Œê³ ë¦¬'].astype(str).str.contains(product_type, regex=True, na=False)]
            
        df_f['ì£¼ë¬¸ì¼'] = pd.to_datetime(df_f['ì£¼ë¬¸ì¼'], errors='coerce')
        df_f['ì£¼ë¬¸ì¼'] = df_f['ì£¼ë¬¸ì¼'].dt.strftime('%Y-%m-%d')

        pivot = (
            df_f
            .groupby('ì£¼ë¬¸ì¼', as_index=False) # ë°˜ë“œì‹œ Falseë¡œ ìœ ì§€ (ê·¸ë˜ì•¼ ì»¬ëŸ¼ì— ì‚´ì•„ìˆìŒ)
            .agg(
                ord_amount_sum=('ì‹¤ê²°ì œê¸ˆì•¡', 'sum'),
                ord_count_sum=('ì£¼ë¬¸ìˆ˜', 'sum')
            )
            .reset_index(drop=True)
        )
        return pivot

    def summary_row(df):
        sum_row = df.iloc[:, 1:].sum(numeric_only=True)
        avg_row = df.iloc[:, 1:].mean(numeric_only=True)

        # í•©ê³„/í‰ê·  í–‰ DataFrame
        summary = pd.DataFrame([
            ["í•©ê³„"] + sum_row.astype(int).tolist(),
            ["í‰ê· "] + avg_row.round(1).tolist()
        ], columns=df.columns)
        
        return summary



    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë°ì´í„°í”„ë ˆì„ ìƒì„± (JOINì¸ ê²½ìš°ëŠ” ê³ ì˜ë¡œ "ì£¼ë¬¸ì¼" ì»¬ëŸ¼ ë–¨êµ´ ëª©ì )
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1-1) ìŠ¬ë¦½í¼
    _sctSes_slp      = pivot_cstSes(df_merged, brand_type="ìŠ¬ë¦½í¼")
    _ord_slp         = pivot_ord(df_order,     brand_type="ìŠ¬ë¦½í¼")
    df_slp           = _sctSes_slp.join(_ord_slp.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')
    
    # 1-2) ìŠ¬ë¦½í¼ & ë§¤íŠ¸ë¦¬ìŠ¤
    _sctSes_slp_mat  = pivot_cstSes(df_merged, brand_type="ìŠ¬ë¦½í¼", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
    _ord_slp_mat     = pivot_ord(df_order,     brand_type="ìŠ¬ë¦½í¼", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
    df_slp_mat       = _sctSes_slp_mat.join(_ord_slp_mat.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')
    
    # 1-3) ìŠ¬ë¦½í¼ & í”„ë ˆì„
    _sctSes_slp_frm  = pivot_cstSes(df_merged, brand_type="ìŠ¬ë¦½í¼", product_type="í”„ë ˆì„")
    _ord_slp_frm     = pivot_ord(df_order,     brand_type="ìŠ¬ë¦½í¼", product_type="í”„ë ˆì„")
    df_slp_frm       = _sctSes_slp_frm.join(_ord_slp_frm.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')
    
    # 2-1) ëˆ„ì–´ 
    _sctSes_nor      = pivot_cstSes(df_merged, brand_type="ëˆ„ì–´")
    _ord_nor         = pivot_ord(df_order,     brand_type="ëˆ„ì–´")
    df_nor           = _sctSes_nor.join(_ord_nor.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')
    
    # 2-2) ëˆ„ì–´ & ë§¤íŠ¸ë¦¬ìŠ¤
    _sctSes_nor_mat  = pivot_cstSes(df_merged, brand_type="ëˆ„ì–´", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
    _ord_nor_mat     = pivot_ord(df_order,     brand_type="ëˆ„ì–´", product_type="ë§¤íŠ¸ë¦¬ìŠ¤")
    df_nor_mat       = _sctSes_nor_mat.join(_ord_nor_mat.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')
    
    # 2-3) ëˆ„ì–´ & í”„ë ˆì„
    _sctSes_nor_frm  = pivot_cstSes(df_merged, brand_type="ëˆ„ì–´", product_type="í”„ë ˆì„")
    _ord_nor_frm     = pivot_ord(df_order,     brand_type="ëˆ„ì–´", product_type="í”„ë ˆì„")
    df_nor_frm       = _sctSes_nor_frm.join(_ord_nor_frm.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')
    
    # 3) í†µí•© ë°ì´í„° (3ë²ˆ ì´ì§€ë§Œ, ìœ„ì¹˜ìƒ ìµœìƒìœ„ì— ìœ„ì¹˜í•¨ ì£¼ì˜)
    _df_total_psi    = df_psi  # ì´ë¯¸ ë‚ ì§œë³„ë¡œ ì„¸ì…˜ìˆ˜ê°€ í”¼ë²—ë˜ì–´ ìˆëŠ” ë°ì´í„°í”„ë ˆì„
    _df_total_cost   = df_merged.groupby('event_date', as_index=False).agg(cost_gross_sum=('cost_gross','sum')).sort_values('event_date')  # df_mergedì—ì„œ cost_grossë§Œ ê°€ì ¸ì˜´
    _df_total_order  = df_order.groupby('ì£¼ë¬¸ì¼', as_index=False).agg(ord_amount_sum=('ì‹¤ê²°ì œê¸ˆì•¡','sum'), ord_count_sum  =('ì£¼ë¬¸ìˆ˜', 'sum')).sort_values('ì£¼ë¬¸ì¼')
    _df_total_order  = _df_total_order.rename(columns={'ì£¼ë¬¸ì¼':'event_date'}) # ì£¼ë¬¸ì¼ -> event_date
    df_total = (_df_total_psi
                .merge(_df_total_cost,  on='event_date', how='left')
                .merge(_df_total_order, on='event_date', how='left')
                )

    
    # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ì´ ë™ì¼í•œ íŒŒìƒ ì§€í‘œë¥¼ ê°€ì§
    def decorate_df(df: pd.DataFrame) -> pd.DataFrame:
        # í‚¤ì—ëŸ¬ ë°©ì§€
        required = ["event_date", "ord_amount_sum", "ord_count_sum", "cost_gross_sum", "session_count"]
        for c in required:
            if c not in df.columns:
                df[c] = 0  
        num_cols = ["ord_amount_sum", "ord_count_sum", "cost_gross_sum", "session_count"]
        df[num_cols] = df[num_cols].apply(pd.to_numeric, errors="coerce").fillna(0)
            
        # íŒŒìƒì§€í‘œ ìƒì„±
        df['CVR']    =  (df['ord_count_sum']  / df['session_count']  * 100).round(2)
        df['AOV']    =  (df['ord_amount_sum'] / df['ord_count_sum']  ).round(0)
        df['ROAS']   =  (df['ord_amount_sum'] / df['cost_gross_sum'] * 100).round(2)
        
        # ì»¬ëŸ¼ ìˆœì„œ ì§€ì •
        df = df[['event_date','ord_amount_sum','ord_count_sum','AOV','cost_gross_sum','ROAS','session_count','CVR']]
        
        # ìë£Œí˜• ì›Œì‹±
        df['event_date'] = pd.to_datetime(df['event_date'], errors='coerce').dt.strftime('%Y-%m-%d')
        num_cols = df.select_dtypes(include=['number']).columns
        df[num_cols] = (df[num_cols].replace([np.inf, -np.inf], np.nan).fillna(0))        

        # ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½ - ë‹¨ì¼ ì¸ë±ìŠ¤
        # rename_map = {
        #     "event_date":       "ë‚ ì§œ",
        #     "ord_amount_sum":   "ë§¤ì¶œ",
        #     "ord_count_sum":    "ì£¼ë¬¸ìˆ˜",
        #     "AOV":              "AOV(í‰ê· ì£¼ë¬¸ê¸ˆì•¡)",
        #     "cost_gross_sum":   "ê´‘ê³ ë¹„",
        #     "ROAS":             "ROAS(ê´‘ê³ ìˆ˜ìµë¥ )",
        #     "session_count":    "ì„¸ì…˜ìˆ˜",
        #     "CVR":              "CVR(ì „í™˜ìœ¨)",
        # }
        # apply_map = {k: v for k, v in rename_map.items() if k in df.columns}
        # df = df.rename(columns=apply_map)
        
        # í•©ê³„ & í‰ê·  í–‰ ì¶”ê°€
        sum_row = df[num_cols].sum().to_frame().T
        sum_row['event_date'] = "í•©ê³„"
        mean_row = df[num_cols].mean().to_frame().T
        mean_row['event_date'] = "í‰ê· "
        df = pd.concat([df, sum_row, mean_row], ignore_index=True)

        # ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½ - ë©€í‹° ì¸ë±ìŠ¤
        df.columns = pd.MultiIndex.from_tuples([
            ("ê¸°ë³¸ì •ë³´",      "ë‚ ì§œ"),              # event_date
            ("COST",        "ë§¤ì¶œ"),               # ord_amount_sum
            ("COST",        "ì£¼ë¬¸ìˆ˜"),             # ord_count_sum
            ("COST",        "AOV"),    # AOV
            ("MEDIA", "ê´‘ê³ ë¹„"),              # cost_gross_sum
            ("MEDIA", "ROAS"),     # ROAS
            ("GA",          "ì„¸ì…˜ìˆ˜"),              # session_count
            ("GA",          "CVR"),          # CVR
        ], names=["ê·¸ë£¹","ì§€í‘œ"])  # ìƒë‹¨ ë ˆë²¨ ì´ë¦„(ì˜µì…˜)        
        
        return df

    def render_style(target_df):
        styled = style_format(
            decorate_df(target_df),
            decimals_map={
                ("COST",        "ë§¤ì¶œ"): 0,
                ("COST",        "ì£¼ë¬¸ìˆ˜"): 0,
                ("COST",        "AOV"): 0,
                ("MEDIA", "ê´‘ê³ ë¹„"): 0,
                ("MEDIA", "ROAS"): 1,
                ("GA",          "ì„¸ì…˜ìˆ˜"): 0,
                ("GA",          "CVR"): 1,
            },
            suffix_map={
                ("MEDIA", "ROAS"): " %",
                ("GA",          "CVR"): " %",
        }
        )
        styled2 = style_cmap(
            styled,
            gradient_rules=[
                {"col": ("COST",   "ë§¤ì¶œ"), "cmap":"Greens", "low":0.0, "high":0.3},
                {"col": ("MEDIA", "ê´‘ê³ ë¹„"), "cmap":"Blues", "low":0.0, "high":0.3},
                {"col": ("GA",          "ì„¸ì…˜ìˆ˜"), "cmap":"OrRd",  "low":0.0, "high":0.3},

            ],
        )
        st.dataframe(styled2, use_container_width=True, hide_index=True, row_height=30)



    # íƒ­ ê°„ê²© CSS
    st.markdown("""
        <style>
          [role="tablist"] [role="tab"] { margin-right: 1rem; }
        </style>
    """, unsafe_allow_html=True)



    # (25.11.10) ì œëª© + ì„¤ëª… + ì—…ë°ì´íŠ¸ ì‹œê° + ìºì‹œì´ˆê¸°í™” 
    # last_updated_time__media, last_updated_time__GA
    # ì œëª©
    st.subheader("ë§¤ì¶œ ì¢…í•© ëŒ€ì‹œë³´ë“œ")

    if "refresh" in st.query_params:
        st.cache_data.clear()
        st.query_params.clear()   # íŒŒë¼ë¯¸í„° ì œê±°
        st.rerun()
        
    # ì„¤ëª…
    col1, col2 = st.columns([0.65, 0.35], vertical_alignment="center")
    with col1:
        st.markdown(
            """
            <div style="    
                font-size:14px;       
                line-height:1.5;      
            ">
            <b>ë§¤ì¶œ Â· ë§¤ì²´ Â· ìœ ì…</b> ë°ì´í„°ë¥¼ íš¨ìœ¨ ì§€í‘œì™€ í•¨ê»˜ í•œëˆˆì— í™•ì¸í•˜ëŠ” 
            <b>ê°€ì¥ ê°œê´„ì ì¸ ëŒ€ì‹œë³´ë“œ</b>ì…ë‹ˆë‹¤.<br>
            </div>
            <div style="
                color:#6c757d;        
                font-size:14px;       
                line-height:2.0;      
            ">
            â€» GAÃ—MEDIA D-1 ë§¤ì¹­ ë°ì´í„°ëŠ” ë§¤ì¼ 15ì‹œ ~ 16ì‹œ ì‚¬ì´ì— ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.
            </div>
            """,
            unsafe_allow_html=True
        )
        
    with col2:
        # last_updated_time__media -> lut_media
        if isinstance(last_updated_time__media, str):
            lut_m = datetime.strptime(last_updated_time__media, "%Y%m%d")
        else:
            lut_m = last_updated_time__media
        lut_media = lut_m.date()
        
        # last_updated_time__GA -> lut_ga
        if isinstance(last_updated_time__GA, str):
            lut_g = datetime.strptime(last_updated_time__GA, "%Y%m%d")
        else:
            lut_g = last_updated_time__GA
        lut_ga = lut_g.date()
        
        now_kst   = datetime.now(ZoneInfo("Asia/Seoul"))
        today_kst = now_kst.date()
        delta_days__lut_media = (today_kst - lut_media).days
        delta_days__lut_ga    = (today_kst - lut_ga).days

        
        # lut_media ê¸°ë³¸ê°’
        # msg__lut_media = f"{lut_media.strftime('%mì›” %dì¼')} (D-{delta_days__lut_media})"
        msg__lut_media    = f"D-{delta_days__lut_media} ì—…ë°ì´íŠ¸ ì™„ë£Œ"
        sub_bg__lut_media = "#fff7ed"
        sub_bd__lut_media = "#fdba74"
        sub_fg__lut_media = "#c2410c" 
        
        # # lut_ga ê¸°ë³¸ê°’
        # # msg__lut_ga    = f"{lut_ga.strftime('%mì›” %dì¼')} (D-{delta_days__lut_ga})"
        # msg__lut_ga    = f"D-{delta_days__lut_ga} ì—…ë°ì´íŠ¸ ì™„ë£Œ"
        # sub_bg__lut_ga = "#fff7ed"
        # sub_bd__lut_ga = "#fdba74"
        # sub_fg__lut_ga = "#c2410c"

        
        # ë Œë”ë§
        st.markdown(
            f"""
            <div style="display:flex;justify-content:flex-end;align-items:center;gap:8px;">
            <span style="
                display:inline-flex;align-items:center;justify-content:center;
                height:26px;padding:0 10px;
                font-size:13px;line-height:1.1;
                color:{sub_fg__lut_media};background:{sub_bg__lut_media};border:1px solid {sub_bd__lut_media};
                border-radius:10px;white-space:nowrap;">
                ğŸ“¢ {msg__lut_media}
            </span>
            </span>
            <a href="?refresh=1" title="ìºì‹œ ì´ˆê¸°í™”" style="text-decoration:none;vertical-align:middle;">
                <span style="
                display:inline-flex;align-items:center;justify-content:center;
                height:26px;padding:0 8px;
                font-size:13px;line-height:1;
                color:#475569;background:#f8fafc;border:1px solid #e2e8f0;
                border-radius:10px;white-space:nowrap;">
                ğŸ—‘ï¸ ìºì‹œ ì´ˆê¸°í™”
                </span>
            </a>
            </div>
            """,
            unsafe_allow_html=True
        )
    

    st.divider()

    # st.markdown("""
    # <div style="
    #     background-color:#F0F2F6;
    #     border-radius:8px;
    #     padding:12px 16px;
    #     color:#333;
    #     font-size:0.9rem;
    #     line-height:1.5;
    # ">
    # âœ… <b>ì •ë³´</b><br>
    # MEDIA ë°ì´í„°ëŠ” 
    # </div>
    # """, unsafe_allow_html=True)
    

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì‹œê°í™” (ì‹ ê·œ - ê¸°ê°„ ì¡°ì • ê°œë³„~)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown(" ")
    st.markdown("<h5 style='margin:0'>ì‹œê³„ì—´ ë¶„ì„</h5>", unsafe_allow_html=True)  
    st.markdown(":gray-badge[:material/Info: Info]ã…¤ì£¼ìš” ë§¤ì¶œ ì§€í‘œì˜ ì¶”ì´ë¥¼ ìŠ¤ë¬´ë”© ê¸°ë²•ìœ¼ë¡œ ì •ì œí•´, ë‹¨ê¸° ë³€ë™ ëŒ€ì‹  í•µì‹¬ íë¦„ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.", unsafe_allow_html=True)

    with st.expander("ìŠ¤ë¬´ë”©ì€ ì‹œê³„ì—´ ë¶„ì„ì—ì„œ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ê³  ì¶”ì„¸ë¥¼ ë„ì¶œí•˜ëŠ” ë°¥ë²•ë¡ ì…ë‹ˆë‹¤. ", expanded=False):
        st.markdown("""
    - **MA (ì´ë™í‰ê· )** : ê¸°ë³¸ ìŠ¤ë¬´ë”©, ìµœê·¼ Sì¼ í‰ê· ìœ¼ë¡œ ìš”ë™ì„ ëˆŒëŸ¬ í° íë¦„ë§Œ ë³´ì´ê²Œ í•©ë‹ˆë‹¤.
    - **EWMA (ì§€ìˆ˜ê°€ì¤‘ ì´ë™í‰ê· )** : ê°€ì¤‘ ìŠ¤ë¬´ë”©, ìµœê·¼ ê°’ì— ë” í° ê°€ì¤‘ì¹˜ë¥¼ ì£¼ì–´ ë³€í™”ì— ë¯¼ê°í•©ë‹ˆë‹¤.
    - **STL ë¶„í•´** : ì£¼ê¸°ì„±(Seasonal)ì„ ì œê±°í•˜ê³ , ì´ìƒ/ê·¹ë‹¨ì¹˜ì˜ ì˜í–¥ì„ ì ê²Œ ë°›ëŠ” ë°©ì‹ìœ¼ë¡œ, ìˆœìˆ˜ ì¶”ì„¸ë§Œ ë³´ì—¬ì¤ë‹ˆë‹¤.
    - **Seasonally Adjusted** : ì£¼ê¸°ì„±(Seasonal)ë§Œ ì œê±°í•˜ê³ , ì´ë²¤íŠ¸ë‚˜ í”„ë¡œëª¨ì…˜ ë“±ì˜ ì”ì°¨ëŠ” ë‚¨ê²¨, ìˆœìˆ˜ ë³€í™”ëŸ‰ ì¶”ì„¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
    """)

    #  ë‚ ì§œ ë¡œë“œ
    _today = pd.Timestamp.today().normalize()
    _chart_end = (_today - pd.Timedelta(days=1)).date()  # D-1

    cs_chart = "20250701"
    ce_chart = pd.Timestamp(_chart_end).strftime("%Y%m%d")

    # ì´í›„ ë¡œì§ ë™ì¼
    df_merged_chart, df_psi_chart, last_updated_time__media, last_updated_time__GA = load_data(cs_chart, ce_chart)

    # ê¸°ì¡´ load_data(cs, ce)ë¥¼ ì¬ì‚¬ìš©í•˜ì—¬ ì°¨íŠ¸ ì „ìš© ë°ì´í„° í™•ë³´
    df_merged_chart, df_psi_chart, last_updated_time__media, last_updated_time__GA = load_data(cs_chart, ce_chart)

    # â”€â”€ 1) ë¸Œëœë“œë³„ ì¼ì í”¼ë²—(ì°¨íŠ¸ìš©) â€“ ë³´ê³ ì„œ ìª½ê³¼ ë™ì¼í•œ ë¡œì§ ê°„ì†Œ ë³µì œ
    def _pivot_cstSes(df, brand_type=None, product_type=None):
        df_f = df.copy()
        if brand_type:
            df_f = df_f[df_f['brand_type'].astype(str).str.contains(brand_type, regex=True, na=False)]
        if product_type:
            df_f = df_f[df_f['product_type'].astype(str).str.contains(product_type, regex=True, na=False)]
        df_f['event_date'] = pd.to_datetime(df_f['event_date'], errors='coerce').dt.strftime('%Y-%m-%d')
        return (df_f.groupby('event_date', as_index=False)
                    .agg(session_count=('pseudo_session_id','sum'),
                        cost_gross_sum=('cost_gross','sum'))
                    .reset_index(drop=True))

    def _pivot_ord(df, brand_type=None, product_type=None):
        df_f = df.copy()
        if brand_type:
            df_f = df_f[df_f['ë¸Œëœë“œ'].astype(str).str.contains(brand_type, regex=True, na=False)]
        if product_type:
            df_f = df_f[df_f['ì¹´í…Œê³ ë¦¬'].astype(str).str.contains(product_type, regex=True, na=False)]
        df_f['ì£¼ë¬¸ì¼'] = pd.to_datetime(df_f['ì£¼ë¬¸ì¼'], errors='coerce').dt.strftime('%Y-%m-%d')
        return (df_f.groupby('ì£¼ë¬¸ì¼', as_index=False)
                    .agg(ord_amount_sum=('ì‹¤ê²°ì œê¸ˆì•¡','sum'),
                        ord_count_sum=('ì£¼ë¬¸ìˆ˜','sum'))
                    .reset_index(drop=True))

    # ì°¨íŠ¸ìš© ë°ì´í„°í”„ë ˆì„ êµ¬ì„± (í†µí•©/ìŠ¬ë¦½í¼/ëˆ„ì–´)
    _df_total_cost = (df_merged_chart.groupby('event_date', as_index=False)
                    .agg(cost_gross_sum=('cost_gross','sum'))
                    .sort_values('event_date'))
    _df_total_order = (df_order.groupby('ì£¼ë¬¸ì¼', as_index=False)
                    .agg(ord_amount_sum=('ì‹¤ê²°ì œê¸ˆì•¡','sum'), ord_count_sum=('ì£¼ë¬¸ìˆ˜','sum'))
                    .sort_values('ì£¼ë¬¸ì¼')
                    .rename(columns={'ì£¼ë¬¸ì¼':'event_date'}))
    df_total_chart = (df_psi_chart
                    .merge(_df_total_cost,  on='event_date', how='left')
                    .merge(_df_total_order, on='event_date', how='left'))

    _s_slp  = _pivot_cstSes(df_merged_chart, brand_type="ìŠ¬ë¦½í¼")
    _o_slp  = _pivot_ord(df_order,          brand_type="ìŠ¬ë¦½í¼")
    df_slp_chart = _s_slp.join(_o_slp.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')

    _s_nor  = _pivot_cstSes(df_merged_chart, brand_type="ëˆ„ì–´")
    _o_nor  = _pivot_ord(df_order,          brand_type="ëˆ„ì–´")
    df_nor_chart = _s_nor.join(_o_nor.set_index('ì£¼ë¬¸ì¼'), on='event_date', how='left')

    # â”€â”€ 2) ì»¨íŠ¸ë¡¤ (ì´ ì˜ì—­ë§Œ ë…ë¦½ í‚¤ ì‚¬ìš©)
    options = {"ì „ì²´ í†µí•©": df_total_chart, "ìŠ¬ë¦½í¼ í†µí•©": df_slp_chart, "ëˆ„ì–´ í†µí•©": df_nor_chart}
    c1, c2, c3, _p, c4 = st.columns([3,3,3,0.5,3])

    with c1:
        ds_name = st.selectbox("ë°ì´í„° ì„ íƒ", list(options.keys()), index=0, key="ts_ds")
    df_ts = options[ds_name].copy()

    # ë‚ ì§œ ì •ê·œí™”
    DATE_CANDS = ['ë‚ ì§œ','date','event_date']
    date_col = next((c for c in DATE_CANDS if c in df_ts.columns), None)
    if date_col is None:
        st.error("ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ì–´ ì‹œê³„ì—´ì„ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); st.stop()
    df_ts[date_col] = pd.to_datetime(df_ts[date_col], errors='coerce')
    df_ts = df_ts.dropna(subset=[date_col]).sort_values(date_col)

    label_map = {
        'ord_amount_sum': 'ë§¤ì¶œ',
        'cost_gross_sum': 'ê´‘ê³ ë¹„',
        'session_count' : 'ì„¸ì…˜ìˆ˜',
        'ord_count_sum' : 'ì£¼ë¬¸ìˆ˜',
    }
    metric_options = [k for k in ['ord_amount_sum','cost_gross_sum','session_count','ord_count_sum'] if k in df_ts.columns]
    with c2:
        metric = st.selectbox("ì§€í‘œ ì„ íƒ", metric_options, index=0, key="ts_metric",
                            format_func=lambda k: label_map.get(k, k))
    overlay_options = ["MA (ì´ë™í‰ê· )", "EWMA (ì§€ìˆ˜ê°€ì¤‘ ì´ë™í‰ê· )", "STL ë¶„í•´", "Seasonally Adjusted"]
    with c3:
        overlay = st.selectbox("ìŠ¤ë¬´ë”© ê¸°ë²• ì„ íƒ", overlay_options, index=0, key="ts_overlay")
    with _p:
        pass
    with c4:
        period = st.radio("ì£¼ê¸°(S) ì„ íƒ", [7, 14], horizontal=True, index=0, key="ts_period",
                        help="ë””í´íŠ¸ê°’ì¸ 7ì¼ì„ ê¶Œì¥í•©ë‹ˆë‹¤. ì´ ê°’ì€ ì´ë™í‰ê·  í‰í™œ, ì„¸ë¡œì„  ê°„ê²©, ë³¼ë¦°ì € ë°´ë“œì— ì‚¬ìš©ë©ë‹ˆë‹¤.")

    # â”€â”€ 3) ì›” ë‹¨ìœ„ ì„ íƒ ìŠ¬ë¼ì´ë” (ì´ ì˜ì—­ë§Œ ë…ë¦½) â€” ê¸°ë³¸: ìµœì‹  2ê°œì›”
    date_min = pd.to_datetime(df_ts[date_col].min()).normalize()
    date_max = pd.to_datetime(df_ts[date_col].max()).normalize()
    if pd.isna(date_min) or pd.isna(date_max):
        st.warning("ìœ íš¨í•œ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); st.stop()

    start_period = date_min.to_period("M")
    end_period   = date_max.to_period("M")
    month_options = [p.to_timestamp() for p in pd.period_range(start=start_period, end=end_period, freq="M")]

    # ì˜µì…˜ì´ 0/1ê°œì¼ ë•Œ ë°©ì–´ (RangeError ì˜ˆë°©)
    if len(month_options) == 0:
        st.warning("í‘œì‹œí•  ì›” ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."); st.stop()
    elif len(month_options) == 1:
        start_sel = end_sel = month_options[0]
        st.select_slider("ê¸°ê°„(ì›”)", options=month_options, value=start_sel,
                        format_func=lambda x: x.strftime("%Y-%m"), key="ts_period_single")
    else:
        # ê¸°ë³¸ê°’: ë§ˆì§€ë§‰ ë‘ ë‹¬
        default_start, default_end = (month_options[-2], month_options[-1])
        start_sel, end_sel = st.select_slider(
            "ê¸°ê°„(ì›”)", options=month_options, value=(default_start, default_end),
            format_func=lambda x: x.strftime("%Y-%m"), key="ts_period_range"
        )
        if start_sel > end_sel:
            start_sel, end_sel = end_sel, start_sel

    period_start, period_end = start_sel, end_sel + MonthEnd(0)
    dfp = df_ts[(df_ts[date_col] >= period_start) & (df_ts[date_col] <= period_end)].copy()

    # â”€â”€ 4) ì‹œê³„ì—´ ê³„ì‚° ë° ê·¸ë¦¬ê¸° 
    s = dfp.set_index(date_col)[metric].asfreq('D').fillna(0)
    if s.empty or s.dropna().shape[0] < 2:
        st.warning("ì„ íƒí•œ ê¸°ê°„ì— í‘œì‹œí•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ê¸°ê°„ì„ ë„“í˜€ì£¼ì„¸ìš”.")
    else:
        win = period
        y_ma = s.rolling(win, min_periods=1).mean() if overlay == "MA (ì´ë™í‰ê· )" else None

        y_trend = y_seas = y_sa = None
        if overlay in ("STL ë¶„í•´", "Seasonally Adjusted"):
            try:
                from statsmodels.tsa.seasonal import STL
                stl_period = max(2, min(int(period), max(2, len(s)//2)))
                stl = STL(s, period=stl_period, robust=True).fit()
                y_trend, y_seas = stl.trend, stl.seasonal
            except Exception:
                key = np.arange(len(s)) % period
                y_seas  = s.groupby(key).transform('mean')
                y_trend = (s - y_seas).rolling(period, min_periods=1, center=True).mean()
            y_sa = (s - y_seas) if y_seas is not None else None

        y_ewma = s.ewm(halflife=period, adjust=False, min_periods=1).mean() if overlay == "EWMA (ì§€ìˆ˜ê°€ì¤‘ ì´ë™í‰ê· )" else None

        fig = make_subplots(specs=[[{"secondary_y": True}]])
        fig.add_trace(
            go.Scatter(x=s.index, y=s, name="RAW", mode="lines+markers", line=dict(color="#666"), opacity=0.45),
            secondary_y=False
        )

        # Bollinger Bands (ì§§ì€ êµ¬ê°„ ë°©ì–´)
        k = 2.0
        minp = int(min(period, max(2, len(s))))
        ma_bb = s.rolling(period, min_periods=minp).mean()
        sd_bb = s.rolling(period, min_periods=minp).std(ddof=0)
        bb_upper = ma_bb + k * sd_bb
        bb_lower = ma_bb - k * sd_bb

        fig.add_trace(go.Scatter(x=bb_upper.index, y=bb_upper, name="BB Upper", mode="lines", line=dict(width=1, color="#FFB6C1")), secondary_y=False)
        fig.add_trace(go.Scatter(x=bb_lower.index, y=bb_lower, name="BB Lower", mode="lines", line=dict(width=1, color="#ADD8E6"),
                                fill="tonexty", fillcolor="rgba(128,128,128,0.12)"), secondary_y=False)

        overlay_series = None
        if overlay == "MA (ì´ë™í‰ê· )" and y_ma is not None:
            overlay_series = y_ma
            fig.add_trace(go.Scatter(x=y_ma.index, y=y_ma, name=f"MA{win}", mode="lines", line=dict(color="#FF4B4B")), secondary_y=True)
        elif overlay == "STL ë¶„í•´" and y_trend is not None:
            overlay_series = y_trend
            fig.add_trace(go.Scatter(x=y_trend.index, y=y_trend, name="STL ë¶„í•´", mode="lines", line=dict(color="#FF4B4B")), secondary_y=True)
        elif overlay == "Seasonally Adjusted" and y_sa is not None:
            overlay_series = y_sa
            fig.add_trace(go.Scatter(x=y_sa.index, y=y_sa, name="Seasonally Adjusted", mode="lines", line=dict(color="#FF4B4B")), secondary_y=True)
        elif overlay == "EWMA (ì§€ìˆ˜ê°€ì¤‘ ì´ë™í‰ê· )" and y_ewma is not None:
            overlay_series = y_ewma
            fig.add_trace(go.Scatter(x=y_ewma.index, y=y_ewma, name=f"EWMA(h={period})", mode="lines", line=dict(color="#FF4B4B")), secondary_y=True)

        # left_candidates = [s.dropna()]
        # if (bb_upper is not None) and (not bb_upper.dropna().empty): left_candidates.append(bb_upper.dropna())
        # if (bb_lower is not None) and (not bb_lower.dropna().empty): left_candidates.append(bb_lower.dropna())
        # left_all = pd.concat(left_candidates) if left_candidates else s.dropna()
        # right = overlay_series.dropna() if (overlay_series is not None) else None

        # if (not left_all.empty) and (right is not None) and (not right.empty):
        #     ymin = float(np.nanmin([left_all.min(), right.min()]))
        #     ymax = float(np.nanmax([left_all.max(), right.max()]))
        #     if (not np.isfinite(ymin)) or (not np.isfinite(ymax)) or (ymax <= ymin):
        #         pad = 1.0
        #         ymin = (ymin if np.isfinite(ymin) else 0.0) - pad
        #         ymax = (ymax if np.isfinite(ymax) else 0.0) + pad
        #     else:
        #         pad = (ymax - ymin) * 0.05
        #         ymin, ymax = ymin - pad, ymax + pad
        #     fig.update_yaxes(range=[ymin, ymax], secondary_y=False)
        #     fig.update_yaxes(range=[ymin, ymax], secondary_y=True)
        #     fig.update_yaxes(tickformat="~s", secondary_y=False)
        #     fig.update_yaxes(tickformat="~s", secondary_y=True)
        
        # â”€â”€ ì¢Œ/ìš° ì¶• ë²”ìœ„ ì„¤ì • (STL/SAëŠ” ìš°ì¸¡ ë…ë¦½ ìŠ¤ì¼€ì¼)
        left_candidates = [s.dropna()]
        if (bb_upper is not None) and (not bb_upper.dropna().empty):
            left_candidates.append(bb_upper.dropna())
        if (bb_lower is not None) and (not bb_lower.dropna().empty):
            left_candidates.append(bb_lower.dropna())
        left_all = pd.concat(left_candidates) if left_candidates else s.dropna()
        right = overlay_series.dropna() if (overlay_series is not None) else None

        def _minmax_with_pad(series_min, series_max, pad_ratio=0.05, fallback_pad=1.0):
            # ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ None ë°˜í™˜ (ìë™ ìŠ¤ì¼€ì¼)
            if (series_min is None) or (series_max is None):
                return None
            if (not np.isfinite(series_min)) or (not np.isfinite(series_max)):
                return None
            if series_max <= series_min:
                pad = fallback_pad
                return (series_min - pad, series_max + pad)
            pad = (series_max - series_min) * pad_ratio
            return (series_min - pad, series_max + pad)

        # 1) ì¢Œì¸¡ ì¶•: RAW(+BB) ê¸°ì¤€ ë²”ìœ„ ì„¤ì •
        if not left_all.empty:
            lmin = float(left_all.min())
            lmax = float(left_all.max())
            lrange = _minmax_with_pad(lmin, lmax)
            if lrange is not None:
                fig.update_yaxes(range=list(lrange), secondary_y=False)
        fig.update_yaxes(tickformat="~s", secondary_y=False)

        # 2) ìš°ì¸¡ ì¶•: ì˜¤ë²„ë ˆì´ë³„ ì²˜ë¦¬
        if (right is not None) and (not right.empty):
            rmin = float(right.min())
            rmax = float(right.max())

            # STL / Seasonally Adjusted â†’ ìš°ì¸¡ ë…ë¦½ ìŠ¤ì¼€ì¼
            if overlay in ("STL ë¶„í•´", "Seasonally Adjusted"):
                rrange = _minmax_with_pad(rmin, rmax)
                if rrange is not None:
                    fig.update_yaxes(range=list(rrange), secondary_y=True)
            else:
                # ê·¸ ì™¸(MA/EWMA)ëŠ” ì¢Œì¸¡ê³¼ ë™ì¼ ë²”ìœ„(ë™ê¸°í™”)
                if not left_all.empty:
                    if lrange is not None:
                        fig.update_yaxes(range=list(lrange), secondary_y=True)

        fig.update_yaxes(tickformat="~s", secondary_y=True)


        # ì£¼ê¸°ë³„ ì„¸ë¡œì„ 
        start_ts = pd.to_datetime(s.index.min()).normalize()
        end_ts   = pd.to_datetime(s.index.max()).normalize()
        offset_days = (6 - start_ts.weekday()) % 7   # 0=ì›” ... 6=ì¼ â†’ ì²« ì¼ìš”ì¼
        first_sunday = start_ts + pd.Timedelta(days=offset_days)
        step = 7 if period == 7 else 14
        t = first_sunday
        while t <= end_ts:
            fig.add_vline(x=t, line_dash="dash", line_width=1, opacity=0.6, line_color="#8c8c8c")
            t += pd.Timedelta(days=step)

        fig.update_yaxes(title_text=f"{label_map.get(metric, metric)} Â· RAW / BB", secondary_y=False)
        overlay_title = {
            "MA (ì´ë™í‰ê· )": f"{label_map.get(metric, metric)} Â· MA{win}",
            "STL ë¶„í•´": "STL ë¶„í•´",
            "Seasonally Adjusted": "Seasonally Adjusted",
            "EWMA (ì§€ìˆ˜ê°€ì¤‘ ì´ë™í‰ê· )": f"EWMA (halflife={period})"
        }[overlay]
        fig.update_yaxes(title_text=overlay_title, secondary_y=True)
        fig.update_yaxes(showgrid=False, zeroline=False)
        fig.update_layout(
            margin=dict(l=10, r=10, t=30, b=10),
            legend=dict(orientation="h", y=1.03, x=1, xanchor="right", yanchor="bottom", title=None),
        )
        st.plotly_chart(fig, use_container_width=True)







    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # í†µí•© ë§¤ì¶œ ë¦¬í¬íŠ¸ 
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.header(" ") # ê³µë°±ìš©
    st.markdown("<h5 style='margin:0'>í†µí•© ë§¤ì¶œ ë¦¬í¬íŠ¸</h5>", unsafe_allow_html=True)  
    st.markdown(":gray-badge[:material/Info: Info]ã…¤ì¼ìë³„ **í†µí•©** ë°ì´í„°ì™€ íš¨ìœ¨ ì¶”ì´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ", unsafe_allow_html=True)
    with st.popover("ì§€í‘œ ì„¤ëª…"):
        st.markdown("""
                    - **AOV** (Average Order Value) : **í‰ê· ì£¼ë¬¸ê¸ˆì•¡** (ë§¤ì¶œ Ã· ì£¼ë¬¸ìˆ˜)  
                    - **ROAS** (Return On Ad Spend) : **ê´‘ê³  ìˆ˜ìµë¥ ** (ë§¤ì¶œ Ã· ê´‘ê³ ë¹„ Ã— 100)  
                    - **CVR** (Conversion Rate) : **ì „í™˜ìœ¨** (ì£¼ë¬¸ìˆ˜ Ã· ì„¸ì…˜ìˆ˜ Ã— 100)  
                    """)
    render_style(df_total)


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ìŠ¬ë¦½í¼ ë§¤ì¶œ ë¦¬í¬íŠ¸
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.header(" ") # ê³µë°±ìš©
    st.markdown("<h5 style='margin:0'><span style='color:#FF4B4B;'>ìŠ¬ë¦½í¼</span> ë§¤ì¶œ ë¦¬í¬íŠ¸</h5>", unsafe_allow_html=True)  
    st.markdown(":gray-badge[:material/Info: Info]ã…¤ì¼ìë³„ **í’ˆëª©** ë°ì´í„°ì™€ íš¨ìœ¨ ì¶”ì´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. <span style='color:#8E9097;'>(15ì‹œ ì´í›„ D-1 ë°ì´í„° ì œê³µ)</span> ", unsafe_allow_html=True)
    with st.popover("ì§€í‘œ ì„¤ëª…"):
        st.markdown("""
                    - **AOV** (Average Order Value) : **í‰ê· ì£¼ë¬¸ê¸ˆì•¡** (ë§¤ì¶œ Ã· ì£¼ë¬¸ìˆ˜)  
                    - **ROAS** (Return On Ad Spend) : **ê´‘ê³  ìˆ˜ìµë¥ ** (ë§¤ì¶œ Ã· ê´‘ê³ ë¹„ Ã— 100)  
                    - **CVR** (Conversion Rate) : **ì „í™˜ìœ¨** (ì£¼ë¬¸ìˆ˜ Ã· ì„¸ì…˜ìˆ˜ Ã— 100)  
                    """)

    tabs = st.tabs(["ìŠ¬ë¦½í¼ í†µí•©", "ìŠ¬ë¦½í¼ ë§¤íŠ¸ë¦¬ìŠ¤", "ìŠ¬ë¦½í¼ í”„ë ˆì„"])
    with tabs[0]:
        render_style(df_slp)
    with tabs[1]:
        render_style(df_slp_mat)
    with tabs[2]:
        render_style(df_slp_frm)


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ëˆ„ì–´ ë§¤ì¶œ ë¦¬í¬íŠ¸
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.header(" ") # ê³µë°±ìš©
    st.markdown("<h5 style='margin:0'><span style='color:#FF4B4B;'>ëˆ„ì–´</span> ë§¤ì¶œ ë¦¬í¬íŠ¸</h5>", unsafe_allow_html=True)  
    st.markdown(":gray-badge[:material/Info: Info]ã…¤ì¼ìë³„ **í’ˆëª©** ë°ì´í„°ì™€ íš¨ìœ¨ ì¶”ì´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. <span style='color:#8E9097;'>(15ì‹œ ì´í›„ D-1 ë°ì´í„° ì œê³µ)</span> ", unsafe_allow_html=True)
    with st.popover("ì§€í‘œ ì„¤ëª…"):
        st.markdown("""
                    - **AOV** (Average Order Value) : **í‰ê· ì£¼ë¬¸ê¸ˆì•¡** (ë§¤ì¶œ Ã· ì£¼ë¬¸ìˆ˜)  
                    - **ROAS** (Return On Ad Spend) : **ê´‘ê³  ìˆ˜ìµë¥ ** (ë§¤ì¶œ Ã· ê´‘ê³ ë¹„ Ã— 100)  
                    - **CVR** (Conversion Rate) : **ì „í™˜ìœ¨** (ì£¼ë¬¸ìˆ˜ Ã· ì„¸ì…˜ìˆ˜ Ã— 100)  
                    """)

    tabs = st.tabs(["ëˆ„ì–´ í†µí•©", "ëˆ„ì–´ ë§¤íŠ¸ë¦¬ìŠ¤", "ëˆ„ì–´ í”„ë ˆì„"])
    with tabs[0]:
        render_style(df_nor)
    with tabs[1]:
        render_style(df_nor_mat)
    with tabs[2]:
        render_style(df_nor_frm)


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì‹œê°í™” ì°¨íŠ¸ (ë‚˜ì¤‘ì— ì‹œê°í™” ì˜ì—­ ë”°ë¡œ ì¶”ê°€í•  ê±° ê°™ì•„ì„œ ì£¼ì„ì²˜ë¦¬í•¨ // 08.19)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # st.header(" ")
    # st.markdown("<h5 style='margin:0'>ë¦¬í¬íŠ¸ ì‹œê°í™”</h5>", unsafe_allow_html=True)
    # st.markdown(
    #     ":gray-badge[:material/Info: Info]ã…¤ë¦¬í¬íŠ¸, ì§€í‘œ, ì°¨íŠ¸ ì˜µì…˜ì„ ììœ ë¡­ê²Œ ì„ íƒí•˜ì—¬, ì›í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì‚´í´ë³´ì„¸ìš”.",
    #     unsafe_allow_html=True,
    # )

    # dfs = {
    #     "í†µí•© ë¦¬í¬íŠ¸":    df_total,
    #     "ìŠ¬ë¦½í¼ í†µí•©":    df_slp,
    #     "ìŠ¬ë¦½í¼ ë§¤íŠ¸ë¦¬ìŠ¤": df_slp_mat,
    #     "ìŠ¬ë¦½í¼ í”„ë ˆì„":   df_slp_frm,
    #     "ëˆ„ì–´ í†µí•©":     df_nor,
    #     "ëˆ„ì–´ ë§¤íŠ¸ë¦¬ìŠ¤":  df_nor_mat,
    #     "ëˆ„ì–´ í”„ë ˆì„":    df_nor_frm,
    # }
    
    # metrics = ["ë§¤ì¶œ","ì£¼ë¬¸ìˆ˜","AOV","ê´‘ê³ ë¹„","ROAS","ì„¸ì…˜ìˆ˜","CVR"]
    
    # col_map = {
    #     "ë§¤ì¶œ":   "ord_amount_sum",
    #     "ì£¼ë¬¸ìˆ˜": "ord_count_sum",
    #     "AOV":    "AOV",
    #     "ê´‘ê³ ë¹„": "cost_gross_sum",
    #     "ROAS":   "ROAS",
    #     "ì„¸ì…˜ìˆ˜": "session_count",
    #     "CVR":    "CVR"
    # }

    # default_yaxis = {
    #     "ë§¤ì¶œ": "left",
    #     "ì£¼ë¬¸ìˆ˜": "left",
    #     "AOV": "left",
    #     "ê´‘ê³ ë¹„": "left",
    #     "ROAS": "right",
    #     "ì„¸ì…˜ìˆ˜": "left",
    #     "CVR": "right"
    # }
    # default_chart = {
    #     "ë§¤ì¶œ": "bar",
    #     "ì£¼ë¬¸ìˆ˜": "bar",
    #     "AOV": "line",
    #     "ê´‘ê³ ë¹„": "bar",
    #     "ROAS": "line",
    #     "ì„¸ì…˜ìˆ˜": "bar",
    #     "CVR": "line"
    # }


    # # â”€â”€ 1) ì„ íƒ UI
    # c_report, c_metric = st.columns([3, 7])
    # with c_report:
    #     sel_report = st.selectbox("ë¦¬í¬íŠ¸ ì„ íƒ", list(dfs.keys()), key="select_report")
    # with c_metric:
    #     sel_metrics = st.multiselect("ì§€í‘œ ì„ íƒ", metrics, default=["AOV", "ROAS"], key="select_metrics")

    # # â”€â”€ 2) ì»¬ëŸ¼ë³„ ì˜µì…˜ ì„ íƒ UI (í‘œ í˜•íƒœ)
    # with st.expander("ì§€í‘œë³„ ì˜µì…˜ ì„ íƒ", expanded=False):

    #     metric_settings = {}
    #     for i, metric in enumerate(sel_metrics):
    #         c2, c3 = st.columns([2, 2])
    #         with c2:
    #             yaxis = st.selectbox(
    #                 f"Yì¶• ìœ„ì¹˜: {metric}", ["ì™¼ìª½", "ì˜¤ë¥¸ìª½"],
    #                 key=f"y_axis_{metric}_{i}",
    #                 index=0 if default_yaxis[metric] == "left" else 1
    #             )
    #         with c3:
    #             chart_type = st.selectbox(
    #                 f"ì°¨íŠ¸ ìœ í˜•: {metric}", ["êº¾ì€ì„ ", "ë§‰ëŒ€"],
    #                 key=f"chart_type_{metric}_{i}",
    #                 index=0 if default_chart[metric] == "line" else 1
    #             )
    #         metric_settings[metric] = {
    #             "yaxis": "right" if yaxis == "ì˜¤ë¥¸ìª½" else "left",
    #             "chart": "bar" if chart_type == "ë§‰ëŒ€" else "line"
    #         }

    # # â”€â”€ 3) ì°¨íŠ¸ ë¡œì§
    # if not sel_metrics:
    #     st.warning("í•˜ë‚˜ ì´ìƒì˜ ì§€í‘œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
    # else:
    #     df = dfs[sel_report].sort_values("event_date").copy()
    #     # íŒŒìƒì§€í‘œ ìƒì„± (ìˆ˜ì‹ì´ í•„ìš”í•œ í•­ëª©ë§Œ)
    #     df["AOV"]  = df["ord_amount_sum"] / df["ord_count_sum"]
    #     df["ROAS"] = df["ord_amount_sum"] / df["cost_gross_sum"] * 100
    #     df["CVR"]  = df["ord_count_sum"]  / df["session_count"] * 100

    #     fig = make_subplots(specs=[[{"secondary_y": True}]])

    #     for metric in sel_metrics:
    #         col = col_map[metric]
    #         y_axis = metric_settings[metric]["yaxis"] == "right"
    #         chart_type = metric_settings[metric]["chart"]

    #         if chart_type == "bar":
    #             fig.add_trace(
    #                 go.Bar(
    #                     x=df["event_date"],
    #                     y=df[col],
    #                     name=metric,
    #                     opacity=0.5,
    #                     # width=0.9
    #                 ),
    #                 secondary_y=y_axis
    #             )
    #         else:  # êº¾ì€ì„ 
    #             fig.add_trace(
    #                 go.Scatter(
    #                     x=df["event_date"],
    #                     y=df[col],
    #                     name=metric,
    #                     mode="lines+markers"
    #                 ),
    #                 secondary_y=y_axis
    #             )

    #     left_titles  = [m for m in sel_metrics if metric_settings[m]["yaxis"]=="left"]
    #     right_titles = [m for m in sel_metrics if metric_settings[m]["yaxis"]=="right"]
    #     left_title  = " Â· ".join(left_titles)  if left_titles  else None
    #     right_title = " Â· ".join(right_titles) if right_titles else None

    #     fig.update_layout(
    #         title=f"{sel_report}  -  {' / '.join(sel_metrics)} ì¶”ì´",
    #         xaxis=dict(tickformat="%mì›” %dì¼"),
    #         legend=dict(
    #             orientation="h",
    #             x=1, y=1.1, xanchor="right", yanchor="bottom"
    #         ),
    #         margin=dict(t=80, b=20, l=20, r=20)
    #     )
    #     if left_title:
    #         fig.update_yaxes(title_text=left_title, secondary_y=False)
    #     if right_title:
    #         fig.update_yaxes(title_text=right_title, secondary_y=True)

    #     st.plotly_chart(fig, use_container_width=True)




if __name__ == "__main__":
    main()